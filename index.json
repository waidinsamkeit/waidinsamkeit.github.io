[{"categories":["Kubernetes"],"content":"Kubernetes中Cgroup泄漏问题 Cgorup文档: https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt 绝大多数的kubernetes集群都有这个隐患。只不过一般情况下，泄漏得比较慢，还没有表现出来而已。 一个pod可能泄漏两个memory cgroup数量配额。即使pod百分之百发生泄漏， 那也需要一个节点销毁过三万多个pod之后，才会造成后续pod创建失败。 一旦表现出来，这个节点就彻底不可用了，必须重启才能恢复。 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:1:0","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"故障表现 该内容的故障信息已经提交给Github: https://github.com/kubernetes/kubernetes/issues/112940 我在服务器中更新Pod出现如下错误 cannot allocate memory unable to ensure pod container exists: failed to create container for [kubepods burstable podd5dafc96-2bcd-40db-90fd-c75758746a7a] : mkdir /sys/fs/cgroup/memory/kubepods/burstable/podd5dafc96-2bcd-40db-90fd-c75758746a7a: cannot allocate memory 使用dmesg查看系统日志的错误内容信息 SLUB: Unable to allocate memory on node -1 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:2:0","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"服务器配置信息 操作系统: CentOS Linux release 7.9.2009 (Core) 系统内核: 3.10.0-1160.el7.x86_64 Kubernetes: 1.17.9 dockerVersion: 20.10.7 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:3:0","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"问题原因1 Kubernetes在1.9版本开启了对kmem的支持,因此 1.9以后的所有版本都有该问题，但必须搭配3.x内核的机器才会出问题。一旦出现会导致新 pod 无法创建，已有 pod不受影响，但pod 漂移到有问题的节点就会失败，直接影响业务稳定性。因为是内存泄露，直接重启机器可以暂时解决，但还会再次出现。 cgroup的kmem account特性在3.x 内核上有内存泄露问题，如果开启了kmem account特性会导致可分配内存越来越少，直到无法创建新 pod 或节点异常。 kmem account 是cgroup 的一个扩展，全称CONFIG_MEMCG_KMEM，属于机器默认配置，本身没啥问题，只是该特性在 3.10 的内核上存在漏洞有内存泄露问题，4.x的内核修复了这个问题。 因为 kmem account 是 cgroup 的扩展能力，因此runc、docker、k8s 层面也进行了该功能的支持，即默认都打开了kmem 属性。 因为3.10 的内核已经明确提示 kmem 是实验性质，我们仍然使用该特性，所以这其实不算内核的问题，是 k8s 兼容问题。 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:4:0","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"问题原因2 memcg是 Linux 内核中用于管理 cgroup 内存的模块，整个生命周期应该是跟随 cgroup 的，但是在低版本内核中(已知3.10)，一旦给某个 memory cgroup 开启 kmem accounting 中的 memory.kmem.limit_in_bytes 就可能会导致不能彻底删除 memcg 和对应的 cssid，也就是说应用即使已经删除了 cgroup (/sys/fs/cgroup/memory 下对应的 cgroup 目录已经删除), 但在内核中没有释放 cssid，导致内核认为的 cgroup 的数量实际数量不一致，我们也无法得知内核认为的 cgroup 数量是多少。 这个问题可能会导致创建容器失败，因为创建容器为其需要创建 cgroup 来做隔离，而低版本内核有个限制：允许创建的 cgroup 最大数量写死为 65535，如果节点上经常创建和销毁大量容器导致创建很多 cgroup，删除容器但没有彻底删除 cgroup 造成泄露(真实数量我们无法得知)，到达 65535 后再创建容器就会报创建 cgroup 失败并报错 no space left on device，使用 kubernetes 最直观的感受就是 pod 创建之后无法启动成功。 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:5:0","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"解决方案 目前官方给出的解决方案如下: kernel upgrade to 4.0+: application crash due to k8s 1.9.x open the kernel memory accounting by default #61937 (comment) rebuild the kubelet with nokmem args. See Failed to create container, mkdir /sys/fs/cgroup/memory/kubepods/besteffort/pod98211fca-b27e-4316-b1ae-c0d27925aa84: cannot allocate memory #96701 (comment) Set cgroup.memory=nokmem in grub: see application crash due to k8s 1.9.x open the kernel memory accounting by default #61937 (comment) ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:6:0","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"解决方案一 感谢提供的解决方案: https://cloud.tencent.com/developer/article/1739289 https://github.com/torvalds/linux/commit/d6e0b7fa11862433773d986b5f995ffdf47ce672 https://support.mesosphere.com/s/article/Critical-Issue-KMEM-MSPH-2018-0006 这种方式的缺点是： 1、要升级所有节点，节点重启的话已有 pod 肯定要漂移，如果节点规模很大，这个升级操作会很繁琐，业务部门也会有意见，要事先沟通。 2、这个问题归根结底是软件兼容问题，3.x 自己都说了不成熟，不建议你使用该特性，k8s、docker却 还要开启这个属性，那就不是内核的责任，因为我们是云上机器，想替换4.x 内核需要虚机团队做足够的测试和评审，因此这是个长期方案，不能立刻解决问题。 3、已有业务在 3.x 运行正常，不代表可以在 4.x 也运行正常，即全量升级内核之前需要做足够的测试，尤其是有些业务需求对os做过定制。 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:6:1","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"解决方案2 修改虚机启动的引导项 grub 中的cgroup.memory=nokmem，让机器启动时直接禁用 cgroup的 kmem 属性 vim /etc/default/grub GRUB_TIMEOUT=5 GRUB_DISTRIBUTOR=\"$(sed 's, release .*$,,g' /etc/system-release)\" GRUB_DEFAULT=saved GRUB_DISABLE_SUBMENU=true GRUB_TERMINAL_OUTPUT=\"console\" GRUB_CMDLINE_LINUX=\"crashkernel=auto spectre_v2=retpoline rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet cgroup.memory=nokmem\" GRUB_DISABLE_RECOVERY=\"true\" 更改完成后你需要生成一下新的cgroup配置. /usr/sbin/grub2-mkconfig -o /boot/grub2/grub.cfg reboot # 重启服务器 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:6:2","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"解决方案3 如果你想在Kubernetes中禁用该属性。issue 中一般建议修改 kubelet代码并重新编译。 对于v1.13及其之前版本的kubelet，需要手动替换以下两个函数。 vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go func EnableKernelMemoryAccounting(path string) error { return nil } func setKernelMemory(path string, kernelMemoryLimit int64) error { return nil } 重新编译并替换 kubelet make WHAT=cmd/kubelet GOFLAGS=-v GOGCFLAGS=\"-N -l\" 对于v1.14及其之后版本的kubelet,通过添加BUILDTAGS来禁止 kmem accounting. make BUILDTAGS=\"nokmem\" WHAT=cmd/kubelet GOFLAGS=-v GOGCFLAGS=\"-N -l\" 遇到1.16 版本的BUILDTAGS=”nokmem“编译出来的 let 还是有问题，还是通过修改代码的方式使其生效 vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem.go package fs import ( \"errors\" ) func EnableKernelMemoryAccounting(path string) error { return nil } func setKernelMemory(path string, kernelMemoryLimit int64) error { return errors.New(\"kernel memory accounting disabled in this runc build\") } 编译前，可以编辑下文件 hack/lib/version.sh，将 KUBE_GIT_TREE_STATE=\"dirty\" 改为 KUBE_GIT_TREE_STATE=\"clean\"，确保版本号干净。 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:6:3","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"影响范围 k8s在1.9版本开启了对kmem的支持，因此1.9以后的所有版本都有该问题,但必须搭配 3.x内核的机器才会出问题。一旦出现会导致新pod无法创建,已有 pod不受影响，但pod 漂移到有问题的节点就会失败，直接影响业务稳定性。因为是内存泄露，直接重启机器可以暂时解决，但还会再次出现。 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:6:4","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"大概得原理理解 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:7:0","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"keme是什么? kmem是Cgroup的一个扩展，全称CONFIG_MEMCG_KMEM，属于机器默认配置。 内核内存与用户内存： 内核内存：专用于Linux内核系统服务使用，是不可swap的，因而这部分内存非常宝贵的。但现实中存在很多针对内核内存资源的攻击，如不断地fork新进程从而耗尽系统资源，即所谓的“fork bomb”。 为了防止这种攻击，社区中提议通过linux内核限制 cgroup中的kmem 容量，从而限制恶意进程的行为，即kernel memory accounting机制。 使用如下命令查看KMEM是否打开： cat /boot/config-`uname -r`|grep CONFIG_MEMCG CONFIG_MEMCG=y CONFIG_MEMCG_SWAP=y CONFIG_MEMCG_SWAP_ENABLED=y CONFIG_MEMCG_KMEM=y ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:7:1","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"cgroup与kmem机制 使用 cgroup 限制内存时，我们不但需要限制对用户内存的使用，也需要限制对内核内存的使用。kernel memory accounting 机制为 cgroup 的内存限制增加了 stack pages（例如新进程创建）、slab pages(SLAB/SLUB分配器使用的内存)、sockets memory pressure、tcp memory pressure等，以保证 kernel memory 不被滥用。 当你开启了kmem 机制，具体体现在 memory.kmem.limit_in_bytes 这个文件上： /sys/fs/cgroup/memory/kubepods/pod632f736f-5ef2-11ea-ad9e-fa163e35f5d4/memory.kmem.limit_in_bytes 实际使用中，我们一般将 memory.kmem.limit_in_bytes 设置成大于 memory.limit_in_bytes，从而只限制应用的总内存使用。 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:7:2","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"docker与k8s使用kmem 以上描述都是cgroup层面即机器层面，但是 runc 和 docker 发现有这个属性之后，在后来的版本中也支持了 kmem ，k8s 发现 docker支持，也在 1.9 版本开始支持。 1.9版本及之后，kubelet 才开启 kmem 属性 kubelet 的这部分代码位于： https://github.com/kubernetes/kubernetes/blob/release-1.12/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go#L70-L106 对于k8s、docker 而言，kmem 属性属于正常迭代和优化，至于3.x的内核上存在 bug 不能兼容，不是k8s 关心的问题。但 issue 中不断有人反馈，因此在 k8s 1.14 版本的 kubelet 中，增加了一个编译选项 make BUILDTAGS=“nokmem”，就可以编译 kubelet 时就禁用 kmem，避免掉这个问题。而1.8 到1.14 中间的版本，只能选择更改 kubelet 的代码。 ","date":"2022-10-08","objectID":"/kubernetescgroup%E6%B3%84%E6%BC%8F/:7:3","tags":["Kubernetes","Kubernetes问题解决"],"title":"Kubernetes低版本中内存泄漏问题","uri":"/kubernetescgroup%E6%B3%84%E6%BC%8F/"},{"categories":["Kubernetes"],"content":"准备工作 兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及那些没有包管理器的发行版提供了通用说明。 每台机器 2 GB 或更多 RAM（任何更少都会为您的应用程序留下很小的空间）。 2 个 CPU 或更多。 集群中所有机器之间的完整网络连接（公共或专用网络都可以）。 每个节点的唯一主机名、MAC 地址和 product_uuid。有关更多详细信息，请参见此处。 您的机器上的某些端口是开放的。有关更多详细信息，请参见此处。 交换Swap分区。必须禁用Swap才能使 kubelet 正常工作。 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:1:0","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"我的服务器配置列表 没有必要按照我的环境来,个人一般机器建议以下配置. master: 2核4G work1: 2核2G work2: 2核2G IP 主机名称 CPU 内存 硬盘 10.1.6.45 containerd-kube-master 4 8 60 10.1.6.46 containerd-kube-work1 4 8 60 10.1.6.47 containerd-kube-work2 4 8 60 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:1:1","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"你所需要开放的端口 协议 方向 端口范围 目的 使用者 TCP 入站 6443 Kubernetes API 服务器 全部 TCP 入站 2379-2380 etcd 服务器客户端 API kube-apiserver, etcd TCP 入站 10250 Kubelet API 自我，控制平面 TCP 入站 10259 kube-调度器 自己 TCP 入站 10257 kube-控制器-管理器 自己 虽然 etcd 端口包含在控制平面部分，但您也可以在外部或自定义端口上托管自己的 etcd 集群。 协议 方向 端口范围 目的 使用者 TCP 入站 10250 Kubelet API 自我，控制平面 TCP 入站 30000-32767 NodePort端口范围 全部 可以覆盖所有默认端口号。当使用自定义端口时，这些端口需要打开而不是此处提到的默认值。 一个常见的例子是 API 服务器端口，有时会切换到 443。或者，默认端口保持原样，API 服务器放在负载均衡器后面，该负载均衡器监听 443 并将请求路由到默认端口上的 API 服务器。 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:1:2","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"准备主机地址 修改每一台主机的/etc/hosts配置 # vim /etc/hosts 10.1.6.45 containerd-kube-master 10.1.6.46 containerd-kube-work1 10.1.6.47 containerd-kube-work2 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:1:3","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"关闭swap分区以及防火墙 如果你的系统使用的并不是Rocky而是CentOS默认是应该没有挂载SWAP分区到fastab当中的 [root@bogon ~]# swapoff -a [root@localhost ~]# echo \"vm.swappiness = 0\" \u003e\u003e /etc/sysctl.conf [root@bogon ~]# vim /etc/fstab # /dev/mapper/rl-swap none swap defaults 0 0 [root@localhost ~]# systemctl stop firewalld \u0026\u0026 systemctl disable firewalld # 关闭并且禁用防火墙 所有内容准备完成后重启三台服务器! ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:1:4","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"安装Containerd 本文档后续基于Containerd+RockyLinux+Kubeadmin containerd Docker CRI-O 需要注意的是,根据Kubernetes官方给出的公告。Kubernetes 1.20x版本将会废弃对Docker的支持 参考链接 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:2:0","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"通过阿里云镜像源安装 官方镜像站 三台主机全部执行此操作 [root@containerd-kube-master ~]# yum install -y yum-utils device-mapper-persistent-data lvm2 [root@containerd-kube-master ~]# yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo [root@containerd-kube-master ~]# yum -y install containerd.io 查看一下containerd的版本 [root@containerd-kube-master ~]# containerd -v containerd containerd.io 1.6.8 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:2:1","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"生成containerd的配置文件 三台主机全部执行此操作 默认情况下在/etc/containerd/config.toml已经有这个文件了,但是里面是一些简短的配置. [root@containerd-kube-master containerd]# mkdir - /etc/containerd/ [root@containerd-kube-master containerd]# containerd config default | tee /etc/containerd/config.toml # 生成contained的默认配置 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:2:2","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"修改sandbox_img pause： 此镜像是kubernetes的基础容器 三台主机全部执行此操作 由于部分用户无法进入k8s.gcr.io资源地址,需要对此地址进行替换. [root@containerd-kube-master containerd]# vim /etc/containerd/config.toml sandbox_image = \"k8s.gcr.io/pause:3.6\" # 找到此选项并且修改为: registry.aliyuncs.com/google_containers/pause:3.6 systemd_cgroup = true # 改为true,一定要是小写的. [plugins.\"io.containerd.grpc.v1.cri\".containerd.default_runtime] runtime_type = \"io.containerd.runtime.v1.linux\"# 修改为io.containerd.runtime.v1.linux ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:2:3","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"启动containerd 三台主机全部执行此操作 保证Active: active(running)的状态即可 [root@containerd-kube-master containerd]# systemctl restart containerd [root@containerd-kube-master containerd]# systemctl enable containerd [root@containerd-kube-master containerd]# systemctl status containerd ● containerd.service - containerd container runtime Loaded: loaded (/usr/lib/systemd/system/containerd.service; disabled; vendor preset: disabled) Active: active (running) since Mon 2022-09-05 02:53:02 EDT; 6s ago Docs: https://containerd.io Process: 8465 ExecStartPre=/sbin/modprobe overlay (code=exited, status=0/SUCCESS) Main PID: 8467 (containerd) Tasks: 12 Memory: 25.2M CGroup: /system.slice/containerd.service └─8467 /usr/bin/containerd Sep 05 02:53:02 containerd-kube-master containerd[8467]: time=\"2022-09-05T02:53:02.159619104-04:00\" level=info msg=\"Start subscribing containerd event\" Sep 05 02:53:02 containerd-kube-master containerd[8467]: time=\"2022-09-05T02:53:02.159662811-04:00\" level=info msg=\"Start recovering state\" Sep 05 02:53:02 containerd-kube-master containerd[8467]: time=\"2022-09-05T02:53:02.159718042-04:00\" level=info msg=\"Start event monitor\" Sep 05 02:53:02 containerd-kube-master containerd[8467]: time=\"2022-09-05T02:53:02.159737174-04:00\" level=info msg=\"Start snapshots syncer\" Sep 05 02:53:02 containerd-kube-master containerd[8467]: time=\"2022-09-05T02:53:02.159750064-04:00\" level=info msg=\"Start cni network conf syncer for default\" Sep 05 02:53:02 containerd-kube-master containerd[8467]: time=\"2022-09-05T02:53:02.159756351-04:00\" level=info msg=\"Start streaming server\" Sep 05 02:53:02 containerd-kube-master containerd[8467]: time=\"2022-09-05T02:53:02.159868546-04:00\" level=info msg=serving... address=/run/containerd/containerd.sock.ttrpc Sep 05 02:53:02 containerd-kube-master containerd[8467]: time=\"2022-09-05T02:53:02.159906215-04:00\" level=info msg=serving... address=/run/containerd/containerd.sock Sep 05 02:53:02 containerd-kube-master containerd[8467]: time=\"2022-09-05T02:53:02.160196660-04:00\" level=info msg=\"containerd successfully booted in 0.021144s\" Sep 05 02:53:02 containerd-kube-master systemd[1]: Started containerd container runtime. ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:2:4","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"准备配置IP转发 三台全部执行 cat \u003c\u003cEOF | tee /etc/modules-load.d/kubernetes1.22.10.conf overlay br_netfilter EOF cat \u003c\u003cEOF | tee /etc/sysctl.d/kubernetes1.22.10-forsys.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF [root@containerd-kube-master containerd]# modprobe br_netfilter [root@containerd-kube-master ~]# sysctl --system 配置完成后请全部重启机器! ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:2:5","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"kubernetes安装 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:3:0","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"通过阿里云镜像源安装 三台全部安装 由于官网未开放同步方式, 可能会有索引gpg检查失败的情况, 这时请用 yum install -y --nogpgcheck kubelet kubeadm kubectl 安装 cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF [root@containerd-kube-work1 ~]# yum install -y kubelet-1.22.10-0 kubeadm-1.22.10-0 kubectl-1.22.10-0 可以通过yum –showduplicates list kubelet查看当前仓库中可用的版本 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:3:1","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"安装命令提示 安装后可以使用tab进行快捷提示 [root@containerd-kube-master ~]# yum -y install bash-completion [root@containerd-kube-master ~]# source \u003c(kubeadm completion bash) \u0026\u0026 source \u003c(kubectl completion bash) 如果你想要永久的使其生效,请把他们加入到.bashrc当中 cd ~ [root@containerd-kube-master ~]# vim .bashrc # .bashrc # User specific aliases and functions alias rm='rm -i' alias cp='cp -i' alias mv='mv -i' # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi source \u003c(kubeadm completion bash) source \u003c(kubectl completion bash) source \u003c(crictl completion bash) ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:3:2","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"启动kubelet [root@containerd-kube-master containerd]# systemctl enable kubelet [root@containerd-kube-master containerd]# systemctl start kubelet ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:3:3","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"初始化集群配置信息 [root@containerd-kube-master containerd]# kubeadm config print init-defaults \u003e init.yaml apiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 10.1.6.45 # 初始化的第一台master主机的地址 bindPort: 6443 nodeRegistration: criSocket: unix:///var/run/containerd/containerd.sock imagePullPolicy: IfNotPresent name: kubernetes-master # 定义主机的唯一名称 taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/google_containers # 修改为阿里云地址 kind: ClusterConfiguration kubernetesVersion: 1.22.10 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 # Pod使用的子网地址 scheduler: {} [root@containerd-kube-master containerd]# kubeadm init --config=init.yaml # 等待镜像Pull完成 [init] Using Kubernetes version: v1.22.10 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:3:4","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"创建admin配置目录 [root@containerd-kube-master containerd]# mkdir -p $HOME/.kube [root@containerd-kube-master containerd]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@containerd-kube-master containerd]# sudo chown $(id -u):$(id -g) $HOME/.kube/config ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:3:5","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"创建集群网络 因为flannel不支持网络隔离,所以不想用了! 不再基于flannel,而是基于calico [root@containerd-kube-master .kube]# curl https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml -O # 如果上面这个地址较慢的话下面的也可以用 curl https://projectcalico.docs.tigera.io/manifests/calico.yaml -O 编辑calico.yaml - name: CALICO_IPV4POOL_CIDR # 修改CIDR为Kubernetes的子网地址,即初始化集群的serviceSubnet value: \"10.96.0.0/12\" 创建calico网络 [root@containerd-kube-master ~]# kubectl apply -f calico.yaml ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:3:6","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"加入集群 如果初始化成功会出现Your Kubernetes control-plane has initialized successfully! 在node节点执行 [root@containerd-kube-work1 containerd]# kubeadm join 10.1.6.45:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:417d4385cc4f0cc572b106a6a13bf59fd865421f12a401f3660afa6ca19e500d ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:3:7","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"验证集群 查看master节点的Pod是否全部启动 [root@containerd-kube-master ~]# kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-6799f5f4b4-pf8w8 1/1 Running 0 2m16s kube-system calico-node-lzcjk 1/1 Running 0 54s kube-system calico-node-mrqkd 1/1 Running 0 2m16s kube-system calico-node-r45bc 1/1 Running 0 71s kube-system coredns-74586cf9b6-gkmbl 1/1 Running 0 2m37s kube-system coredns-74586cf9b6-tgh6f 1/1 Running 0 2m37s kube-system etcd-kubernetes-master 1/1 Running 2 2m42s kube-system kube-apiserver-kubernetes-master 1/1 Running 2 2m43s kube-system kube-controller-manager-kubernetes-master 1/1 Running 2 2m43s kube-system kube-proxy-mx4bg 1/1 Running 0 54s kube-system kube-proxy-ssw98 1/1 Running 0 71s kube-system kube-proxy-tpgfj 1/1 Running 0 2m38s kube-system kube-scheduler-kubernetes-master 1/1 Running 2 2m43s 从master上查看节点是否已经全部Ready [root@containerd-kube-master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION containerd-kube-work1 Ready \u003cnone\u003e 55s v1.22.10 containerd-kube-work2 Ready \u003cnone\u003e 38s v1.22.10 containerd-kube-master Ready control-plane 2m29s v1.22.10 到此为止,1.24的kubernetes已经安装完毕 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:3:8","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"提一个小问题 看一下你们的coredns是否在同一个节点上,如果在同一个节点上,建议重新分配一下coredns保证其高可用性 [root@containerd-kube-master ~]# kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-74586cf9b6-gkmbl 1/1 Running 0 32m 10.105.56.1 kubernetes-master \u003cnone\u003e \u003cnone\u003e kube-system coredns-74586cf9b6-tgh6f 1/1 Running 0 32m 10.105.56.3 kubernetes-master \u003cnone\u003e \u003cnone\u003e 重新分配coredns [root@containerd-kube-master ~]# kubectl --namespace kube-system rollout restart deployment coredns ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:3:9","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"问题解决 ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:4:0","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"01 使用crictl image出现WARN[0000] image connect using default endpoints 出现该问题的原因是由于crictl不知道使用那个sock导致的 [root@containerd-kube-master ~]# crictl image WARN[0000] image connect using default endpoints: [unix:///var/run/dockershim.sock unix:///run/containerd/containerd.sock unix:///run/crio/crio.sock unix:///var/run/cri-dockerd.sock]. As the default settings are now deprecated, you should set the endpoint instead. ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:4:1","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"01-解决方法 默认情况下containerd的sock存放于/run/containerd/containerd.sock # 重新设置一下使用的runtime-endpoint crictl config runtime-endpoint unix:///run/containerd/containerd.sock 默认生成的crictl存放在 /etc/crictl.yaml [root@containerd-kube-master containerd]# vim /etc/crictl.yaml runtime-endpoint: \"unix:///run/containerd/containerd.sock\" image-endpoint: \"unix:///run/containerd/containerd.sock\" # 新版本增加了image-endpoint需要手动更改 timeout: 10 debug: false pull-image-on-create: false disable-pull-on-run: false [root@containerd-kube-master containerd]# systemctl daemon-reload [root@containerd-kube-master containerd]# crictl image IMAGE TAG IMAGE ID SIZE ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:4:2","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Kubernetes"],"content":"02 Master主集群加入token过期如何处理 默认情况下,该token只有24小时,如果token值过期的话需要重新生成 --discovery-token-ca-cert-hash sha256:793106d3b4305808d55c3cdb211f89a768bec86ecef64264b131dc8f2548da16 查看当前master集群的token列表 [root@containerd-kube-master .kube]# kubeadm token list TOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS abcdef.0123456789abcdef 8h 2022-09-06T10:10:05Z authentication,signing \u003cnone\u003e system:bootstrappers:kubeadm:default-node-token 重新生成一份token [root@containerd-kube-master .kube]# kubeadm token create 通过证书hashtokne [root@containerd-kube-master .kube]# openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2\u003e/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //' ","date":"2022-09-22","objectID":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/:4:3","tags":["Kubernetes"],"title":"Kubeadm部署Kubernetes1.22.10","uri":"/kubernetes-1.22.10%E9%83%A8%E7%BD%B2/"},{"categories":["Ansible"],"content":"Ansible-with_items 通过with_items进行循环 语法 {{ item }}: 为读取with_items的固定写法 with_items: 是一个列表,下面可以有多个不同的内容 - hosts: test remote_user: root gather_facts: false vars_files: ./public_vars.yaml tasks: - name: Services Http start service: name={{ item }} state=started with_items: - httpd - firewalld ","date":"2022-08-29","objectID":"/ansible-tasks/:1:0","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"普通写法 - hosts: test remote_user: root gather_facts: false vars_files: ./public_vars.yaml tasks: - name: Set authorized_key in dest hosts authorized_key: user: root key: \"{{ lookup('file', '/root/.ssh/id_rsa.pub') }}\" register: result_auth_info tags: authorized_key_hosts - name: Install httpd yum: name=\"httpd\" state=present - name: Services Http start service: name={{ item }} state=started with_items: - httpd - firewalld ","date":"2022-08-29","objectID":"/ansible-tasks/:1:1","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"使用变量的循环写法 - hosts: test remote_user: root gather_facts: true tasks: - name: Install httpd yum: name={{ packages }} state=present vars: packages: - httpd - pcre-devel ","date":"2022-08-29","objectID":"/ansible-tasks/:1:2","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"使用变量字典循环方式批量创建用户 - hosts: test remote_user: root gather_facts: false vars_files: ./public_vars.yaml tasks: - name: Add Users user: name={{ item.name }} groups={{ item.groups }} state=present with_items: - { name: \"alex\",groups: \"test\"} - { name: \"alex1\",groups: \"test\"} ","date":"2022-08-29","objectID":"/ansible-tasks/:1:3","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"使用变量字典循环拷贝文件 - hosts: test remote_user: root gather_facts: false tasks: - name: Add Users copy: src: '{{ item.src }}' dest: '{{ item.dest }}' mode: '{{ item.mode }}' with_items: - { src: \"./1.txt\", dest: \"/tmp\", mode: 0644} - { src: \"./2.txt\", dest: \"/tmp\", mode: 0644} ","date":"2022-08-29","objectID":"/ansible-tasks/:1:4","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"Ansible-Handlers 通过notify进行监控-\u003e通过handlers触发 关于Handler的一些小注意事项 无论你拥有多少个notify通知相同的handlers,handlers仅仅会在所有tasks正常执行完成后运行一次 只有tasks发生改变了才会通知handlers,没有改变则不会触发handlers 不能使用handlers替代tasks,因为handlers是一个特殊的tasks notify的名称要与handlers的名称一致 - hosts: test remote_user: root gather_facts: false tasks: - name: Set authorized_key in dest hosts authorized_key: user: root key: \"{{ lookup('file', '/root/.ssh/id_rsa.pub') }}\" register: result_auth_info tags: authorized_key_hosts - name: Install httpd yum: name=\"httpd\" state=present notify: Debug Message register: install_info handlers: - name: Debug Message debug: msg: '{{install_info}}' ","date":"2022-08-29","objectID":"/ansible-tasks/:2:0","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"Ansible-Tags 根据playbook中的指定标签的内容进行执行、调试等操作. 对一个tasks指定一个tags标签 对一个tasks指定多个tags标签(真没啥意义,感觉不实用。) 对多个tasks指定一个标签 ","date":"2022-08-29","objectID":"/ansible-tasks/:3:0","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"执行指定Tags标签内容 tags: 指定标签名称 - hosts: test remote_user: root gather_facts: false tasks: - name: Set authorized_key in dest hosts authorized_key: user: root key: \"{{ lookup('file', '/root/.ssh/id_rsa.pub') }}\" register: result_auth_info tags: - authorized_key_hosts -t: 通过-t选项参数进行选择指定标签进行运行 ansible-playbook 1.yaml -t authorized_key_hosts -i hosts ","date":"2022-08-29","objectID":"/ansible-tasks/:3:1","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"跳过指定标签执行其他内容 跳过指定的标签内容,执行标签内容外的其他内容 ansible-playbook 1.yaml --skip-tags \"authorized_key_hosts\" -i hosts ","date":"2022-08-29","objectID":"/ansible-tasks/:3:2","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"Ansible-Include 一个可以将playbook简单的进行复用的一个功能! ","date":"2022-08-29","objectID":"/ansible-tasks/:4:0","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"简单应用 编写一个重启http服务的配置 - name: Start HTTP service: name=httpd state=restarted PlayBook中的应用 include： 查找的文件目录为你当前所在的目录,可以通过pwd命令进行查看。 - hosts: test remote_user: root gather_facts: true tasks: - name: Set authorized_key in dest hosts authorized_key: user: root key: \"{{ lookup('file', '/root/.ssh/id_rsa.pub') }}\" register: result_auth_info tags: authorized_key_hosts - name: Install HTTP yum: name=\"httpd\" state=present - name: Restart HTTP include: starthttp.yaml # 包含你刚刚写的配置 # include_tasks: starthttpd.yaml # 两种写法都可以 ","date":"2022-08-29","objectID":"/ansible-tasks/:4:1","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"多个playbook合成 如果你写的playbook存在多个文件,你只想执行一个playbook,那么可以使用import_playbook。 import_playbook: 引入你需要的playbook文件,必须是一个完整的playbook文件 - import_playbook: ./tasks1.yaml - import_playbook: ./tasks2.yaml ","date":"2022-08-29","objectID":"/ansible-tasks/:4:2","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"Ansible-ignore_errors 在Ansible中进行错误的忽略 - hosts: test remote_user: root gather_facts: true tasks: - name: Set authorized_key in dest hosts authorized_key: user: root key: \"{{ lookup('file', '/root/.ssh/id_rsa.pub') }}\" register: result_auth_info tags: authorized_key_hosts - name: Ingoring command: /bin/false ignore_errors: yes 输出结果大概是这样的 PLAY [test] TASK [Ingoring] ***************************************************************************************************************************************************************************************************************************fatal: [10.1.6.5]: FAILED! =\u003e {\"changed\": true, \"cmd\": [\"/bin/false\"], \"delta\": \"0:00:00.026834\", \"end\": \"2022-08-29 02:17:00.089749\", \"msg\": \"non-zero return code\", \"rc\": 1, \"start\": \"2022-08-29 02:17:00.062915\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"\", \"stdout_lines\": []} ...ignoring PLAY RECAP ********************************************************************************************************************************************************************************************************************************10.1.6.5 : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=1 ","date":"2022-08-29","objectID":"/ansible-tasks/:5:0","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"Ansible-changed_when 通常用于失败后所执行一些操作: 例如失败后强制调用handlers、失败后强制删除等. 通常而言，如果任务失败并且play在该主机上中止，则收到play中早前任务通知的处理程序将不会运行。如果在play中设置force_handlers: yes关键字，则即使play因为后续任务失败而中止也会调用被通知的处理程序。 ","date":"2022-08-29","objectID":"/ansible-tasks/:6:0","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"force_handlers - hosts: test remote_user: root gather_facts: true force_handlers: yes # 强制调用handlers tasks: - name: Set authorized_key in dest hosts authorized_key: user: root key: \"{{ lookup('file', '/root/.ssh/id_rsa.pub') }}\" register: result_auth_info tags: authorized_key_hosts - name: Test False command: echo \"This is Force \" notify: Restart HTTP service - name: Install available yum: name=dbdbdb state=present handlers: - name: Restart HTTP service service: name=httpd state=restarted 虽然任务是失败的,但是依旧调用了最后执行的handlers [root@localhost ansible_linux]# ansible-playbook 1.yaml -i hosts TASK [Install available] ******************************************************************************************************************************************************************************************************************fatal: [10.1.6.57]: FAILED! =\u003e {\"changed\": false, \"failures\": [\"No package dbdbdb available.\"], \"msg\": \"Failed to install some of the specified packages\", \"rc\": 1, \"results\": []} RUNNING HANDLER [Restart HTTP service] ****************************************************************************************************************************************************************************************************changed: [10.1.6.57] ","date":"2022-08-29","objectID":"/ansible-tasks/:6:1","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["Ansible"],"content":"changed_when 当前命令确保不会对被控端主机进行变更的时候,可以使用changer_when来进行忽略提示中的changed - hosts: test remote_user: root gather_facts: true force_handlers: yes # 强制调用handlers tasks: - name: Set authorized_key in dest hosts authorized_key: user: root key: \"{{ lookup('file', '/root/.ssh/id_rsa.pub') }}\" register: result_auth_info tags: authorized_key_hosts - name: Check HTTP shell: ps -aux | grep httpd changed_when: false # 这样ps -aux | grep httpd 再也不会提示changed - name: Message debug: msg: \"{{ ansible_distribution }}\" changed_when还可以检查tasks任务返回的结果 查找输出当中是否存在successfuly如果没有则不执行 - hosts: test remote_user: root gather_facts: true tasks: - name: Set authorized_key in dest hosts authorized_key: user: root key: \"{{ lookup('file', '/root/.ssh/id_rsa.pub') }}\" register: result_auth_info tags: authorized_key_hosts - name: Install Nginx yum: name=nginx state=present notify: Start Nginx - name: Check Nginx Configure command: /usr/sbin/nginx -t register: check_nginx changed_when: (check_nginx.stdout.find('successful')) handlers: - name: Start Nginx service: name=nginx state=restarted ","date":"2022-08-29","objectID":"/ansible-tasks/:6:2","tags":["Ansible"],"title":"Ansible-Tasks任务控制","uri":"/ansible-tasks/"},{"categories":["声明"],"content":"我的博客即将同步至腾讯云开发者社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=359l3zwqzko4c ","date":"2022-08-25","objectID":"/%E5%A3%B0%E6%98%8E/:0:0","tags":["声明"],"title":"本站即将同步腾讯开发者社区","uri":"/%E5%A3%B0%E6%98%8E/"},{"categories":["Ansible"],"content":"1.0 Ansible怎么定义变量 通过playbook中的play进行变量的定义 通过inventory主机清单进行变量定义 通过执行playbook的时候增加-e选项进行定义 ","date":"2022-08-15","objectID":"/ansible%E5%8F%98%E9%87%8F%E8%BF%9B%E9%98%B6/:1:0","tags":["Ansible"],"title":"Ansible变量进阶","uri":"/ansible%E5%8F%98%E9%87%8F%E8%BF%9B%E9%98%B6/"},{"categories":["Ansible"],"content":"1.0.1 通过Playbook中的vars定义变量 在Playbook中通过写入vars语法定义变量 通过{{变量名}}进行引用! - hosts: test remote_user: root vars: - httpd_package: httpd tasks: - name: Install DepencyEnvorment yum: name: {{httpd_package}} state: present update_cache: yes ","date":"2022-08-15","objectID":"/ansible%E5%8F%98%E9%87%8F%E8%BF%9B%E9%98%B6/:1:1","tags":["Ansible"],"title":"Ansible变量进阶","uri":"/ansible%E5%8F%98%E9%87%8F%E8%BF%9B%E9%98%B6/"},{"categories":["Ansible"],"content":"1.0.2 通过定义变量文件进行使用 定义一个名字为public_vars.yaml的变量配置文件 depence: ['openssl-devel','pcre-devel','zlib-devel'] 注意: 当你引用了变量文件中的变量,请在读取变量的时候增加双引号\"\" - hosts: test remote_user: root vars_files: - ./public_vars.yaml - ./public_vars2.yaml # 如果是多个变量的话 tasks: - name: \"Install De\" yum: name: \"{{depence}}\" # 通过双引号去引入变量内容,不然会报错 state: present update_cache: no ","date":"2022-08-15","objectID":"/ansible%E5%8F%98%E9%87%8F%E8%BF%9B%E9%98%B6/:1:2","tags":["Ansible"],"title":"Ansible变量进阶","uri":"/ansible%E5%8F%98%E9%87%8F%E8%BF%9B%E9%98%B6/"},{"categories":["Ansible"],"content":"1.0.3 通过编辑inventory主机清单进定义 这种方法一般用的很少 [test] 10.1.6.205 [test:vars] file_name=group_sys 官方推荐的方法: 在项目目录中创建两个变量目录host_vars和group_vars group_vars mkdir host_vars; mkdir group_vars 创建一个同名文件,用于写入变量内容 必须与hosts清单中的组名保持一致,如果不同名会报错。但是如果你想要多个配置文件使用同一个组中的变量,只需要在group_vars/all新建一个all文件,所有组可用! [root@bogon ~]# cat group_vars/test file_name: group_sys host_vars 在host_vars中创建一个文件,文件名与inventory清单中的主机名称要保持完全一致,如果是IP地址,则创建相同IP地址的文件即可 vim host_vars/10.1.6.205 [root@bogon ~]# cat host_vars/10.1.6.205 file_name: group_sys ","date":"2022-08-15","objectID":"/ansible%E5%8F%98%E9%87%8F%E8%BF%9B%E9%98%B6/:1:3","tags":["Ansible"],"title":"Ansible变量进阶","uri":"/ansible%E5%8F%98%E9%87%8F%E8%BF%9B%E9%98%B6/"},{"categories":["MYSQL"],"content":"MySQL性能优化-优化思路 大概的优化思路分为以下几个内容 PS: 优化是有风险的,如果你要优化就要变更。 硬件层面优化 系统层面优化 MySQL版本选择优化 MySQL三层结构及参数优化 MySQL开发规范 MySQL的索引优化 MySQL的事务以及锁优化 MySQL架构优化 MySQL安全优化 ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:1:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"硬件层面优化 这个地方就略过了就是一些加大硬件配置的需求. ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:2:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"系统层面优化 id: 空闲状态,如果数值越大,表示空闲状态越多。如果可能达到0的情况下,表示当前CPU的核心处于满负荷状态。 us: 表示当前CPU核心数量的使用率。 sy: 表示CPU与内核交互的频率,内核与CPU处理请求的占用,如果此参数高,表示内核很忙。 wa: CPU从内存中刷数据到硬盘中的占用,可能会出现I/O的问题。 [root@mysql-master ~]# top top - 15:05:11 up 35 days, 5:54, 2 users, load average: 0.00, 0.01, 0.05 Tasks: 225 total, 2 running, 223 sleeping, 0 stopped, 0 zombie %Cpu0 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu1 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu2 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu3 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu4 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu5 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu6 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu7 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 24522416 total, 14931524 free, 3675344 used, 5915548 buff/cache KiB Swap: 12386300 total, 12386300 free, 0 used. 20450988 avail Mem 通过 top -Hp 10380 指定占用高的进程,可以看到具体是那些线程占用过高 假设 1893线程占用过高,可以从数据库中查看performance_schema库中具体的信息 定位操作系统线程-\u003e从系统线程中定位数据库线程 *************************** 38. row *************************** THREAD_ID: 128014 NAME: thread/sql/one_connection TYPE: FOREGROUND PROCESSLIST_ID: 127988 PROCESSLIST_USER: ooooo PROCESSLIST_HOST: 192.168.0.1 PROCESSLIST_DB: test PROCESSLIST_COMMAND: Sleep PROCESSLIST_TIME: 104 PROCESSLIST_STATE: NULL PROCESSLIST_INFO: ** PARENT_THREAD_ID: NULL ROLE: NULL INSTRUMENTED: YES HISTORY: YES CONNECTION_TYPE: SSL/TLS THREAD_OS_ID: 16165 *************************** 39. row *************************** ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:3:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"如果可能存在的是IO问题 查询MySQL中的sys库中存在记录IO的表 如果存在IO问题： 可以选择用内存换取时间的方法.. mysql\u003e use sys mysql\u003e show tables; | x$io_by_thread_by_latency | | x$io_global_by_file_by_bytes | | x$io_global_by_file_by_latency | | x$io_global_by_wait_by_bytes | | x$io_global_by_wait_by_latency | ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:3:1","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"MySQL版本选择优化 在这里…笔者非常推荐MySQL8.0x!!! 同样的机器,8.0比5.7快2.5倍左右吧 选择稳定版,选择开源社区的稳定版和GA版本 选择MySQL数据库GA版本发布后6-12个月的GA双数版本 要选择开发兼容的MySQL版本 ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:4:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"MySQL三层结构及参数优化 ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:5:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"连接层优化 一切根据自己或者项目需要自由设置吧! max_connections = 1000 max_connect_errors = 999999 wait_timeout = 600 interactive_wait_timeout = 3600 net_read_timeout = 120 new_write_timeout = 120 max_allowed_packet = 500M ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:5:1","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"Server层优化 一切根据自己或者项目需要自由设置吧! sort_buffer_size = 8M sql_safe_updates = 1 slow_query_log = 1 long_query_time = 1 slow_query_log_file = /data/mysql/mysql-slow.log log_queries_not_using_indexes = 10 read_buffer_size = 2M read_rnd_buffer_size = 8M sort_buffer_size = 8M join_buffer_size = 8M key_buffer_size = 16M max_binlog_size = 500M max_execution_time = 28800 log_timestamps = SYSTEM init_connect = \"set names utf8mb4\" binlog_format = ROW event_scheduler = OFF lock_wait_timeout = sync_binlog = 1 ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:5:2","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"Engine层优化 一切根据自己或者项目需要自由设置吧! transaction-isolation = \"READ-COMMITIED\" innodb_data_home_dir = /xxx innodb_log_group_home_dir = /xxx innodb_log_file_size = 2048M innodb_log_files_in_group = 3 innodb_flush_log_at_trx_commit = 2 innodb_flush_method = O_DIRECT innodb_io_capacity = 1000 innodb_io_capacity_max = 4000 innodb_buffer_pool_size = 64G innodb_buffer_pool_instances = 4 innodb_log_buffer_size = 64M innodb_max_dirty_pages_pct = 85 ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:5:3","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"全局锁读Global Read Lock (GRL） 加锁方法：FTWRL,flush tables with read lock. 解锁方法：unlock tables； 可能出现的场景 记录binlog日志-\u003e不让所有事务提交 FTWRL-\u003e不让新的修改进入 snapshot innodb-\u003e 允许所有的DML语句,但是不允许DDL 属于类型: MDL(matedatalock)层面锁 影响情况: 加锁的期间,阻塞所有事务的写入,阻塞所有事务的commit,时间受到lock_wait_timeout=315336000 ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:6:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"全局读锁的排查方法 MySQL [(none)]\u003e USE performance_schema MySQL [performance_schema]\u003e # 5.6需要手动开启 MySQL [performance_schema]\u003e UPDATE setup_instruments SET ENABLED = \"YES\",TIMED = \"YES\" WHERE NAME='wait/lock/metadata/sql/mdl'; # 查看是否有阻塞问题 MySQL [performance_schema]\u003e SELECT * FROM metadata_locks; mysql\u003e SELECT OBJECT_SCHEMA,OBJECT_NAME,LOCK_TYPE,LOCK_DURATION,LOCK_STATUS,OWNER_THREAD_ID,OWNER_EVENT_ID FROM performance_schema.metadata_locks; ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:6:1","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"5.7版本全局读锁排查 mysql\u003e SHOW proceslist\\G; mysql\u003e SELECT * FORM sys.schema_table_lock_waits; ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:6:2","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"经典故障案例 假设模拟一个大的查询或者事物 模拟备份时的TWRL,此时会发现命令阻塞 发起正常查询请求,发现查询被阻塞 5.7版本的Xbackup/mysqldump备份数据库出现锁表状态,所有的查询不能正常进行. SELECT *,SLEEP(100) FORM `user` WHERE username = 'test1' for update; flush tables with read lock; SELECT * FROM icours.user where username = 'test' for update ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:6:3","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"Table Lock(表级锁) 加锁方式: lock table t1 read; 所有会话只读,属于MDL锁。lock table write; 当前会话可以可以RW,属于MDL锁. SELECT FOR UPDATE; SELECT FOR SHARE 解锁方式: unlock tables; ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:7:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"检测方式 [mysqld] performance-schema-instrument = 'wait/lock/metadata/sql/mdl=ON' SELECT * FROM performance_schema.metadata_locks; SELECT * FROM performance_schema.threads; ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:7:1","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"MetaDataLock(元数据锁) 作用范围: global、commit、tablespace、schema、table 默认时间： lock_wait_timeout mysql\u003e select @@lock_wait_timeout; +---------------------+ | @@lock_wait_timeout | +---------------------+ | 31536000 | +---------------------+ 1 row in set (0.00 sec) ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:8:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"检测方式 [mysqld] performance-schema-instrument = 'wait/lock/metadata/sql/mdl=ON' SELECT * FROM performance_schema.metadata_locks; // 找到阻塞的Id OWNER_THREAD_ID = 12 mysql\u003e SELECT * FROM threads where thread_id = '12'\\G; kill 12; ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:8:1","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"AutoincLock(自增锁) 通过参数: innodb_autoinc_lock_mod = 0 | 1 | 2 0 表锁：每次插入都请求表锁,效率低下 1 mutex： 预计插入多少行,预申请自增序列.如果出现load或者insert select方式会退化为0。 2 : 强制使用mutex的方式,并发插入会更高效！ ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:9:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"Innodb Row Lock(行级锁) record lock、gap、next、lock MySQL [(none)]\u003e SHOW STATUS LIKE 'innodb_row_lock'; MySQL [information_schema]\u003e SELECT * FROM information_schema.innodb_trx; MySQL [information_schema]\u003e SELECT * FORM sys.schema_table_lock_waits; MySQL [information_schema]\u003e SELECT * FROM performance_schema.threads; MySQL [information_schema]\u003e SELECT * FROM performance_schema.events_statements_current; MySQL [information_schema]\u003e ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:10:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"优化方向 优化索引 减少事务的更新范围 RC级别 拆分语句 // 假设 k1是辅助索引 update t1 set num=num+10 where k1\u003c100; // 改为 select id from t1 where k1\u003c100; update t1 set num=num+10 where id in (20,30,50) ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:10:1","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["MYSQL"],"content":"Dead Lock死锁 dead lock 多个并发事务之间发生交叉依赖的时候,会出现死锁. SHOW ENGINE innodb STATUS\\G; innodb_print——all_deadlocks =1 // 开启记录死锁日志 ","date":"2022-07-20","objectID":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/:11:0","tags":["MYSQL"],"title":"MySQL全面优化思路-基础内容","uri":"/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96/"},{"categories":["Docker"],"content":" 总结了一下平常Docker常见的错误处理,大概二十几个左右。 ","date":"2022-07-04","objectID":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/:0:0","tags":["Docker","Linux"],"title":"Docker常见的几个问题处理","uri":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"categories":["Docker"],"content":"Docker迁移存储目录 问题起因 由于公司最开始的服务器在/var/lib/docker没有挂载存储,容量只有40G,导致服务器磁盘用满。现将原有的Docker目录数据进行迁移。 请各位Kubernetes用户不要操作,因为容器编排不支持!\" # 启动容器发现如下报错 ERROR：cannot create temporary directory! ","date":"2022-07-04","objectID":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/:1:0","tags":["Docker","Linux"],"title":"Docker常见的几个问题处理","uri":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"categories":["Docker"],"content":"方法一: 软连接方式 # 1.停止docker服务 systemctl stop docker # 2.开始迁移目录 mv /var/lib/docker /data/ # 使用cp命令也可以 cp -arv /var/lib/docker /data/docker # 3.添加软链接 ln -s /data/docker /var/lib/docker # 4.启动docker服务 systemctl start docker ","date":"2022-07-04","objectID":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/:1:1","tags":["Docker","Linux"],"title":"Docker常见的几个问题处理","uri":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"categories":["Docker"],"content":"方法二: 修改docker配置文件 vim /etc/docker/daemon.json { \"graph\": [ \"/data/docker/\" ] # 更改docker镜像的存储目录 } ","date":"2022-07-04","objectID":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/:1:2","tags":["Docker","Linux"],"title":"Docker常见的几个问题处理","uri":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"categories":["Docker"],"content":"Docker存储空间不足 ","date":"2022-07-04","objectID":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/:2:0","tags":["Docker","Linux"],"title":"Docker常见的几个问题处理","uri":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"categories":["Docker"],"content":"问题一: No space left on device 问题描述：docker run 的时候系统提示No space left on device! 这个问题无非就两种情况 一种是磁盘满了 一种是磁盘inode满了 因为 ext3 文件系统使用 inode table 存储 inode 信息，而 xfs 文件系统使用 B+ tree 来进行存储。考虑到性能问题，默认情况下这个 B+ tree 只会使用前 1TB 空间，当这 1TB 空间被写满后，就会导致无法写入 inode 信息，报磁盘空间不足的错误。我们可以在 mount 时，指定 inode64 即可将这个 B+ tree 使用的空间扩展到整个文件系统。 # 查看inde信息 df -i # 删除过多的小文件即可 Filesystem Inodes IUsed IFree IUse% Mounted on /dev/sda3 593344 56998 536346 10% / tmpfs 238282 1 238281 1% /dev/shm /dev/sda1 51200 39 51161 1% /boot /tmp/1m 128 128 0 100% /app/logs 如果不知道小文件如何查找 # 查找系统中 目录大小大于1M（目录一般大小为4K，所以目录要是大了那么文件必然很多） find / -size +4k -type d |xargs ls -ldhi 如果是硬盘空间满了的话 # 查看磁盘使用容量 df -h # 查看到具体哪个目录满了,然后配合 du -sh命令解决即可 Filesystem Size Used Avail Use% Mounted on /dev/sda3 8.8G 8.8G 0 100% / tmpfs 931M 0 931M 0% /dev/shm /dev/sda1 190M 40M 141M 22% /boot ","date":"2022-07-04","objectID":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/:2:1","tags":["Docker","Linux"],"title":"Docker常见的几个问题处理","uri":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"categories":["Docker"],"content":"优雅地重启Docker 不停止重启,重启docker是一件多么美妙的事情! 当 Docker 守护程序终止时，它会关闭正在运行的容器。从 Docker-ce 1.12 开始，可以在配置文件中添加 live-restore 参数，以便在守护程序变得不可用时容器保持运行。需要注意的是 Windows 平台暂时还是不支持该参数的配置。 vim /etc/docker/daemon.json { \"live-restore\": true } 在守护进程关闭的时候保持容器运行 # 重载docker服务 systemctl reload docker.service [root@VM-0-9-centos ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e58a220f03c3 nginx \"/docker-entrypoint.…\" 5 minutes ago Up 15 seconds 80/tcp web # 这个时候重启docker服务,web服务并没有停止工作 [root@VM-0-9-centos ~]# systemctl restart docker [root@VM-0-9-centos ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e58a220f03c3 nginx \"/docker-entrypoint.…\" 7 minutes ago Up About a minute 80/tcp web ","date":"2022-07-04","objectID":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/:3:0","tags":["Docker","Linux"],"title":"Docker常见的几个问题处理","uri":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"categories":["Docker"],"content":"live-restore的限制 当前的Live Restore特性可以在进行Daemon维护，或者在Daemon发生问题导致不可用的情况，减少容器的停机时间，不过其也有一定的限制。 Docker版本升级限制 Live Restore仅支持Docker补丁版本升级时可用，也就是 YY.MM.x 最后一位发生变化的升级，而不支持大版本的升级。在进行大版本升级后，可能会导致Daemon无法重新连接到运行中容器的问题，这时候需要手动停止运行的容器。 Daemon选项变更 也就是说Live Restore仅仅在某些Daemon级别的配置选项不发生改变的情况工作，例如Bridge的IP地址，存储驱动类型等。如果在重启Daemon时候，这些选项发生了改变，则可能会到Daemon无法重新连接运行中的容器，这时也需要手动停止这些容器。 影响容器的日志输出 如果Daemon长时间停止，会影响运行容器的日志输出。因为默认情况下，日志管道的缓冲区大小为64k，当缓冲写满之后，必须启动Daemon来刷新缓冲区。 不支持Docker Swarm Live Restore只是独立Docker引擎的特性，而Swarm的服务是由Swarm管理器管理的。当Swarm管理器不可用时，Swarm服务是可以在工作节点上继续运行的，只是不同通过Swarm管理器进行管理，直到Swarm管理恢复工作。 ","date":"2022-07-04","objectID":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/:3:1","tags":["Docker","Linux"],"title":"Docker常见的几个问题处理","uri":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"categories":["Docker"],"content":"容器内部中文异常 问题描述: 容器内部中文乱码、无法正常显示中文、 例如显示中文：--------��� # 查看容器内部编码 root@e58a220f03c3:/# locale -a C C.UTF-8 POSIX 然而 POSIX 字符集是不支持中文的，而 C.UTF-8 是支持中文的只要把系统中的环境 LANG 改为 \"C.UTF-8\" 格式即可解决问题。同理，在 K8S 进入 pod 不能输入中文也可用此方法解决。 export LANG=zh_CN.UTF-8 ","date":"2022-07-04","objectID":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/:4:0","tags":["Docker","Linux"],"title":"Docker常见的几个问题处理","uri":"/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/"},{"categories":["MySQL"],"content":" 本章内容针对tortoise-orm进行多对多关系的数据分析 ","date":"2022-06-25","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%85%B3%E7%B3%BB-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB/:0:0","tags":["MySQL","FastAPI"],"title":"数据库表关系之-多对多关系","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%85%B3%E7%B3%BB-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB/"},{"categories":["MySQL"],"content":"简单的多对多关系介绍 如上ER图中看到了我们的三张表：分别是access、role、user(user这张表我没放上去). 多对多关系: role角色表的一条记录能够对应另外一张user用户表中的多条记录，同时user表中的一条记录也能对应role表中的多条记录,被称之为我们的多对多关系。 在tortoise-orm的ManyToManyRelation关系中,默认是使用pk字段作为关联字段的 class ManyToManyRelation(ReverseRelation[MODEL]): \"\"\" Many to many relation container for :func:`.ManyToManyField`. \"\"\" def __init__(self, instance: \"Model\", m2m_field: \"ManyToManyFieldInstance\") -\u003e None: super().__init__(m2m_field.related_model, m2m_field.related_name, instance, \"pk\") # type: ignore self.field = m2m_field self.instance = instance 表结构如下 # 角色表 class Role(TimestampMixin): role_name = fields.CharField(max_length=15, description=\"角色名称\") user: fields.ManyToManyRelation[\"User\"] = fields.ManyToManyField(\"base.User\", related_name=\"role\", on_delete=fields.CASCADE) access: fields.ManyToManyRelation[\"Access\"] = fields.ManyToManyField(\"base.Access\", related_name=\"role\", on_delete=fields.CASCADE) role_status = fields.BooleanField(default=False, description=\"True:启用 False:禁用\") role_desc = fields.CharField(null=True, max_length=255, description='角色描述') class Meta: table_description = \"角色表\" table = \"role\" # 用户表 class User(TimestampMixin): role: fields.ManyToManyRelation[Role] username = fields.CharField(unique=True, null=False, min_length=5, max_length=32, description=\"用户名\") password = fields.CharField(null=False,min_length=8,max_length=255) mobile_phone = fields.CharField(unique=True, null=False, description=\"手机号\", max_length=11) email = fields.CharField(unique=True, null=False, description='邮箱', max_length=32) full_name = fields.CharField(null=True, description='姓名', max_length=15) is_activate = fields.BooleanField(default=0, description='0未激活 1正常 2禁用') is_staff = fields.BooleanField(default=False, description=\"用户类型 True:超级管理员 False:普通管理员\") header_img = fields.CharField(null=True, max_length=255, description='用户头像') sex = fields.IntField(default=0, null=True, description='0未知 1男 2女') login_host = fields.CharField(null=True, max_length=15, description=\"访问IP\") # 返回用户名默认 def __str__(self): return self.username class Meta: table_description = \"用户表\" table = \"user\" # 权限表 class Access(TimestampMixin): role: fields.ManyToManyRelation[Role] access_name = fields.CharField(max_length=15, description=\"权限名称\") parent_id = fields.IntField(default=0, description='父id') scopes = fields.CharField(unique=True, max_length=255, description='权限范围标识') access_desc = fields.CharField(null=True, max_length=255, description='权限描述') menu_icon = fields.CharField(null=True, max_length=255, description='菜单图标') is_check = fields.BooleanField(default=False, description='是否验证权限 True为验证 False不验证') is_menu = fields.BooleanField(default=False, description='是否为菜单 True菜单 False不是菜单') def __str__(self): return self class Meta: table_description = \"权限表\" table = \"access\" ","date":"2022-06-25","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%85%B3%E7%B3%BB-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB/:0:1","tags":["MySQL","FastAPI"],"title":"数据库表关系之-多对多关系","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%85%B3%E7%B3%BB-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB/"},{"categories":["MySQL"],"content":"根据ER图进行关系分析 tortoise-orm维护多对多的表关系才用的是中间表的形式,通过related_name来生成表中间表前缀. 角色对用户 一个角色可以对应多个用户 系统管理员角色可以对应多个用户： 张三是管理员、李四是管理员、王五也是管理员。多个用户对应的同时都是系统管理员的角色。 兄弟们: 以后在更新,torroise-orm这个多对多关系的查询我真是搞得不太明白… ","date":"2022-06-25","objectID":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%85%B3%E7%B3%BB-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB/:0:2","tags":["MySQL","FastAPI"],"title":"数据库表关系之-多对多关系","uri":"/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%85%B3%E7%B3%BB-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB/"},{"categories":["Ansible"],"content":" playbook是由一个或多个\"play\"组成的列表 playbook的主要功能在于将预定义的一组主机，装扮成事先通过ansible中的task定义好的角色。 Task实际是调用ansible的一个module，将多个play组织在一个playbook中， 即可以让它们联合起来，按事先编排的机制执行预定义的动作 Playbook采用YAML语言编写 --- - hosts: test # 指定主机列表 remote_user: root # 远程操作以什么身份执行 tasks: - name: Install Redis # 提示字段,表示当前处于什么进度 command: install redis # 当前执行的具体命令操作 ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:0:0","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"1.0 PlayBook核心元素 Hosts：playbook中的每一个play的目的都是为了让特定主机以某个指定的用户身份执行任务,hosts用于指定要执行指定任务的主机，须事先定义在主机清单中. 详细请看 remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务.此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户. varniables: 内置变量或自定义变量在playbook中调用 Templates模板 : 可替换模板文件中的变量并实现一些简单逻辑的文件 Handlers和notify: 结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行 tags: 指定某条任务执行，用于选择运行playbook中的部分代码. ansible-playbook -C hello.yaml -C 选项检查剧本是否成功,并不实际执行 ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:1:0","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"1.0.1 忽略错误信息 也可以使用ignore_errors来忽略错误信息 tasks: - name: run this shell: /usr/bin/ls || /bin/true ignore_errors: True ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:1:1","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"1.0.2 常用选项 --check: 只检测可能会发生的改变,但是不会执行 --list-hosts: 列出运行任务的主机 --limit: 主机列表,只针对主机列表中的主机执行 -v: 显示过程 --list-tasks: 查看任务列表 ansible-playbook hello.yaml --check ansible-playbook hello.yaml --list-hosts ansible-playbook hello.yaml --limit 10.1.6.111 ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:1:2","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"2.0 Handlers和notify 由于playbook执行会有次序问题,所以当出现次序问题的时候,可以使用handlers结合notify Handlers: 是task列表,这些task与前述的task没有本质的区别,用于当不同的资源发生变化的时候,才会采取一定的操作. Notify: 此action可以用在每个play的最后被触发,这样可以避免多次有改变的发生时每次都执行指定的操作,仅仅在所有变化发生完后,一次性执行制定操作,在notify中列出的操作称为hendler，也就是notify中定义的操作. Handlers和notify可以写多个 --- - hosts: test remote_user: root tasks: - name: \"create new file\" file: name=/data/newfile state=touch - name: \"create new user\" user: name=test2 system=yes shell=/sbin/nologin - name: \"install httpd\" yum: name=httpd state=installed notify: restart service # 表示执行完yum操作以后需要执行handlers的操作 - name: \"copy log\" copy: src=/var/log/httpd/error_log dest=/data handlers: - name: restart service service: name=httpd state=restarted ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:2:0","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"3.0 PlayBook的tags使用 给特定的内容打上tags可以单独的执行标签内容 --- - hosts: test remote_user: root tasks: - name: \"create new file\" file: name=/data/newfile state=touch tags: newfile - name: \"create new user\" user: name=test2 system=yes shell=/sbin/nologin tags: newuser - name: \"install httpd\" yum: name=httpd state=installed notify: restart service # 表示执行完yum操作以后需要执行handlers的操作 - name: \"copy log\" copy: src=/var/log/httpd/error_log dest=/data handlers: - name: restart service service: name=httpd state=restarted ansible-playbook -t newfile test.yaml # 表示只执行newfile标签的动作 ansible-playbook -t newfile,newuser test.yaml # 表示只执行newfile标签的动作 ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:3:0","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"4.0 PlayBook中变量的使用 变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量的来源 通过setup模块 在/etc/ansible/hosts中定义 普通变量：主机组中的主机单独定义,优先级高于公共变量 公共变量：针对主机组所有主机定义统一变量 通过命令行指定变量： 优先级最高 ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:4:0","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"4.0.1 通过命令行指定变量 --- - hosts: test remote_user: root tasks: - name: \"create new file\" file: name=/data/{{filename}} state=touch tags: newfile ansible-playbook -e 'filename=app1' # /data/app1 ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:4:1","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"4.0.2 在playbook中定义 # 在playbook中定义 --- - hosts: test remote_user: root vars: - filename: app1 tasks: - name: \"create new file\" file: name=/data/{{filename}} state=touch tags: newfile ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:4:2","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"4.0.3 通过setup模块获取变量 ansible setup facts 远程主机的所有变量都可直接调用 (系统自带变量) setup模块可以实现系统中很多系统信息的显示 ansible all -m setup -a 'filter=\"ansible_nodename\"' 查询主机名 ansible all -m setup -a 'filter=\"ansible_memtotal_mb\"' 查询主机内存大小 ansible all -m setup -a 'filter=\"ansible_distribution_major_version\"' 查询系统版本 ansible all -m setup -a 'filter=\"ansible_processor_vcpus\"' 查询主机cpu个数 ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:4:3","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"4.0.4 在hosts中定义变量 定义主机组单独的变量 [test] 192.168.1.1 http_port=81 192.168.1.2 http_port=82 --- - hosts: test remote_user: root tasks: - name: \"create new file\" hostname: name=www{{http_port}}.baidu.com 定义公共变量 # 针对test主机组当中的所有主机都有效 [test:vars] nodename=www domain=baidu.com ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:4:4","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"4.0.5 通过文件加载变量 # vars.yaml filename: applications # playbook.yaml - hosts: test remote_user: root vars_files: - vars.yaml tasks: - name: \"create new file\" file: name=/data/{{filename}} ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:4:5","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"5.0 模板Templates 采用Jinja2语言，使用字面量，有下面形式 数字：整数，浮点数 列表：[item1, item2, …] 元组：(item1, item2, …) 字典：{key1:value1, key2:value2, …} 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, \u003e, \u003e=, \u003c, \u003c= 逻辑运算：and，or，not 流表达式：For，If，When # For more information on configuration, see: # * Official English Documentation: http://nginx.org/en/docs/ # * Official Russian Documentation: http://nginx.org/ru/docs/ user nginx; worker_processes {{ansible_processor_vcpus**2}}; # 例如,你可以将nginx核心数动态的设置为主机的CPU数量 error_log /var/log/nginx/error.log; pid /run/nginx.pid; ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:5:0","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"5.0.1 When语法 条件测试:如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试, 通过when语句实现，在task中使用，jinja2的语法格式 在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法 当ansible_distribution=CentOS的时候才会去执行template --- - hosts: test remote_user: root tasks: - name: \"Install Nginx\" yum: name=nginx - name: Config conf template: src=/templates/nginx.conf.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution == \"CentOS\" - name: start nginx service: name=nginx state=started enabled=yes ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:5:1","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"5.0.2 With_item 迭代写法 --- - hosts: test remote_user: root tasks: - name: \"Create new file\" file: name=/data/{{items}} state=touch with_items: - app1 - app2 - app3 迭代嵌套子变量 - hosts: test remote_user: root tasks: - name: \"Create new file\" file: name=/data/{{item.name}}_{{item.date}} state=touch with_items: - {name: 'app1', date: '2022'} ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:5:2","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"5.0.3 for循环 --- - hosts: test remote_user: root vars: ports: - 81 - 82 - 83 tasks: - name: copy template template: src=/root/templates/for.j2 dest=/data/for.conf # 或者 --- - hosts: test remote_user: root vars: ports: - listen:81 - listen:82 - listen:83 tasks: - name: copy template template: src=/root/templates/for.j2 dest=/data/for.conf # 或者 --- - hosts: test remote_user: root vars: config: - host1: port: 81 name: host1.do.com rootdir: /root/ tasks: - name: copy template template: src=/root/templates/for.j2 desc=/data/for.conf 创建一个模板文件 {%for i in ports%} server { listen {{i}} } {%endfor%} # 或者 {%for i in ports%} server { listen {{i.listen}} } {%endfor%} # 或者 {%for i in ports%} server { listen {{ i.port }} name {{ i.name }} } {%endfor%} ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:5:3","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Ansible"],"content":"5.0.4 if判断 {%for i in ports%} server { listen {{ i.port }} {% if i.name is defind %} name {{ i.name }} {% endif %} } {%endfor%}a ","date":"2022-04-01","objectID":"/playbook%E8%AF%A6%E8%A7%A3/:5:4","tags":["Linux","Ansible"],"title":"Ansible-Playbook","uri":"/playbook%E8%AF%A6%E8%A7%A3/"},{"categories":["Redis"],"content":"缓存穿透 简单地就是用户请求透过redis直接进入到mysql当中进行查询，通常是一个不存在的key,在数据库查询为null。每次请求落在数据库、并且高并发。数据库扛不住会挂掉。 当用户的请求进入到Redis当中的时候,Redis当中并没有用户查询的键。 Redis会告诉用户没有查询到此Key，随后请求会被直接转发到后台MySQL当中 MySQL当中自然也不会存在此键值对,所以当大量的请求落在MySQL当中则会导致数据库宕机 ","date":"2022-03-24","objectID":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/:1:0","tags":["Redis"],"title":"Redis缓存击穿、雪崩、穿透","uri":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"},{"categories":["Redis"],"content":"解决缓存穿透的方案 可以将查到的null设成该key的缓存对象。 当然，也可以根据明显错误的key在逻辑层就就行验证。 同时，你也可以分析用户行为，是否为故意请求或者爬虫、攻击者。针对用户访问做限制。 其他等等，比如用布隆过滤器(超大型hashmap)先过滤。 ","date":"2022-03-24","objectID":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/:1:1","tags":["Redis"],"title":"Redis缓存击穿、雪崩、穿透","uri":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"},{"categories":["Redis"],"content":"缓存雪崩 和雪崩一样。在这里，就是redis缓存集体大规模集体失效，在高并发情况下突然使得key大规模访问mysql，使得数据库崩掉。 ","date":"2022-03-24","objectID":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/:2:0","tags":["Redis"],"title":"Redis缓存击穿、雪崩、穿透","uri":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"},{"categories":["Redis"],"content":"解决缓存雪崩 通常的解决方案是将key的过期时间后面加上一个随机数，让key均匀的失效。 考虑用队列或者锁让程序执行在压力范围之内，当然这种方案可能会影响并发量。 热点数据可以考虑不失效 ","date":"2022-03-24","objectID":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/:2:1","tags":["Redis"],"title":"Redis缓存击穿、雪崩、穿透","uri":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"},{"categories":["Redis"],"content":"缓存击穿 缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库。 击穿和穿透不同，穿透的意思是想法绕过redis去使得数据库崩掉。而击穿你可以理解为正面刚击穿,这种通常为大量并发对一个key进行大规模的读写操作。这个key在缓存失效期间大量请求数据库，对数据库造成太大压力使得数据库崩掉。就比如在秒杀场景下10000块钱的mac和100块的mac这个100块的那个订单肯定会被抢到爆，不断的请求(当然具体秒杀有自己处理方式这里只是举个例子)。所以缓存击穿就是针对某个常用key大量请求导致数据库崩溃。 ","date":"2022-03-24","objectID":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/:3:0","tags":["Redis"],"title":"Redis缓存击穿、雪崩、穿透","uri":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"},{"categories":["Redis"],"content":"解决缓存击穿 可以使用互斥锁避免大量请求同时落到db。 布隆过滤器，判断某个容器是否在集合中 可以将缓存设置永不过期(适合部分情况) 做好熔断、降级，防止系统崩溃。 ","date":"2022-03-24","objectID":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/:3:1","tags":["Redis"],"title":"Redis缓存击穿、雪崩、穿透","uri":"/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"},{"categories":["Linux"],"content":" yum -y install libevent-devel openssl-devel ","date":"2022-03-20","objectID":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/:0:0","tags":["Linux"],"title":"Coturn穿透服务器搭建","uri":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"1.1下载编译安装coturn git clone https://github.com/coturn/coturn cd coturn ./configure --prefix=/usr/local/coturn make install ","date":"2022-03-20","objectID":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/:0:1","tags":["Linux"],"title":"Coturn穿透服务器搭建","uri":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"1.2查看是否安装成功 which turnserver ","date":"2022-03-20","objectID":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/:0:2","tags":["Linux"],"title":"Coturn穿透服务器搭建","uri":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"1.3配置文件 安装目录位于/usr/local/coturn cd /usr/local/coturn/etc/ cp turnserver.conf.default turnserver.conf ","date":"2022-03-20","objectID":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/:0:3","tags":["Linux"],"title":"Coturn穿透服务器搭建","uri":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"1.4 配置证书 openssl req -x509 -newkey rsa:2048 -keyout ./turn_server_pkey.pem -out ./etc/turn_server_cert.pem -days 99999 -nodes 生成的证书默认放在./当前目录 可以通过pwd进行查看 ","date":"2022-03-20","objectID":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/:0:4","tags":["Linux"],"title":"Coturn穿透服务器搭建","uri":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"1.5修改配置信息 vim /usr/local/coturn/etc/turnserver.conf relay-device=eth0 # 与前nmcli查到的网卡名称一致 listening-ip=192.168.1.10 # 内网IP listening-port=3478 tls-listening-port=5349 relay-ip=172.18.77.60 external-ip=xxx.xxx.xxx.xxx # 公网IP relay-threads=50 lt-cred-mech cert=./turn_server_cert.pem pkey=./turn_server_pkey.pem pidfile=”/var/run/turnserver.pid” min-port=49152 max-port=65535 user=users:123.com # 用户名密码，创建IceServer时用 cli-password=123.com ","date":"2022-03-20","objectID":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/:0:5","tags":["Linux"],"title":"Coturn穿透服务器搭建","uri":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"1.6 启动turnserver turnserver -o -a -f -user=users:123.com -r Beijing 千万注意，如果你是阿里云服务器直接去安全组里面放行TCP/UDP 3478端口即可,下面操作是给本地内网测试做的 firewall-cmd --zone=public --add-port=3478/udp --permanent firewall-cmd --zone=public --add-port=3478/tcp --permanent 重新载入 firewall-cmd --reload 重启防火墙 systemctl restart firewalld 或者 systemctl stop firewalld ","date":"2022-03-20","objectID":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/:0:6","tags":["Linux"],"title":"Coturn穿透服务器搭建","uri":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"ICE测试 地址 https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/ ","date":"2022-03-20","objectID":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/:0:7","tags":["Linux"],"title":"Coturn穿透服务器搭建","uri":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"网页配置如下 # stun:xxx.xxx.xxx.xxx:3478 # users # 123.com ","date":"2022-03-20","objectID":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/:0:8","tags":["Linux"],"title":"Coturn穿透服务器搭建","uri":"/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"1.0 准备条件 准备如下： filebeat-6.3.2 elasticsearch-6.3.2 kibana-6.3.2 logstash-6.3.2 内存3GB以上,elasticsearch这东西太吃内存了,实验环境建议内存给到4G. 官网地址 https://www.elastic.co/cn/elasticsearch/ 如果你嫌弃官网下载的太慢,可以使用以下微云地址下载 https://share.weiyun.com/fnAz5I2f 版本最好是和我这个一致吧 教程是老教程了,微云这会儿也限速了 - 2022-03-21 ","date":"2022-03-20","objectID":"/elasticsearch-kibana-logstash%E9%83%A8%E7%BD%B2/:1:0","tags":["Linux","Elasticsearch"],"title":"Elasticsearch+kibana+Logstash部署","uri":"/elasticsearch-kibana-logstash%E9%83%A8%E7%BD%B2/"},{"categories":["Linux"],"content":"2.0 搭建Elasticsearch 2.0.1 准备JDK环境 下载JDK8 # 解压并且移动jdk目录 [root@MySQL8 ~]# tar -zxf jdk-8u201-linux-x64.tar.gz [root@MySQL8 ~]# mv jdk1.8.0_201/ /usr/local/java # 设置java的环境变量 echo ' export JAVA_HOME=/usr/local/java export JRE_HOME=/usr/local/java/jre export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin ' \u003e\u003e /etc/profile [root@MySQL8 ~]# source /etc/profile # 加载profile使其生效 # 检测配置的java环境变量是否生效 [root@MySQL8 ~]# java -version # 使用java -verison出现版本信息 java version \"1.8.0_201\" Java(TM) SE Runtime Environment (build 1.8.0_201-b09) Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode) 2.0.2 部署Elasticsearch单机版 [root@localhost ~]# tar -zxf elasticsearch-6.3.2.tar.gz [root@localhost ~]# mv elasticsearch-6.3.2 /usr/local/elasticsearch-6.3.2 [root@localhost ~]# cd /usr/local/elasticsearch-6.3.2/config/ [root@localhost ~]# vim elasticsearch.yml 修改以下内容 # 有注释的把注释取消,没有注释的手动添加 # ---------------------------------- Cluster ----------------------------------- cluster.name: my-application # ------------------------------------ Node ------------------------------------ node.name: node-1 node.data: true node.master: true # ----------------------------------- Paths ------------------------------------ # 日志目录和数据目录 path.data: /usr/local/elasticsearch-6.3.2/data path.logs: /usr/local/elasticsearch-6.3.2/logs # ---------------------------------- Network ----------------------------------- network.host: 192.168.231.60 # 本机ip的地址 http.port: 9200 # 端口为9200 http.cors.enabled: true http.cors.allow-origin: \"*\" # --------------------------------- Discovery ---------------------------------- discovery.zen.minimum_master_nodes: 1 2.0.3 安装Kibana [root@localhost ~]# tar -zxf kibana-6.3.2-linux-x86_64.tar.gz [root@localhost ~]# mv kibana-6.3.2 /usr/local/kibana-6.3.2 [root@localhost ~]# cd /usr/local/kibana-6.3.2/config/ [root@localhost ~]# vim kibana.yml 修改以下内容 # Kibana is served by a back end server. This setting specifies the port to use. server.port: 15601 # Kibana的web页面端口 # To allow connections from remote users, set this parameter to a non-loopback address. server.host: \"192.168.231.60\" # kibana本机ip地址 # The URL of the Elasticsearch instance to use for all your queries. elasticsearch.url: \"http://192.168.231.60:9200\" # 填写elasticsearch的ip地址 # dashboards. Kibana creates a new index if the index doesn't already exist. kibana.index: \".kibana\" # kibana的索引文件 2.0.4 安装Logstash [root@localhost ~]# tar -zxf logstash-6.3.2.tar.gz [root@localhost ~]# mv logstash-6.3.2 /usr/local/logstash-6.3.2 [root@localhost ~]# cd /usr/local/logstash-6.3.2/config/ [root@localhost config]# vim logstash.yml 修改以下内容 path.config: /usr/local/logstash-6.3.2/config/*.conf # 此目录为logstash安装的目录 config.reload.automatic: true # 配置文件自动加载 config.reload.interval: 3s # 每次加载间隔时间 http.host: \"192.168.231.60\" # 本机IP地址 path.logs: /usr/local/logstash-6.3.2/logs # 日志目录 2.0.5 安装filebeat [root@localhost ~]# tar -zxf filebeat-6.3.2-linux-x86_64.tar.gz [root@localhost ~]# tar -zxf filebeat-6.3.2 /usr/local/filebeat-6.3.2 [root@localhost ~]# cd /usr/local/filebeat-6.3.2/ [root@localhost ~]# vim filebeat.yml 修改以下内容 # 如果添加日志的话记得删除原来的 #=========================== Filebeat inputs ============================= filebeat: prospectors: - type: log # 类型 paths: - /var/log/nginx/access.log #采取的日志目录 tags: true # Change to true to enable this input configuration. enabled: true #----------------------------- Logstash output -------------------------------- output.logstash: # The Logstash hosts hosts: [\"192.168.231.60:5044\"] # logstash默认端口5044 #-------------------------- Elasticsearch output ------------------------------ # output.elasticsearch: //注释 # Array of hosts to connect to. //注释 # hosts: [\"localhost:9200\"] //注释 2.0.6 编写nginx-access.conf [root@localhost bin]# vim /usr/local/logstash-6.3.2/config/nginx-access.conf nginx-access.conf input { beats { port =\u003e 5044 } } output { elasticsearch { hosts =\u003e \"192.168.231.60:9200\" index =\u003e \"nginx-%{+YYYY.MM.dd}\" } } 2.0.7 启动服务 # 启动elasticsear","date":"2022-03-20","objectID":"/elasticsearch-kibana-logstash%E9%83%A8%E7%BD%B2/:2:0","tags":["Linux","Elasticsearch"],"title":"Elasticsearch+kibana+Logstash部署","uri":"/elasticsearch-kibana-logstash%E9%83%A8%E7%BD%B2/"},{"categories":["MYSQL"],"content":"MySQL5.5以后版本的默认存储引擎 支持事物的ACID特性 Innodb使用表空间存储 innodb_file_per_table (如果此参数为ON) 则会创建一个独立的表空间:tablename.ibd 系统表空间:ibdataX(如果参数为OFF) X表示一个数字 演示参数ON mysql\u003e show variables like 'innodb_file_per_table'; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | innodb_file_per_table | ON | +-----------------------+-------+ 1 row in set (0.00 sec) 由此可见 file_per_table是开启的,可以为每一个表创造一个表空间 mysql\u003e create table myinnodb(id int,c1 varchar(40)); # 新建一个表 找的你的数据库下面可以看到 myinnodb.ibd myinnodb.frm 演示参数OFF mysql\u003e set global innodb_file_per_table=OFF; mysql\u003e show variables like \"innodb_file_per_table\"; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | innodb_file_per_table | OFF | +-----------------------+-------+ 1 row in set (0.00 sec) mysql\u003e create table myinnodb1(id int,cid varchar(20))engine=innodb; 查看数据库目录下只有 myinnodb1.frm # 存储的系统表空间 ","date":"2022-03-20","objectID":"/innodb%E5%BC%95%E6%93%8E/:0:0","tags":["MYSQL"],"title":"MySQL常用存储引擎之InnoDB","uri":"/innodb%E5%BC%95%E6%93%8E/"},{"categories":["MYSQL"],"content":"1.0 系统表空间和独立表空间怎么选 比较 系统表空间无法简单的收缩文件大小 独立表空间可以通过optimize table命令收缩文件大小 系统表空间会产生IO瓶颈 独立表空间可以同时向多个文件刷新数据 建议对Innodb使用独立表空间 ","date":"2022-03-20","objectID":"/innodb%E5%BC%95%E6%93%8E/:1:0","tags":["MYSQL"],"title":"MySQL常用存储引擎之InnoDB","uri":"/innodb%E5%BC%95%E6%93%8E/"},{"categories":["MYSQL"],"content":"1.1 如何把原来存在于系统表空间的表转移到独立表空间 步骤 使用mysqldump导出所有数据库表数据 停止mysql服务,修改参数,并删除innodb相关文件 重启mysql服务,重建innodb系统表空间 重新导入数据 注意: Innodb数据字典信息,这种信息还是很重要的 ","date":"2022-03-20","objectID":"/innodb%E5%BC%95%E6%93%8E/:2:0","tags":["MYSQL"],"title":"MySQL常用存储引擎之InnoDB","uri":"/innodb%E5%BC%95%E6%93%8E/"},{"categories":["MYSQL"],"content":"1.3 Innodb存储引擎的特性 Innodb是一种事务性存储引擎 完全支持事物的ACID特性 Redo log和Undo log 查看Redo log大小 以字节为单位 redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。 mysql\u003e show variables like \"innodb_log_buffer_size\"; +------------------------+----------+ | Variable_name | Value | +------------------------+----------+ | innodb_log_buffer_size | 16777216 | +------------------------+----------+ 1 row in set (0.00 sec) cd /var/lib/mysql/ 查看到这个目录下会有两个文件 ib_logfile0 和 ib_logfile1 这是因为默认的redo log的files是2 mysql\u003e show variables like 'innodb_log_files_in_group'; +---------------------------+-------+ | Variable_name |Value | +---------------------------+-------+ | innodb_log_files_in_group | 2 | +---------------------------+-------+ 1 row in set (0.00 sec) Undo log用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。 包括MVCC Innodb支持行级锁 行级锁可以最大程度的支持并发 行级锁由存储引擎层实现 ","date":"2022-03-20","objectID":"/innodb%E5%BC%95%E6%93%8E/:3:0","tags":["MYSQL"],"title":"MySQL常用存储引擎之InnoDB","uri":"/innodb%E5%BC%95%E6%93%8E/"},{"categories":["MYSQL"],"content":"1.4 什么是数据库中的锁 锁的主要作用是管理共享资源的并发访问 锁用于实现事物的隔离性 所保证一个用户写入数据时候另一个用户进行写的时候会被阻塞 锁的类型 共享锁(读锁) 独占锁(写锁) 独占锁以及共享锁演示 begin # 开启一个事务 insert into myinnodb values(3,'bb'); update myinnodb set name='bbbb' where id =2; # 更新name字段的值为bbbb 其实innodb在锁的方面还是比较复杂的 了解即可 加入表级别的独占锁 mysql\u003e lock table myinnodb write; mysql\u003e unlock table; 当存在锁的情况下 select的语句会被阻塞需要进行解锁 锁的粒度 表级锁 通过mysql的服务器层实现 行级锁 阻塞和死锁 阻塞是为了保证并发的正常运行 过多的阻塞会导致数据库的连接进行堆积 死锁是两个或两个以上的事务在执行的过程中占用相互等待的资源导致异常,少量死锁不会有影响 当有大量的死锁就会有问题了 ","date":"2022-03-20","objectID":"/innodb%E5%BC%95%E6%93%8E/:4:0","tags":["MYSQL"],"title":"MySQL常用存储引擎之InnoDB","uri":"/innodb%E5%BC%95%E6%93%8E/"},{"categories":["MYSQL"],"content":"1.5 Innodb状态检查 show engine innodb status # 间隔30s进行采样 主要是包括一些 I/O读写进程 一些配置页 缓存信息 索引等等 *************************** 1. row *************************** Type: InnoDB Name: Status: ===================================== 2020-09-17 23:22:26 0x7f371091e700 INNODB MONITOR OUTPUT ===================================== Per second averages calculated from the last 21 seconds # 21秒的统计值 ","date":"2022-03-20","objectID":"/innodb%E5%BC%95%E6%93%8E/:5:0","tags":["MYSQL"],"title":"MySQL常用存储引擎之InnoDB","uri":"/innodb%E5%BC%95%E6%93%8E/"},{"categories":["MYSQL"],"content":"适用场景 适合于大多数的OLTP应用 ","date":"2022-03-20","objectID":"/innodb%E5%BC%95%E6%93%8E/:6:0","tags":["MYSQL"],"title":"MySQL常用存储引擎之InnoDB","uri":"/innodb%E5%BC%95%E6%93%8E/"},{"categories":["MYSQL"],"content":"MySQL5.5版本之前的默认存储引擎就是MyISAM 系统表 临时表(查询优化器建立的临时表) MyISAM存储引擎表由MYD和MYI组成 ","date":"2022-03-20","objectID":"/myisam/:0:0","tags":["MYSQL"],"title":"MySQL常用存储引擎之MyISAM","uri":"/myisam/"},{"categories":["MYSQL"],"content":"MyISAM的特性 并发性与锁级别 对于读写混合的并发性不会太好 表损坏修复 通过 check table tablename 进行检查 通过 repair table tablename 进行恢复 演示实例 use test # 进入你自己的数据库 create table myIsam(id int,c1 varchar(10))engine=myisam; # 需要通过engine指定引擎 cd /var/lib/mysql/test # test是你的库名字 库的位置一般都在你的安装路径下 yum的默认在/var/lib/mysql myIsam_352.sdi myIsam.MYD myIsam.MYI 存储数据信息 存储索引信息 回到mysql的test1库中执行 check table myisam +--------------+-------+----------+------------------------------------+ | Table | Op | Msg_type | Msg_text | +--------------+-------+----------+------------------------------------+ | test1.myisam | check | status | OK | | test1.myisam | check | status | OK | +--------------+-------+----------+------------------------------------+ 接着执行repair table myisam # MyISAM表损坏的时候才有用 MyISAM表支持的索引类型 MyISAM表支持数据压缩 压缩可以使用 演示实例 [root@localhost test]# myisampack -b -f myIsam Compressing myIsam.MYD: (0 records) - Calculating statistics - Compressing file Empty file saved in compressed format # (0 records) 空文件 # 查看文件大小，-f是强制压缩 # myIsam.OLD 压缩之前文件的备份 # 实际上压缩后(MYI)的文件比压缩前(OLD)的文件还要大,因为原来的数据太小了 知识为了演示 对于表中的读写 # 当前myIsam表已经进行压缩了，进行插入操作，结论【对于已经压缩的表是不能进行写操作的，只能读】 mysql\u003e insert into myIsam values(1,'haha'); ERROR 1036 (HY000): Table 'myIsam' is read only 限制 版本\u003c5.0的默认表大小为4Gb 如存储大表则需要修改MAX_Rows和AVG_Row_LENGTH 修改会导致表重建 版本\u003e5.0的默认表大小为256TB ","date":"2022-03-20","objectID":"/myisam/:1:0","tags":["MYSQL"],"title":"MySQL常用存储引擎之MyISAM","uri":"/myisam/"},{"categories":["MYSQL"],"content":"适用场景 非事务型应用 只读类应用 空间类应用(例如GPS 利用空间函数) ","date":"2022-03-20","objectID":"/myisam/:2:0","tags":["MYSQL"],"title":"MySQL常用存储引擎之MyISAM","uri":"/myisam/"},{"categories":["MYSQL"],"content":"1.0 什么是事务 1.事务：事务是数据库系统区别于其他一切文件系统的重要特性之一 2.事务是一组具有原子性的SQL语句,或是一个独立的工作单元 ","date":"2022-03-20","objectID":"/mysql%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%B1%9E%E6%80%A7/:1:0","tags":["MYSQL"],"title":"MySQL的事务属性","uri":"/mysql%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%B1%9E%E6%80%A7/"},{"categories":["MYSQL"],"content":"1.1 MySQL事务的特性 原子性(ATOMICITY)：SQL要么全部执行完成,要么全部失败,不可能执行部分语句。 举个例子 如果要去中国银行向建设银行存钱 查看中国银行中的账户余额是否大于2000元 从中国银行的帐户中转出2000元 在建设银行的账户上增加2000元 如果上面的任何一步拿出来单独执行,后果你懂的…😂 一致性(CONSISTENCY)：数据库的完整性不发生改变 举个例子 不管怎么转钱,总的余额不变 隔离性(ISOLATION)：一个事务对数据库中的数据修改,未提交事务之前对于其他事务不可见 SQL标准的四种隔离级别 未提交读：简称脏读 已提交读：只能看到已提交事物的修改 可重复读：多次读取事物的数据是一致的,包括已提交的事务 可串行化：读取的每一行进行加锁 可能会导致锁超时,除非严格要求数据一致性. 事务持久性(DURABILITY)：一旦事务提交,其所做的修改会永久的存入数据库,即使系统崩溃 数据也不会丢失. ","date":"2022-03-20","objectID":"/mysql%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%B1%9E%E6%80%A7/:2:0","tags":["MYSQL"],"title":"MySQL的事务属性","uri":"/mysql%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%B1%9E%E6%80%A7/"},{"categories":["MYSQL"],"content":"1.2 什么是大事务 运行时间比较长,操作的数据量比较多的事务. 大事务可能会造成的影响 锁定太多的数据,造成大量的阻塞和锁超时 回滚时所需要的时间较长 执行时间长,容易造成主从延迟 ","date":"2022-03-20","objectID":"/mysql%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%B1%9E%E6%80%A7/:3:0","tags":["MYSQL"],"title":"MySQL的事务属性","uri":"/mysql%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%B1%9E%E6%80%A7/"},{"categories":["MYSQL"],"content":"1.3 如何处理大事务 避免一次处理太多的数据 移除不必要在事务中的SELECT操作 做到这两点基本上大事务就解决了 ","date":"2022-03-20","objectID":"/mysql%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%B1%9E%E6%80%A7/:4:0","tags":["MYSQL"],"title":"MySQL的事务属性","uri":"/mysql%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%B1%9E%E6%80%A7/"},{"categories":["MYSQL"],"content":" 分担数据库的读负载 对服务器进行水平扩展 异步复制(无法保证主库和从库的延迟) ","date":"2022-03-20","objectID":"/mysql%E5%A4%8D%E5%88%B6/:0:0","tags":["MYSQL"],"title":"MySQL复制功能介绍","uri":"/mysql%E5%A4%8D%E5%88%B6/"},{"categories":["MYSQL"],"content":"复制解决了什么问题？ 不同服务器上的数据分布 利用二进制日志进行增量备份 不需要太多带宽 但是基于行复制 需要大量的带宽 跨IDC环境下可能有问题 应该进行分批复制 实现数据读取的负载均衡 采用非共享架构 增加数据安全性 减少主库服务器的负载 数据库之间的故障切换 ","date":"2022-03-20","objectID":"/mysql%E5%A4%8D%E5%88%B6/:1:0","tags":["MYSQL"],"title":"MySQL复制功能介绍","uri":"/mysql%E5%A4%8D%E5%88%B6/"},{"categories":["MYSQL"],"content":"binlog日志 记录了所有MySQL数据库的修改事件 包括增删改查时间和对表结构的修改事件 ","date":"2022-03-20","objectID":"/mysql%E5%A4%8D%E5%88%B6/:2:0","tags":["MYSQL"],"title":"MySQL复制功能介绍","uri":"/mysql%E5%A4%8D%E5%88%B6/"},{"categories":["MYSQL"],"content":"二进制日志格式 基于段的格式 binlog_format=STATEMENT 日志记录量相对较,节约磁盘及网络I/O 缺点如下 必须记录上下文信息 必须保证从数据库的语句与主数据库相同 查看日志使用的格式 mysql\u003e show variables like \"binlog_format\"; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | binlog_format | ROW | +---------------+-------+ 1 row in set (0.00 sec) set session binlog_format=statement; # 改成基于段的格式 mysql\u003e flush logs; # 刷新日志 mysql\u003e show binary logs; +------------------+-----------+ | Log_name | File_size | +------------------+-----------+ | mysql_bin.000001 | 201 | | mysql_bin.000002 | 154 | +------------------+-----------+ 2 rows in set (0.00 sec) 如果启动报错 ERROR 1381 (HY000): You are not using binary logging 请在mysql的配置文件中加入 server-id=1 log_bin=mysql_bin 重启mysql就行 ","date":"2022-03-20","objectID":"/mysql%E5%A4%8D%E5%88%B6/:2:1","tags":["MYSQL"],"title":"MySQL复制功能介绍","uri":"/mysql%E5%A4%8D%E5%88%B6/"},{"categories":["MYSQL"],"content":"查看二进制日志所记录的内容 mysql\u003e create database crn; Query OK, 1 row affected (0.07 sec) mysql\u003e use crn Database changed mysql\u003e create table t(id int,name varchar(20)); Query OK, 0 rows affected (0.90 sec) mysql\u003e insert into t values(1,'nica'),(2,'logs'); Query OK, 2 rows affected (0.15 sec) Records: 2 Duplicates: 0 Warnings: 0 [root@MySQL8-slave2 ~]# cd /var/lib/mysql [root@MySQL8-slave2 mysql]# mysqlbinlog mysql_bin.000002 # 里面可以看到所有的操作记录 是基于段的 ","date":"2022-03-20","objectID":"/mysql%E5%A4%8D%E5%88%B6/:2:2","tags":["MYSQL"],"title":"MySQL复制功能介绍","uri":"/mysql%E5%A4%8D%E5%88%B6/"},{"categories":["MYSQL"],"content":"基于行的日志格式binlog_formart=ROW Row可以解决主从同步不一致的问题(记录所有行) 例如 同一个SQL语句修改了10000条数据的情况,基于段的日志格式只会记录这个SQL语句基于行的日志会有10000条记录分别记录每一行SQL语句. 使MySQL主从复制更加安全 对每一行数据的修改比基于段的复制搞笑 记录日志量较大 binlog_row_image=[full|minimal|noblob] full表述全部记录 minimage只记录列的修改 noblob不会记录text的值 mysql\u003e alter table t add c2 text;#加入一个c2列 字段类型为text mysql\u003e insert into t values(3,'ee','bbb'); 查看你的mysqlbinlog日志 [root@MySQL8-slave2 mysql]# mysqlbinlog mysql_bin.000003 # 单独的用mysqlbinary完全看不到row里面的数据 [root@MySQL8-slave2 mysql]# mysqlbinlog mysql_bin.000003 -vv # 加入-vv参数就可以看到row格式的binlog日志记录方式 2.这个时候我们更改一下binlog_row_image的参数为minimal mysql\u003e set session binlog_row_image=minimal; mysql\u003e update t set c2='this 2' where id=2; # 更改数据 再次查看mysql_binlog.000003里面的数据 ### UPDATE `crn`.`t` //可以看到minimal是这样的 3.更改binlog_row_image的参 blob mysql\u003e set session binlog_row_image=noblob; //注意这个时候不能用text格式 mysql\u003e update t set name='blob' where id=3; 再次查看mysql_binlog.000003里面的数据 ### SET ### @1=3 /* INT meta=0 nullable=1 is_null=0 */ ### @2='blob' /* VARSTRING(20) meta=20 nullable=1 is_null=0 */ # at 1092 #200918 10:18:03 server id 1 end_log_pos 1123 CRC32 0x707bd6dc Xid = 61 COMMIT/*!*/; SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/; DELIMITER ; # End of log file //其实和ROW的方式差不多的 因为没更新text的列 所以SET后面没有数据 ","date":"2022-03-20","objectID":"/mysql%E5%A4%8D%E5%88%B6/:2:3","tags":["MYSQL"],"title":"MySQL复制功能介绍","uri":"/mysql%E5%A4%8D%E5%88%B6/"},{"categories":["MYSQL"],"content":"混合日志格式binlog_format=MIXED 根据SQL语句由系统决在基于段和基于行的日志格式中进行选择 数据量的大小由所执行的SQL语句决定 ","date":"2022-03-20","objectID":"/mysql%E5%A4%8D%E5%88%B6/:2:4","tags":["MYSQL"],"title":"MySQL复制功能介绍","uri":"/mysql%E5%A4%8D%E5%88%B6/"},{"categories":["MYSQL"],"content":"对于二进制日志选择 建议 binlog_format=mixed binlog_formart=row 这两个还是作为首选 注意,在使用binlog_formart=row的时候注意也应该设置binlog_row_image=minial ","date":"2022-03-20","objectID":"/mysql%E5%A4%8D%E5%88%B6/:3:0","tags":["MYSQL"],"title":"MySQL复制功能介绍","uri":"/mysql%E5%A4%8D%E5%88%B6/"},{"categories":["Linux"],"content":"1.1 nginx连接数优化 events { worker_connections 65530; # 设置nginx最大连接,最多为65535 use epoll; # 采用epoll模型，作用于event的I/O异步 } 进程优化 worker_processes 8; # NGinx的工作线程一般为核心数或者核心数X2 最多设置为8如果超出性能则不会进行提升了 worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000; //设置NGinx的cpu亲和力，8核心就这样设置 worker_rlimit_nofile 102400; //nginx 子进程允许打开的文件次数 ","date":"2022-03-20","objectID":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/:0:1","tags":["Linux"],"title":"Nginx优化-常规优化","uri":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/"},{"categories":["Linux"],"content":"1.2 选项参数优化 http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' limit_req_zone $binary_remote_addr zone=allip:10m rate=1000r/m; client_header_timeout 15; # 建立链接后发送request header的链接时间，如果超过此时间没有发送数据，则报错408 client_body_timeout 15; # 建立链接后发送request body的链接时间，如果超过此时间没有发送数据，则报错408 send_timeout 60s; # 服务端向客户端传输数据的超时实际那 # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 45; # TCP链接最多保持时间 gzip_http_version 1.1; gzip_http_version 1.1;# 识别gzip使用的http的版本，默认1.1 gzip on; # 开启gzip on 减少数据传输量 } ","date":"2022-03-20","objectID":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/:0:2","tags":["Linux"],"title":"Nginx优化-常规优化","uri":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/"},{"categories":["Linux"],"content":"1.3系统内核层面优化 echo \"net.core.somaxconn = 50000\" \u003e /etc/sysctl.conf # 最大连接数 echo \"net.ipv4.tcp_syncookies = 1\" \u003e /etc/sysctl.conf # 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭； echo 1 \u003e /proc/sys/net/ipv4/tcp_tw_recycle # 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。 echo 1 \u003e /proc/sys/net/ipv4/tcp_tw_reuse # 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭； ","date":"2022-03-20","objectID":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/:0:3","tags":["Linux"],"title":"Nginx优化-常规优化","uri":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/"},{"categories":["Linux"],"content":"1.4 允许打开最大文件数 cat\u003e\u003e/etc/security/limits.conf\u003c\u003cEOF * soft nofile 655350 * hard nofile 655350 EOF ","date":"2022-03-20","objectID":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/:0:4","tags":["Linux"],"title":"Nginx优化-常规优化","uri":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/"},{"categories":["Linux"],"content":"1.5 nginx 添加统计模块及配置 # 在 nginx.conf 中配置统计模块 location /status{ # 开启状态 stub_status on; # 不需要日志 access_log off; # 只允许此 ip 访问 allow 192.168.20.21; # 其他 ip 禁止访问 deny all; } 访问即可http://192.168.20.21/status ","date":"2022-03-20","objectID":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/:0:5","tags":["Linux"],"title":"Nginx优化-常规优化","uri":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/"},{"categories":["Linux"],"content":"1.6 限制同一个IP访问频率 在nginx.conf里的http{}里加上如下代码： http { include mime.types; default_type application/octet-stream; # log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' limit_req_zone $binary_remote_addr zone=allip:10m rate=1000r/m; limit_conn_zone $server_name zone=allserver:10m; # 定义一个名为one的limit_req_zone用来存储session，大小是10M内存，　# 以$binary_remote_addr 为key,限制平均每分钟的请求为1000个， # 1M能存储16000个状态，rete的值必须为整数 # $server_name 为限制同一server最大并发数 } # 在需要限制并发数和下载带宽的网站配置server{}里加上如下代码： limit_conn allip 2; # allip是根据http中的zone选择的，是一个自定名称 limit_conn allserver 20; # allserver也是和http的zone保持一致 limit_rate 100k; # 限制下载速度,根据带宽进行确定 ","date":"2022-03-20","objectID":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/:0:6","tags":["Linux"],"title":"Nginx优化-常规优化","uri":"/nginx%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96%E9%A1%B9/"},{"categories":["Redis"],"content":"准备环境 192.168.1.100 MASTER 6379 192.168.1.101 SLAVE 6379 脚本每个人的环境不同.可能有的会有问题，按照自己的环境来改和执行 [root@localhost redis]# vim start.sh //就是不想手动敲那么累，全是命令拼凑 #!/bin/bash Redis_home=/usr/local/redis # start dow redis echo -e \"\\033[41;36m test env \\033[0m\" if [ ! -d \"/backup\" ]; then mkdir /backup fi mv /etc/yum.repos.d/* /backup wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo # installk envermint echo -e \"\\033[41;36m install env \\033[0m\" yum makecache \u003e /dev/null 2\u003e\u00261 yum -y install centos-release-scl scl-utils-build yum -y install devtoolset-7-gcc* gcc scl enable devtoolset-7 bash # zip redis echo -e \"\\033[41;36m install redis \\033[0m\" wget http://download.redis.io/releases/redis-6.0.8.tar.gz tar -zxf redis-6.0.8.tar.gz mv redis-6.0.8 $Redis_home cd /usr/local/redis \u0026\u0026 make install ","date":"2022-03-20","objectID":"/redis%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/:1:0","tags":["Redis","Linux"],"title":"Redis主从复制搭建","uri":"/redis%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"1.0 修改主Redis配置文件 [root@localhost redis]# vim /usr/local/redis/redis.conf bind 192.168.1.100 # 改为本机IP port 6379 # 默认6379 daemonize yes # 改为yes允许后台执行 pidfile /var/run/redis_6379.pid # pid文件位置 maxmemory 750mb # 设置最大内存 一般为3/4 dbfilename redis-master.rdb # 改一下rdb文件名称 logfile \"/usr/local/redis/logs/redis-master.log\" # 日志文件 requirepass 123.com # redis密码 ","date":"2022-03-20","objectID":"/redis%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/:2:0","tags":["Redis","Linux"],"title":"Redis主从复制搭建","uri":"/redis%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"1.1 修改从Redis配置文件 [root@localhost ~]# vim /usr/local/redis/redis.conf bind 192.168.1.101 # 改为本机IP port 6379 # 默认6379 daemonize yes # 改为yes允许后台执行 pidfile /var/run/redis_6379.pid # pid文件位置 maxmemory 750mb # 设置最大内存 一般为3/4 dbfilename redis-slave.rdb # 改一下rdb文件名称 replicaof 192.168.1.100 6379 # 从节点跟随主节点的地址 logfile \"/usr/local/redis/logs/redis-slave.log\" # 出去记得自己创建目录 requirepass 123.com ","date":"2022-03-20","objectID":"/redis%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/:3:0","tags":["Redis","Linux"],"title":"Redis主从复制搭建","uri":"/redis%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"1.3 启动Redis主从 echo \"511\" \u003e /proc/sys/net/core/somaxconn echo \"vm.overcommit_memory = 1\" \u003e\u003e /etc/sysctl.conf sysctl -p [root@localhost ~]# cd /usr/local/redis/;redis-server redis.conf 检测主从是否同步 [root@localhost redis]# redis-cli -c -h 192.168.1.100 -p 6379 -a 123.com # 从上面链接主 192.168.1.100:6379\u003e set for ceshi [root@localhost redis]# redis-cli -c -h 192.168.1.101 -p 6379 -a 123.com # 在切换到从服务器 192.168.1.101:6379\u003e get for \"ceshi\" # 同步到数据即可 ","date":"2022-03-20","objectID":"/redis%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/:4:0","tags":["Redis","Linux"],"title":"Redis主从复制搭建","uri":"/redis%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/"},{"categories":["MYSQL"],"content":"究竟哪些东西可以影响到我们服务器的性能呢？ 无非就是：CPU、磁盘IO、内存等等一系列硬件 在研究性能时候,先带大家来了解三个术语 QPS: 每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准,简言之就是数据库每秒能查多少数据 TPS: 服务器每秒处理的事务数。TPS包括一条消息入和一条消息出，加上一次用户数据库访问。（业务TPS = CAPS × 每个呼叫平均TPS） 并发量: 同一时间处理请求的数量，注意不要和同时连接数搞混,连接数要比并发量多的多的多 ","date":"2022-03-20","objectID":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/:0:0","tags":["MYSQL"],"title":"探讨一下大促销当中数据库可能出现的问题","uri":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["MYSQL"],"content":"如果存在超高的QPS和TPS 效率低下的SQL 在访问量急剧增大的情况下,数据库每秒能处理多少个QPS就显得很重要了。 假设我们现在只有一个CPU进行处理SQL语句 10ms处理1个SQL 1s处理100个SQL QPS\u003c=100 在假设如果处理SQL语句的时间变长 100ms处理一个SQL 1s处理10个SQL QPS\u003c=10 解决方法 80%的数据库QPS可以通过优化SQL语句来进行一定的优化. ","date":"2022-03-20","objectID":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/:1:0","tags":["MYSQL"],"title":"探讨一下大促销当中数据库可能出现的问题","uri":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["MYSQL"],"content":"大量的并发和超高的CPU 大量的并发: 数据库连接数被占满(导致网页提示503) 超高的CPU使用率: 因CPU的资源耗尽出现了宕机 解决方法 你需要设置一下MySQL的最大连接数max_connections 选择性能更高的CPU ","date":"2022-03-20","objectID":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/:2:0","tags":["MYSQL"],"title":"探讨一下大促销当中数据库可能出现的问题","uri":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["MYSQL"],"content":"磁盘IO 风险 磁盘IO性能突然下降 其他大量消耗磁盘性能的计划任务(调整计划任务,做好此盘维护) 解决方法 使用更快的磁盘设备 ","date":"2022-03-20","objectID":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/:3:0","tags":["MYSQL"],"title":"探讨一下大促销当中数据库可能出现的问题","uri":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["MYSQL"],"content":"网卡流量 风险 网卡流量被占满导致无法连接数据库 解决方法 减少从服务器的数量 进行分级缓存 避免使用select *进行查询 分离业务网络和服务器网络 ","date":"2022-03-20","objectID":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/:4:0","tags":["MYSQL"],"title":"探讨一下大促销当中数据库可能出现的问题","uri":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["MYSQL"],"content":"大表 记录行数巨大,单表超过千万行 表数据文件巨大,表数据文件超过10GB 大表对查询的影响 慢查询: 很难在一定的时间内过滤出所需要的数据 大表对DDL语句操作的影响 建立索引需要很长时间 如果MySQL版本\u003c5.5建立索引会被锁表 如果MySQL版本\u003e=5.5虽然不会被锁表但是会引起主从延迟 修改表结构需要长时间锁表 同建立索引一样,会造成长时间的主从延迟 影响正常数据的操作,阻塞数据 因为所有的Insert语句都会阻塞,都需要等到你的表结构修改完成后才能处理。 ","date":"2022-03-20","objectID":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/:5:0","tags":["MYSQL"],"title":"探讨一下大促销当中数据库可能出现的问题","uri":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["MYSQL"],"content":"解决数据库中的大表 分库分表把一张大表分成多个小表 难点 分表主键的选择 分表后跨分区数据的查询和统计 可能会影响后端业务,需要大量的人力物力 大表的历史数据归档 优点 减少对前后端业务的影响 难点 归档时间点的选择 如何进行归档操作 ","date":"2022-03-20","objectID":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/:6:0","tags":["MYSQL"],"title":"探讨一下大促销当中数据库可能出现的问题","uri":"/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"项目中使用Nginx服务实现文件的访问，由于和tomcat的接口不是一个域，前端VUE做了图片处理，导致出现跨域问题 location /file { alias /kjc; add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Credentials true; } 添加跨域配置： add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Credentials true; ","date":"2022-03-20","objectID":"/nginx%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98/:0:0","tags":["Linux"],"title":"有关于Nginx跨域问题","uri":"/nginx%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"Mongodb主从搭建 内存2以上 无特殊要求 主IP：192.168.1.100 从IP：192.168.1.101 准备配置如下，每台服务器都执行 sudo echo \"never\" \u003e /sys/kernel/mm/transparent_hugepage/enabled sudo echo \"never\" \u003e /sys/kernel/mm/transparent_hugepage/defrag vim /etc/security/limits.conf # 添加mongo用户可以打开的文件数量的限制 mongod soft nofile 64000 mongod hard nofile 64000 mongod soft nproc 32000 mongod hard nproc 32000 1.0 下载安装Mongo [root@bogon ~]# curl -O http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.4.2.tar.gz [root@bogon ~]# tar -zxf mongodb-linux-x86_64-3.4.2.tgz # 解压 [root@bogon ~]# mv mongodb-linux-x86_64-3.4.2 /usr/local/mongo # 移动目录到/usr/local/mongo 1.2 主mongo配置 [root@bogon mongo]# mkdir /usr/local/mongo/{conf,data,logs} [root@bogon mongo]# vim /usr/local/mongo/conf/mongo.conf port=27017 fork=true logpath=/usr/local/mongo/logs/mongodb.log logappend=true dbpath=/usr/local/mongo/data maxConns=1024 master=true oplogSize=2048 port=27017 #端口号 fork=true #以守护进程方式运行 logpath=/usr/local/mongodb/logs/mongodb.log #日志文件 logappend=true #日志输出方式 dbpath=/usr/local/mongodb/data #数据库位置 maxConns=1024 #数据库最大连接数 master=true #主模式 oplogSize=2048 #日志滚动，单位M 1.3 从Mongo配置 [root@bogon mongo]# mkdir /usr/local/mongo/{conf,data,logs} [root@bogon mongo]# vim /usr/local/mongo/conf/mongo.conf port=27017 fork=true logpath=/usr/local/mongo/logs/mongodb.log logappend=true dbpath=/usr/local/mongo/data maxConns=1024 slave=true source=192.168.1.100:27017 autoresync=true port=27017 fork=true logpath=/usr/local/mongo/logs/mongodb.log logappend=true dbpath=/usr/local/mongo/data maxConns=1024 slave=true # 从模式 source=192.168.1.100:27017 # 指定主Mongodb autoresync=true # 自动同步 [root@localhost ~]# ln -s /usr/local/mongo/bin/* /usr/bin/ [root@bogon mongo]# mongod -f /usr/local/mongo/conf/mongo.conf # -f 指定配置文件 [root@bogon mongo]# mongod -f /usr/local/mongo/conf/mongo.conf --shutdown //关闭mongo 测试mongo主从同步 # 创建一个user库，然后创建集合，插入字段测试是否同步 [root@bogon mongo]# mongo \u003e use test \u003e db.test.save({AGE:18}) \u003e db.test.find() { \"_id\" :ObjectId(\"52addd66124c02eb8b2d1a5a\"), \"AGE\" : 18 } //此为查出的数据 \u003e show dbs admin 0.000GB local 0.000GB test 0.000GB # 从库查询数据 [root@bogon mongo]# mongo \u003e use test \u003e db.test.find() { \"_id\" :ObjectId(\"52addd66124c02eb8b2d1a5a\"), \"AGE\" : 18 } //此为查出的数据 ","date":"2022-03-20","objectID":"/mongodb%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/:0:1","tags":["Linux","Mongo"],"title":"Mongodb主从搭建","uri":"/mongodb%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"问题解决 WARNING: Access control is not enabled for the database 原因分析：新版本的MongDB增加了安全性设计，推荐用户创建使用数据库时进行验证。如果用户想建立简单连接，则会提示警示信息。 解决方法 [root@bogon logs]# mongo # 进入mongo数据库 use admin //进入admin db.createUser({user: 'root', pwd: '123456qwerty!@#$%^', roles: ['root']}) # 创建用户密码和权限 db.auth('root', '123456qwerty!@#$%^') # 返回1 认证成功，返回0认证失败 # 因为mongo的密码是针对库设置的，不是像mysql一样针对全局设置的 “errmsg” : “not master and slaveOk=false” 如果从服务器上进入mongo以后使用show dbs查看是否同步数据库报这个错误是正常的 因为SECONDARY是禁止读的 解决方法 # 从库执行 rs.slaveOk() use test db.agre.find() { \"_id\" : ObjectId(\"5f87ff66ab2013c2fb746333\"), \"AGE\" : 18 } //从库能查寻到数据即可 ","date":"2022-03-20","objectID":"/mongodb%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/:0:2","tags":["Linux","Mongo"],"title":"Mongodb主从搭建","uri":"/mongodb%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"关于Mongo认证机制 --auth:表示带着认证方式进行启动 mongod -f /usr/local/mongo/conf/mongo.conf --auth 进入到mongo使用show dbs发现报错 not authorized on admin to execute command { listDatabases: 1.0 } 此时应该先到admin库中进行验证 \u003e use admin \u003e db.auth('root', '123456qwerty!@#$%^') # 返回结果为1则认证成功 \u003e show dbs # 此时查看数据就可以了 ","date":"2022-03-20","objectID":"/mongodb%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/:0:3","tags":["Linux","Mongo"],"title":"Mongodb主从搭建","uri":"/mongodb%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/"},{"categories":["MYSQL"],"content":"1.0 下载安装包 下载地址 # 下载官方的mysql8.0 wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm rpm -ivh mysql80-community-release-el7-3.noarch.rp yum install mysql-community-server # 安装mysql8.0 ","date":"2022-03-20","objectID":"/mysql8.0%E5%AE%89%E8%A3%85/:0:1","tags":["MYSQL"],"title":"MySQL8.0安装","uri":"/mysql8.0%E5%AE%89%E8%A3%85/"},{"categories":["MYSQL"],"content":"1.1 服务启动 systemctl start mysqld # 启动mysql systemctl stop mysqld # 停止mysql systemctl restart mysqld # 重启mysql systemctl status mysqld # 查看mysql的状态 ","date":"2022-03-20","objectID":"/mysql8.0%E5%AE%89%E8%A3%85/:0:2","tags":["MYSQL"],"title":"MySQL8.0安装","uri":"/mysql8.0%E5%AE%89%E8%A3%85/"},{"categories":["MYSQL"],"content":"关于MySQL启动报错 # 优先查看MySQL启动日志,定位错误原因 cat /var/log/mysqld.log --- 2020-09-14T09:26:14.925068Z 1 [ERROR] [MY-011011] [Server] Failed to find valid data directory. 2020-09-14T09:26:14.925300Z 0 [ERROR] [MY-010020] [Server] Data Dictionary initialization failed. --- 如果定位是如上错误 解决办法如下 rm -rf /var/lib/mysql systemctl start mysqld ","date":"2022-03-20","objectID":"/mysql8.0%E5%AE%89%E8%A3%85/:0:3","tags":["MYSQL"],"title":"MySQL8.0安装","uri":"/mysql8.0%E5%AE%89%E8%A3%85/"},{"categories":["MYSQL"],"content":"1.2 修改密码 继MySQL5.7以后默认生成密码,密码可以在/var/log/mysqld.log中查看 cat /var/log/mysqld.log | grep password --- 2020-09-14T09:30:23.884566Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: E\u0026Vkxormg1 --- 如果是忘记密码 vim /etc/my.cnf [mysqld] skip-grant-tables # 在配置文件添加此内容 mysql -u root -p -A mysql\u003e use mysql mysql\u003e update user set authentication_string='' where user='root'; # 因为mysql5.7以后已经废弃password字段了,用了authentication_string字段,所以我们先将密码设置为空. [mysqld] skip-grant-tables # 将原来的跳过验证删除,然后重启MySQL mysql -u root -p -A 回车进入就行 mysql\u003e use mysql mysql\u003e ALTER user 'root'@'localhost' IDENTIFIED BY '(^\u0026*^*\u0026^(*))'; # 将密码修改为(^\u0026*^*\u0026^(*)),这个密码你们自己自定义. mysql\u003e flush privileges; # 刷新权限 如果出现ERROR 1819 (HY000): Your password does not satisfy the current policy requirements错误提示表示你的密码不符合安全策略要求,一般都是字母+数字+符号+大写构成。 ","date":"2022-03-20","objectID":"/mysql8.0%E5%AE%89%E8%A3%85/:0:4","tags":["MYSQL"],"title":"MySQL8.0安装","uri":"/mysql8.0%E5%AE%89%E8%A3%85/"},{"categories":["MYSQL"],"content":"1.3 授权用户远程登录 -- 修改数据库密码认证方式（不修改密码则不执行） ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'chatsure！@#456'; -- root用户设置为可远程连接（注意：需要在mysql数据库下执行） update user set host='%' where user='root'; -- 给用户授权 grant all privileges on *.* to 'root'@'%' with grant option -- 创建角色 create role 'role_all' -- 给角色授权 grant all privileges on *.* to role_all; -- 给用户添加角色 grant role_all to 'root'@'%'; -- 刷新权限 flush privileges; ","date":"2022-03-20","objectID":"/mysql8.0%E5%AE%89%E8%A3%85/:0:5","tags":["MYSQL"],"title":"MySQL8.0安装","uri":"/mysql8.0%E5%AE%89%E8%A3%85/"},{"categories":["Django"],"content":"腾讯云短信接口 注册 登录 具体怎么注册腾讯云接口看下面的文章吧 腾讯云接口注册 ","date":"2022-02-22","objectID":"/%E5%AE%9E%E7%8E%B0%E8%B0%83%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%8E%A5%E5%8F%A3/:1:0","tags":["Django"],"title":"Django实现调用腾讯云短信接口","uri":"/%E5%AE%9E%E7%8E%B0%E8%B0%83%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%8E%A5%E5%8F%A3/"},{"categories":["Django"],"content":"1.0 安装SDK pip3 install qcloudsms_py conda install qcloudsms_py ","date":"2022-02-22","objectID":"/%E5%AE%9E%E7%8E%B0%E8%B0%83%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%8E%A5%E5%8F%A3/:1:1","tags":["Django"],"title":"Django实现调用腾讯云短信接口","uri":"/%E5%AE%9E%E7%8E%B0%E8%B0%83%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%8E%A5%E5%8F%A3/"},{"categories":["Django"],"content":"1.1 编写发送短信接口 我的环境是基于django TENCENT_SMS_APP_ID, TENCENT_SMS_APP_KEY, TENCENT_SMS_SIG: 分别都写在了settings.develop配置文件下 # tencent/smsket.py import ssl from love_language.settings.develop import TENCENT_SMS_APP_ID, TENCENT_SMS_APP_KEY, TENCENT_SMS_SIGN # ssl._create_default_https_context = ssl._create_unverified_context from qcloudsms_py import SmsMultiSender, SmsSingleSender from qcloudsms_py.httpclient import HTTPError class SendTenSms(): def __init__(self, phone_num, template_id, template_param_list): \"\"\" 单条发送短信 :param phone_num: 手机号 :param template_id: 腾讯云短信模板ID :param template_param_list: 短信模板所需参数列表，例如:【验证码：{1}，描述：{2}】，则传递参数 [888,666]按顺序去格式化模板 :return: \"\"\" self.phone_num = phone_num self.template_id = template_id self.template_param_list = template_param_list def send_sms_single(self): appid = TENCENT_SMS_APP_ID # 自己应用ID appkey = TENCENT_SMS_APP_KEY # 自己应用Key sms_sign = TENCENT_SMS_SIGN # 自己腾讯云创建签名时填写的签名内容（使用公众号的话这个值一般是公众号全称或简称） sender = SmsSingleSender(appid, appkey) try: response = sender.send_with_param(86, self.phone_num, self.template_id, self.template_param_list, sign=sms_sign) except HTTPError as e: response = {'result': 1000, 'errmsg': \"网络异常发送失败\"} return respons # urls.py from django.contrib import admin from django.urls import path,re_path from config.views import * urlpatterns = [ path('sms/',OperateTenSms.as_view(),name='短信发送接口') ] # views.py import random from django.shortcuts import render from django.http import HttpResponse from django.views import View from config.tencent.smsket import SendTenSms # 腾讯云发送短信接口 class OperateTenSms(View): def get(self, request): # 实例化接口 code = random.randrange(1000, 999999) send_sms = SendTenSms('接受短信的手机号码', '短信正文模板', [code]) send_sms.send_sms_single() if send_sms.send_sms_single()['result'] == 0: return HttpResponse(\"短信发送成功\") else: return HttpResponse(send_sms.send_sms_single()['errmsg']) def post(self, request): pass ","date":"2022-02-22","objectID":"/%E5%AE%9E%E7%8E%B0%E8%B0%83%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%8E%A5%E5%8F%A3/:1:2","tags":["Django"],"title":"Django实现调用腾讯云短信接口","uri":"/%E5%AE%9E%E7%8E%B0%E8%B0%83%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%8E%A5%E5%8F%A3/"},{"categories":["Django"],"content":"发送短信出现问题汇总 SSLERROR at /send/sms/ [SSL: CERTIFICATE_VERIFY_FAILED] # 解决方法 import ssl 如何灵活的设置短信正文模板ID # setting.py # 短信模板 TENCENT_SMS_TEMPLATE = { 'register': 1313162, 'login': 1312871, } # views.py import random from django.shortcuts import render from django.http import HttpResponse from django.views import View from config.tencent.smsket import SendTenSms from love_language.settings.develop import TENCENT_SMS_TEMPLATE # 腾讯云发送短信接口 class OperateTenSms(View): def get(self, request): \"\"\" :param request: :return: ?tpl=login ?tpl=register \"\"\" t_id = request.POST.get('template_id') # 通过传入的t_id的键去取模板当中的值 template_id = TENCENT_SMS_TEMPLATE.get(t_id) # 当template_id为空的时候 if not template_id: return HttpResponse(\"短信模板不存在\") # 实例化接口 code = random.randrange(1000, 999999) send_sms = SendTenSms('接收短信的手机号', template_id, [code]) send_sms.send_sms_single() if send_sms.send_sms_single()['result'] == 0: return HttpResponse(\"短信发送成功\") else: return HttpResponse(send_sms.send_sms_single()['errmsg']) def post(self, request): pass ","date":"2022-02-22","objectID":"/%E5%AE%9E%E7%8E%B0%E8%B0%83%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%8E%A5%E5%8F%A3/:1:3","tags":["Django"],"title":"Django实现调用腾讯云短信接口","uri":"/%E5%AE%9E%E7%8E%B0%E8%B0%83%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%8E%A5%E5%8F%A3/"},{"categories":["Kubernetes"],"content":"先前了解 参考链接：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md#dockershim-deprecation 参考链接：https://github.com/kubernetes/kubernetes/pull/94624 kubelet中的Docker支持现在已弃用，并将在未来的版本中删除。kubelet使用了一个名为dockershim的模块，该模块实现了对Docker的CRI支持，并在Kubernetes社区中发现了维护问题。我们鼓励您评估迁移到一个容器运行时的情况，该容器运行时是CRI（v1alpha1或v1兼容）的完整实现。 也就是说,在后续的Kubernetes1.20x版本以后会删除dockershim组件,但是由于目前Docker的使用用户众多,中间必然会有替换的一个过渡期,所以大家可以更多的关注一下其他的Container Runtime。 例如我们的Podman、Containerd、cri-o等其他容器运行时来运行kubernetes。 下面我们就具体来看看Kubernetes所提到的弃用dockershim到底是什么东西. ","date":"2022-02-13","objectID":"/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/:1:0","tags":["Kubernetes"],"title":"dockershim究竟是什么","uri":"/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/"},{"categories":["Kubernetes"],"content":"CRI容器运行时接口 参考链接：https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md CRI：容器运行时接口 container runtime interface，CRI 中定义了容器和镜像两个接口，实现了这两个接口目前主流的是：CRI-O、Containerd。（目前 PCI 产品使用的即为 Containerd）。 CRI接口的具体用处就在于 对容器操作的接口，包括容器的创建、启动和停止.即create、stop等操作。 对镜像的操作，下载、删除镜像等. 即pull、rmi等操作。 podsandbox ","date":"2022-02-13","objectID":"/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/:2:0","tags":["Kubernetes"],"title":"dockershim究竟是什么","uri":"/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/"},{"categories":["Kubernetes"],"content":"OCI开放容器标准 OCI：开放容器标准 open container initiative，OCI 中定义了两个标准：容器运行时标准 和 容器镜像标准，实现了这一标准的主流是：runc（也即我们日常说的 Docker）、Kata-Container。 OCI的作用在于 ImageSpec(容器标准包)： 文件系统：以 layer 保存的文件系统，每个 layer 保存了和上层之间变化的部分，layer 应该保存哪些文件，怎么表示增加、修改和删除的文件等 config 文件：保存了文件系统的层级信息（每个层级的 hash 值，以及历史信息），以及容器运行时需要的一些信息（比如环境变量、工作目录、命令参数、mount 列表），指定了镜像在某个特定平台和系统的配置。比较接近我们使用 docker inspect \u003cimage_id\u003e 看到的内容 manifest 文件：镜像的 config 文件索引，有哪些 layer，额外的 annotation 信息，manifest 文件中保存了很多和当前平台有关的信息 index 文件：可选的文件，指向不同平台的 manifest 文件，这个文件能保证一个镜像可以跨平台使用，每个平台拥有不同的 manifest 文件，使用 index 作为索引 runtimeSpec: ociVersion(string, REQUIRED):是该州遵守的开放容器倡议运行时规范的版本。 id： 容器的 ID。这在此主机上的所有容器中必须是唯一的。不要求它在主机之间是唯一的。 status(string, REQUIRED): 是容器的运行时状态。该值可以是以下之一 creating created running stopped pid: host上看到的容器进程 bundle：host上容器bundle目录的绝对路径 annotation：容器相关的标注，可选 所以在Json的序列化时,必须遵守以下格式 { \"ociVersion\": \"0.2.0\", \"id\": \"oci-container1\", \"status\": \"running\", \"pid\": 4422, \"bundle\": \"/containers/redis\", \"annotations\": { \"myKey\": \"myValue\" } } ","date":"2022-02-13","objectID":"/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/:3:0","tags":["Kubernetes"],"title":"dockershim究竟是什么","uri":"/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/"},{"categories":["Kubernetes"],"content":"Dockershim Dockershim 作用：把外部收到的请求转化成 docker daemon 能听懂的请求，让 Docker Daemon 执行创建、删除等容器操作。 具体看一下kubelet是怎样创建容器的 Kubelet 通过 CRI 接口（gRPC）调用dockershim,请求创建一个容器。CRI 即容器运行时接口，这一步中，Kubelet 可以视作一个简单的CRI Client，而 dockershim 就是接收请求的 Server。目前dockershim是内嵌在 Kubelet 中的，所以接收调用就是 Kubelet 进程。 dockershim收到请求后，转化成 docker daemon的请求，发到docker daemon 上请求创建一个容器。 Docker Daemon 早在 1.12 版本中就已经将针对容器的操作移到另一个守护进程 containerd 中，因此 Docker Daemon 仍然不能帮我们创建容器，而是要请求 containerd 创建一个容器。 containerd 收到请求后，并不会自己直接去操作容器，而是创建一个叫做 containerd-shim 的进程，让 containerd-shim 去操作容器。是因为容器进程需要一个父进程来做诸如收集状态，维持 stdin 等 fd 打开等工作。而假如这个父进程就是 containerd，那每次 containerd 挂掉或升级，整个宿主机上所有的容器都得退出了。而引入了 containerd-shim 就规避了这个问题（containerd 和 shim 并不是父子进程关系）。 我们知道创建容器需要做一些设置 namespaces 和 cgroups，挂载 root filesystem 等等操作，而这些事该怎么做已经有了公开的规范，那就是 OCI。它的一个参考实现叫做 runC。于是，containerd-shim 在这一步需要调用 runC 这个命令行工具，来启动容器。 runC 启动完容器后本身会直接退出，containerd-shim 则会成为容器进程的父进程，负责收集容器进程的状态，上报给 containerd，并在容器中 pid 为 1 的进程退出后接管容器中的子进程进行清理，确保不会出现僵尸进程。 ","date":"2022-02-13","objectID":"/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/:4:0","tags":["Kubernetes"],"title":"dockershim究竟是什么","uri":"/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/"},{"categories":["Kubernetes"],"content":"参考链接 别慌: Kubernetes 和 Docker ","date":"2022-02-13","objectID":"/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/:5:0","tags":["Kubernetes"],"title":"dockershim究竟是什么","uri":"/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88/"},{"categories":["Kubernetes"],"content":"本章了解内容 EmptyDir HostPath NFS PV和PVC 生命周期 StorageClass ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:1:0","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":"EmptyDir ​ EmptyDir是基础的Volume类型,一个EmptyDir就是Host上的一个空目录。EmptyDir是在Pod被分配到节点时创建的,它的初始化内容为空,并且无需指定宿主机上对应的目录文件,因为Kubernetes会自动的为他分配一个目录。当Pod被销毁的时候,EmptyDir中的数据也会永久的被删除。 ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:2:0","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":"1. EmptyDir的用途 作为临时空间使用,例如某些应用程序所运行时所需要的临时目录,并且无需永久保留 一个容器需要从另一个容器中获取数据的目录(多容器共享目录) ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:2:1","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":"2. 模拟容器文件共享 在一个Pod中准备两个容器nginx和busybox,然后声明一个Volume分别挂载在两个容器的目录中,然后nginx负责向Volume中写日志,busybox负责读取日志内容到控制台。 apiVersion: v1 kind: Pod metadata: name: volume-test spec: containers: - name: nginx image: nginx:latest ports: - containerPort: 80 volumeMounts: - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 command: [\"/bin/sh\",\"-c\",\"tail -f /logs/access.log\"] volumeMounts: - name: logs-volume mountPath: /logs volumes: - name: logs-volume emptyDir: {} 你可以进入到你的busybox容器查看 实际上就是相当于Nginx挂载了/var/log/nginx/目录,然后Busybox也挂载了/var/log/nginx/下的内容到自己的/logs/目录。 kubectl exec -it volume-test -c busybox /bin/sh 或者使用kubectl logs 进行查看 kubectl logs -f volume-test -c busybox 10.233.97.0 - - [08/Feb/2022:03:42:43 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.29.0\" \"-\" ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:2:2","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":"HostPath ​由于EmptyDir的生命周期是与Pod相关联的,如果Pod销毁的话,那么EmptyDir也会随之删除。如果想要简单的将数据持久化到主机中,可以选择HostPath。 ​HostPath就是主机中的实际目录挂载在Pod中,以供给容器进行使用。这样的设计就可以保证Pod销毁掉以后,数据依然还在主机节点中。 在说一下type的具体类型 DirectoryOrCreate：目录存在就是用,不存在就先创建后使用。 Directory：目录必须存在 FileOrCreate：文件存在就是用,不存在就创建使用 File: 文件必须存在 Socket unix：套接字必须存在 CharDevice：字符设备必须存在 BlockDevice：块儿设备必须存在 apiVersion: v1 kind: Pod metadata: name: volume-test spec: containers: - name: nginx image: nginx:latest ports: - containerPort: 80 volumeMounts: - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 command: [\"/bin/bash\",\"-c\",\"tail -f /logs/access.log\"] volumeMounts: - name: logs-volume mountPath: /logs volumes: - name: logs-volume hostPath: path: /tmp/pod-test type: DirectoryOrCreate # 挂载的类型 ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:3:0","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":"NFS HostPath虽然可以用来解决数据持久化问题,但是一旦节点故障了,Pod转移到了其他的节点上又会出现问题了,此时我们就需要准备单独的网络存储系统。比如 NFS、CIFS等。 NFS是一个网络文件存储系统,可以搭建一台NFS服务器。然后将Pod中的存储直接连接到NFS系统中,无论Pod如何转移,只要Node跟NFS的连接没有问题,数据就可以成功的进行访问。 ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:4:0","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":"1. 安装NFS服务器 # 在所有Kubernetes节点安装NFS服务 yum -y install nfs-utils -y # 准备共享目录 mkdir -pv /data/public # 将共享目录以读写方式暴露给所有主机 vim /etc/exports /data/public *(insecure,rw,sync) # 启动NFS systemctl start nfs apiVersion: v1 kind: Pod metadata: name: volume-test spec: containers: - name: nginx image: nginx:latest ports: - containerPort: 80 volumeMounts: - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 command: [\"/bin/bash\",\"-c\",\"tail -f /logs/access.log\"] volumeMounts: - name: logs-volume mountPath: /logs volumes: - name: logs-volume nfs: server: 192.168.1.2 # NFS服务器地址 path: /data/public # NFS共享文件的路径 ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:4:1","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":"PV和PVC ​ PV(Persistent Volume)是持久化卷的意思,是对底层共享存储的一种抽象。一般情况下PV由Kubernetes管理员创建和配置，它与底层具体的共享存储技术有关,并且通过插件完成共享存储的对接。 ​ PVC(Persistent Volume Claim)是持久卷声明的意思,是用户对存储需求的一种声明。换句话说，实际就是用户向Kubernetes发出的一种需要存储资源的申请。 ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:5:0","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":"1. PV ​ Pv是存储资源的抽象,下面是资源清单文件 apiVersion: v1 kind: PersistentVolume metadata: name: pv2 spec: nfs: # 存储类型,与底层存储对应 capacity: # 存储能力,目前只支持存储空间的设置 storage: 2Gi accessMode: # 访问模式 storageClassName: # 存储类别 persistentVolumeReclaimPolicy: # 回收策略 存储类型：底层实际存储的类型,kubernetes支持多种存储类型,每种存储类型的配置都有所差异。 存储能力：目前只支持存储空间的设置,不过未来可能会加入IOPS、吞吐量等指标配置。 访问模式：用户描述用户对存储资源的访问权限。 ReadWriteOnce(RWO)：读写权限,但是只能被单个节点挂载。 ReadOnlyMany(ROX)：只读权限，可以被多个节点挂载。 ReadWriteMany(RWX)：读写权限，可以被多个节点挂载。 注意：底层不同的存储类型可能支持的访问模式不同。 回收策略：当Pv不在被使用的时候,对这个Pv的处理方式。 Retain(保留)：保留数据,需要管理员手动清理数据。 Recycle(回收)：清除PV中的数据。 Delete(删除)：与PV项链的后端存储完成Volume的删除操作 注意：底层不同的存储类型可能支持的访问模式不同。 存储类别：PV可以通过StorageClassName参数绑定一个存储类别。具有特定类型的PV智能与请求了该类型的Pvc进行绑定。未设定类型的PV只能与不请求任何类型的PVC进行绑定。 状态：一个PV的生命周期中,可能会处于4种不同的阶段 Available(可用)：表示可用状态,还没有被任何PVC绑定。 Bound(已经绑定)：表示该PV已经被PVC绑定 Released(已释放) ：表示PVC被删除,但是资源还未被集群重新声明。 Failed(失败)：表示该PV的自动回收失败。 简单的演示一下PV的使用 apiVersion: v1 kind: PersistentVolume metadata: name: pv1 spec: capacity: storage: 1Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain nfs: path: /var/data ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:5:1","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":"2. PVC ​ PVC是资源的申请,用来声明对存储空间、访问模式、存储类别需求信息。 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc spec: accessModes: # 访问莫斯 selector: # 采用标签对Pv选择 StorageClassName: # 存储类别 resources: # 请求空间 requests: storage: 5Gi accessModes(访问模式)：用于描述用户对存储资源的访问权限。 selector(选择条件)：通过selector的设置,可使PVC对于系统中已经存在的PVC进行筛选。 storageClassName：PVC在定义的时候设定需要后端存储的类别,只有设置了该Class的Pv才能被系统选出。 简单的演示一下Pvc的使用 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc1 spec: accessModes: ReadWriteMany resources: requests: storage: 1Gi --- apiVersion: v1 kind: Pod metadata: name: volume-test spec: containers: - name: nginx image: nginx:latest ports: - containerPort: 80 volumeMounts: - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 command: [\"/bin/bash\",\"-c\",\"tail -f /logs/access.log\"] volumeMounts: - name: volume mountPath: /logs volumes: - name: volume persistentVolumeClaim: claimName: pvc1 readOnly: true ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:5:2","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":"生命周期 ​ PV和PVC是一一对应的,PV和PVC之间的相互作用遵循以下生命周期。 1.资源供应：管理员手动创建底层存储和PV。 2.资源绑定：用户创建PVC请求,Kubernetes负责根据PVC的请求去寻找PV,并且进行绑定,在用户定义好PVC之后,系统将根据PVC对存储资源的请求已存在的PV中选择一个满足条件的。 一旦找到,就会将该PV与用户定义的PVC进行绑定,用户的应用就可以使用此PVC了。 如果找不到,PVC则会无限期处于Pending状态,直到找到符合要求的PVC。 3.资源使用：用户可在Pod中像Volume一样使用Pvc,Pod使用Volume的定义,将Pvc挂载到容器内的某个路径进行使用。 4.资源释放：用户删除PVC释放PV,当存储资源使用完毕后,用户可以删除PVC,与该PVC绑定的PV会被标记完已释放,但不能立刻的与其他PVC进行绑定。通过之前PVC写入的数据可能还留存在存储设备上,只有清楚之后该PV才能再次使用。 5.资源回收：kubernetes根据pv设置的回收策略进行资源的回收,对于PV，管理员可以设定回收策略,用于设置与之绑定的PVC释放资源之后如何处理数据遗留的问题。只有PV的存储空间完成回收,才能与新的PVC绑定和使用。 ","date":"2022-02-08","objectID":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/:6:0","tags":["Kubernetes"],"title":"Kubernetes基本存储","uri":"/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"categories":["Kubernetes"],"content":" 此问题引出的是生产环境中所有的资源完全充足,但是会出现更新Pod、删除Pod、新建Pod无法调度的情况。 ","date":"2021-12-21","objectID":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/:0:0","tags":["Kubernetes"],"title":"有关于Kubernetes中影响Pod调度的问题","uri":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"生产环境解决问题办法 找到问题跟原所在,默认的maxPods: 110,K8S默认一个节点上的pod调度数是110，当前有限制pod数的需求。 vim /var/lib/kubelet/config.yaml maxPods: 110 # 修改为maxPods: 330 ","date":"2021-12-21","objectID":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/:1:0","tags":["Kubernetes"],"title":"有关于Kubernetes中影响Pod调度的问题","uri":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"影响Pod调度的情况 ","date":"2021-12-21","objectID":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/:2:0","tags":["Kubernetes"],"title":"有关于Kubernetes中影响Pod调度的问题","uri":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"requests资源限制 requests：是一种硬限制,Kubernetes在进行Pod请求调度的时候,节点的可用资源必须满足500m的CPU才能进行调度,且使用最大限制为1个CPU,如果该Pod超过请求的最大限制,则Kubernetes将会把该Pod进行Kill重启。 resources: limits: cpu: '1' requests: cpu: 500m 当你设置request为500m以及limit为1000m的时候,当你使用 kubectl\rdescribe node查看节点资源的时候可能会与你设置的请求量不符合,这是以你Pod 的实际使用量为标准的。 ","date":"2021-12-21","objectID":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/:2:1","tags":["Kubernetes"],"title":"有关于Kubernetes中影响Pod调度的问题","uri":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"节点标签的Label 标签选择器： kubectl label node kubernetes-node1 env_role=dev 通过此命令对相应的节点加入标签 kubectl label node 节点名称 标签名称 spec: nodeSelector: env_role: dev 当然,你也可以通过kubectl get node --show-labels命令查看当前节点的标签 NAME STATUS ROLES AGE VERSION LABELS master1 Ready,SchedulingDisabled master 141d v1.17.9 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master1,kubernetes.io/os=linux,node-role.kubernetes.io/master= master2 Ready,SchedulingDisabled master 139d v1.17.9 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master2,kubernetes.io/os=linux,node-role.kubernetes.io/master= master3 Ready,SchedulingDisabled master 139d v1.17.9 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master3,kubernetes.io/os=linux,node-role.kubernetes.io/master= node1 Ready worker 141d v1.17.9 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node1,kubernetes.io/os=linux,node-role.kubernetes.io/worker= node2 Ready worker 141d v1.17.9 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node2,kubernetes.io/os=linux,node-role.kubernetes.io/worker= node3 Ready worker 141d v1.17.9 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=node3,kubernetes.io/os=linux,node-role.kubernetes.io/worker= ","date":"2021-12-21","objectID":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/:2:2","tags":["Kubernetes"],"title":"有关于Kubernetes中影响Pod调度的问题","uri":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"节点亲和性 节点亲和性：nodeAffinity和之前nodeSelector基本上是一样的,有的话满足进行调度,如果没有的话则依旧也可以调度。 硬亲和性：requiredDuringSchedulingIgnoreDuringExecution,当前约束的条件表示为在env_role这个键中有dev/test 有的话即满足的调度,如果不满足则不调度。 软亲和性: preferredDuringSchedulingIgnoredDuringExecution,进行尝试是否满足测试,如果满足则满足调度,如果不满足则依旧会进行调度。 支持的操作符：In/Not In/Gt/Lt/DoesNotExists分别为 存在、不存在、大于、小于、不存在。 spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoreDuringExecution: nodeSelectorTerms: - metchExpressions: - key: env_role operator: In values: - dev - test preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 # 表示权重 比例 preference: matchExpressions: - key: group operator: In # 操作符 In values: - otherprod ","date":"2021-12-21","objectID":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/:2:3","tags":["Kubernetes"],"title":"有关于Kubernetes中影响Pod调度的问题","uri":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["Kubernetes"],"content":"污点和污点容忍 污点：nodeSelector和nodeAffinityPod调度在某些节点上,是属于Pod的属性,在调度的时候进行实现,而污点是对节点做不分配调度,是节点属性。 污点容忍：当一个污点不允许被调度的时候,同时又想让他可能会参与调度,类似于软亲和性。 场景：作为专用节点、配置特定硬件节点、基于Taint驱逐 NoSchedule：一定不被调度 PreferNoSchdule: 尽量不被调度 NoExecute: 不调度,并且会驱逐在该节点上Pod # 污点容忍 spec: tolerations: - key: \"env_role\" operator: \"Equal\" value: \"yes\" effect: \"NoSchedule\" 使用kubectl describe node kubernetes-master1 | grep Taints进行查看是否为污点。 使用kubectl taint node 节点名称 key=value:污点值 ","date":"2021-12-21","objectID":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/:2:4","tags":["Kubernetes"],"title":"有关于Kubernetes中影响Pod调度的问题","uri":"/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98/"},{"categories":["Python"],"content":"元组 Python 的元组与列表类似，不同之处在于元组的元素不能修改。 元组使用小括号 ( )，列表使用方括号 [ ]。 元组创建很简单，只需要在括号中添加元素，并使用逗号隔开即可。 创建一个空元祖 tup1 = () 元组中只包含一个元素时，需要在元素后面添加逗号 , ，否则括号会被当作运算符使用： \u003e\u003e\u003e tup1 = (50) \u003e\u003e\u003e type(tup1) # 不加逗号，类型为整型 \u003cclass 'int'\u003e \u003e\u003e\u003e tup1 = (50,) \u003e\u003e\u003e type(tup1) # 加上逗号，类型为元组 \u003cclass 'tuple'\u003e 元组与字符串类似，下标索引从 0 开始，可以进行截取，组合等。 ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:1:0","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"访问元组 元组可以使用下标索引来访问元组中的值，如下实例: #!/usr/bin/python3 tup1 = ('Google', 'Runoob', 1997, 2000) tup2 = (1, 2, 3, 4, 5, 6, 7 ) print(tup1) print (\"tup1[0]: \", tup1[0]) print (\"tup2[1:5]: \", tup2[1:5]) ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:2:0","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"修改元组 元组中的元素值是不允许修改的，但我们可以对元组进行连接组合，如下实例: #!/usr/bin/python3 tup1 = (12, 34.56) tup2 = ('abc', 'xyz') # 以下修改元组元素操作是非法的。 # tup1[0] = 100 # 创建一个新的元组 tup3 = tup1 + tup2 print (tup3) ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:3:0","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"删除元组 元组中的元素值是不允许删除的，但我们可以使用del语句来删除整个元组，如下实例: #!/usr/bin/python3 tup = ('Google', 'Runoob', 1997, 2000) print (tup) del tup print (\"删除后的元组 tup : \") print (tup) ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:4:0","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"元组运算符 字符串一样，元组之间可以使用 + 号和 * 号进行运算。这就意味着他们可以组合和复制，运算后会生成一个新的元组。 Python 表达式 结果 描述 len((1, 2, 3)) 3 计算元素个数 (1, 2, 3) + (4, 5, 6) (1, 2, 3, 4, 5, 6) 连接 (‘Hi!’,) * 4 (‘Hi!’, ‘Hi!’, ‘Hi!’, ‘Hi!’) 复制 3 in (1, 2, 3) True 元素是否存在 for x in (1, 2, 3): print (x,) 1 2 3 迭代 ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:5:0","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"元组索引，截取 因为元组也是一个序列，所以我们可以访问元组中的指定位置的元素，也可以截取索引中的一段元素，如下所示： 元组： tup = ('Google', 'Runoob', 'Taobao', 'Wiki', 'Weibo','Weixin') Python 表达式 结果 描述 tup[1] ‘Runoob’ 读取第二个元素 tup[-2] ‘Weibo’ 反向读取，读取倒数第二个元素 tup[1:] (‘Runoob’, ‘Taobao’, ‘Wiki’, ‘Weibo’, ‘Weixin’) 截取元素，从第二个开始后的所有元素。 tup[1:4] (‘Runoob’, ‘Taobao’, ‘Wiki’) 截取元素，从第二个开始到第四个元素（索引为 3）。 ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:6:0","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"元组内置函数 ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:7:0","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"len方法 计算元组元素个数。 \u003e\u003e\u003e tuple1 = ('Google', 'Runoob', 'Taobao') \u003e\u003e\u003e len(tuple1) 3 \u003e\u003e\u003e ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:7:1","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"max方法 返回元组中元素最大值。 \u003e\u003e\u003e tuple2 = ('5', '4', '8') \u003e\u003e\u003e max(tuple2) '8' \u003e\u003e\u003e ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:7:2","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"min方法 返回元组中元素最小值。 \u003e\u003e\u003e tuple2 = ('5', '4', '8') \u003e\u003e\u003e min(tuple2) '4' \u003e\u003e\u003e ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:7:3","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"tuple方法 将可迭代系列转换为元组。 \u003e\u003e\u003e list1= ['Google', 'Taobao', 'Runoob', 'Baidu'] \u003e\u003e\u003e tuple1=tuple(list1) \u003e\u003e\u003e tuple1 ('Google', 'Taobao', 'Runoob', 'Baidu') 关于元组是不可变的 \u003e\u003e\u003e tup = ('r', 'u', 'n', 'o', 'o', 'b') \u003e\u003e\u003e tup[0] = 'g' # 不支持修改元素 Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e TypeError: 'tuple' object does not support item assignment \u003e\u003e\u003e id(tup) # 查看内存地址 4440687904 \u003e\u003e\u003e tup = (1,2,3) \u003e\u003e\u003e id(tup) 4441088800 # 内存地址不一样了 ","date":"2021-11-28","objectID":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/:7:4","tags":["Python"],"title":"Python元祖详解","uri":"/%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"本博客的内容要点 什么是函数闭包(function closure)? 什么是语法糖(Syntactic sugar)? 什么是装饰器(decorator)? ","date":"2021-11-22","objectID":"/%E8%A3%85%E9%A5%B0%E5%99%A8%E8%AF%A6%E8%A7%A3/:0:0","tags":["Python"],"title":"Python装饰器详解","uri":"/%E8%A3%85%E9%A5%B0%E5%99%A8%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"什么是函数闭包(function closure)？ 看下方的一段代码 函数的主要功能(输出奇数)和辅助功能(统计函数执行时间)全部都放在一个函数中,一旦要对其进行修改,如果修改错误就会导致出现Bug,导致该函数不可用。 不方便修改 我们的目的是为了能不能在直接调用主要函数的同时调用辅助函数？ import time def print_odds(): \"\"\" 输出0-100之间所有的奇数并且返回函数的执行时间 \"\"\" # 查找并输出所有奇数 start_time = time.clock() for i in range(100): if i % 2 == 1: print(i) end_time = time.clock() print(\"函数执行时间为 {}\".format(end_time - start_time)) if __name__ == '__main__': print_odds() 接着上面的3我们能不能直接调用主要函数的同时调用辅助函数？ 该段代码的缺点 1.我们期望的是直接调用主要函数,同时执行辅助函数,而并不是把辅助函数写在前面。 2.并且对于使用者来说count_time函数是不应该被看到的,在可读性上与我们的期望相反 import time def count_time(func): # 参数传入一个函数 \"\"\" 输出0-100之间所有的奇数并且返回函数的执行时间 \"\"\" # 查找并输出所有奇数 start_time = time.clock() func() #通过调用传入的函数进行执行 end_time = time.clock() print(\"函数执行时间为 {}\".format(end_time - start_time)) def print_odds(): for i in range(100): if i % 2 == 1: print(i) if __name__ == '__main__': count_time(print_odds) # 传入需要进行统计时间的函数 所以,究竟什么是函数的闭包呢？ 一个函数参数和返回值都是函数 用于增强函数功能 面向切面编程(AOP) 究竟如何理解函数闭包 count_time_wrapper传入的是一个函数,其return的improved_func也是一个函数 在返回的函数中既执行了主要函数func也执行了统计函数的功能 闭包函数本身就是一个函数,闭包函数的返回值函数是对传入函数的增强函数 很方便的解耦,只需要在主要函数中写主要函数 在辅助函数中写辅助函数即可 import time def count_time_wrapper(func): # 参数传入一个函数 \"\"\" 输出0-100之间所有的奇数并且返回函数的执行时间 \"\"\" def improved_func(): # 查找并输出所有奇数 start_time = time.clock() func() #通过调用传入的函数进行执行 end_time = time.clock() print(\"函数执行时间为 {}\".format(end_time - start_time)) return improved_func def print_odds(): for i in range(100): if i % 2 == 1: print(i) if __name__ == '__main__': # 通过调用闭包函数对print_odds函数进行增强 # 如果不调用闭包函数,其原本功能就是单纯的执行print_odds \"\"\" 1. 当调用count_time_wrapper后会返回一个新的函数 2. 返回的函数也命名为print_odds,但此时的print_odds函数是被增强过的函数 当然你也可以取名为new_print_odds \"\"\" print_odds = count_time_wrapper(print_odds) print_odds() ","date":"2021-11-22","objectID":"/%E8%A3%85%E9%A5%B0%E5%99%A8%E8%AF%A6%E8%A7%A3/:1:0","tags":["Python"],"title":"Python装饰器详解","uri":"/%E8%A3%85%E9%A5%B0%E5%99%A8%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"什么是语法糖(Syntactic sugar)? 指的是计算机语言中添加的某种语法,这种语法对语言的功能没有影响,但是更方便程序员使用。 语法糖没有增加新功能,只是更方便的写法 语法糖可以完全等价的装换为原本非语法糖的代码 装饰器在第一次调用被装饰的函数时进行增强 强调一下装饰器第一次调用 装饰器在第一次调用之前才会增强,如果没有被调用则不会增强。 装饰器的增强只增强一次,但是对于增强过得函数可以调用很多次。 import time def count_time_wrapper(func): # 参数传入一个函数 \"\"\" 输出0-100之间所有的奇数并且返回函数的执行时间 \"\"\" def improved_func(): # 查找并输出所有奇数 start_time = time.clock() func() #通过调用传入的函数进行执行 end_time = time.clock() print(\"函数执行时间为 {}\".format(end_time - start_time)) return improved_func @count_time_wrapper # 装饰在print_odds函数上 def print_odds(): for i in range(100): if i % 2 == 1: print(i) if __name__ == '__main__': print_odds() 对于有返回值和参数的函数 问题1. 对于有返回值的函数和带参数的函数,不能正常返回,但是可以进行增强 问题2. 对于含有参数的函数调用增强后,并不能成功的接收参数 import time def count_time_wrapper(func): # 参数传入一个函数 \"\"\" 输出0-100之间所有的奇数并且返回函数的执行时间 \"\"\" def improved_func(*args,**kwargs): # 查找并输出所有奇数 start_time = time.clock() result = func(*args,**kwargs) # 记录一下传入func()函数的返回值,也就是count_odds的return的返回值,也就是说增强函数的返回值就是原函数的返回值,并且原函数的参数就是增强函数的参数 end_time = time.clock() print(\"函数执行时间为 {}\".format(end_time - start_time)) return result return improved_func def count_odds(lim=100): cnt=0 for i in range(lim): if i % 2 == 1: cnt+=1 return cnt if __name__ == '__main__': print(count_odds(lim=100)) new_count_odds = count_time_wrapper(count_odds) \"\"\" 1. 因为我们调用的count_odds是增强过后的参数,improved_func增强函数中并没有 lim的参数,只需要在调用improved_func函数的时候接收传入的函数即可 \"\"\" print(new_count_odds(lim=10000000)) ","date":"2021-11-22","objectID":"/%E8%A3%85%E9%A5%B0%E5%99%A8%E8%AF%A6%E8%A7%A3/:2:0","tags":["Python"],"title":"Python装饰器详解","uri":"/%E8%A3%85%E9%A5%B0%E5%99%A8%E8%AF%A6%E8%A7%A3/"},{"categories":["Python"],"content":"字典是另一种可变容器模型，且可存储任意类型对象。 字典的每个键值 key=\u003evalue 对用冒号 : 分割，每个键值对之间用逗号 , 分割，整个字典包括在花括号 {} 中 ,格式如下所示： d = {key1 : value1, key2 : value2 } 键一般是唯一的，如果重复最后的一个键值对会替换前面的，值不需要唯一。 ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:0:0","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"访问字典里的值 把相应的键放入熟悉的方括弧，如下实例: dict = {'Name': 'Zara', 'Age': 7, 'Class': 'First'} print (\"dict['Name']: \", dict['Name']) print (\"dict['Age']: \", dict['Age']) 如果用字典里没有的键访问数据，会输出错误如下： dict['Age']: Traceback (most recent call last): File \"test.py\", line 8, in \u003cmodule\u003e print \"dict['Age']: \", dict['Age'] TypeError: 'type' object is unsubscriptable ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:1:0","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"字典键的特性 字典值可以没有限制地取任何python对象，既可以是标准的对象，也可以是用户定义的，但键不行。 不允许同一个键出现两次。创建时如果同一个键被赋值两次，后一个值会被记住，如下实例： dict = {'Name': 'Zara', 'Age': 7, 'Name': 'Manni'} print (\"dict['Name']: \", dict['Name']) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:2:0","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"字典内置的函数、方法 ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:0","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"len()方法 len() 函数计算字典元素个数，即键的总数。 dict: 要计算元素个数的字典 len(dict) dict = {'Name': 'Zara', 'Age': 7}; print (\"Length : %d\" % len (dict)) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:1","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"str()方法 str()函数将值转化为适于人阅读的形式，以可打印的字符串表示。 dict – 字典 ，返回字符串 str(dict) dict = {'Name': 'Zara', 'Age': 7}; print (\"Equivalent String : %s\" % str (dict)) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:2","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"clear()方法 clear() 函数用于删除字典内所有元素 dict.clear() dict = {'Name': 'Zara', 'Age': 7}; print (\"Start Len : %d\" % len(dict)) dict.clear() print (\"End Len : %d\" % len(dict)) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:3","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"copy()方法 copy() 函数返回一个字典的浅复制。 返回一个字典的浅复制。 dict.copy() dict1 = {'Name': 'Zara', 'Age': 7}; dict2 = dict1.copy() print (\"New Dictinary : %s\" % str(dict2)) 直接赋值和 copy 的区别 dict1 = {'user':'runoob','num':[1,2,3]} dict2 = dict1 # 浅拷贝: 引用对象 dict3 = dict1.copy() # 浅拷贝：深拷贝父对象（一级目录），子对象（二级目录）不拷贝，还是引用,原对象与深拷贝后得对象是两个独立的存在 # 修改 data 数据 dict1['user']='root' dict1['num'].remove(1) # 输出结果 print(dict1) print(dict2) print(dict3) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:4","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"fromkeys()方法 fromkeys()函数用于创建一个新字典，以序列 seq 中元素做字典的键，value 为字典所有键对应的初始值。 seq – 字典键值列表。 value – 可选参数, 设置键序列（seq）的值。 dict.fromkeys(seq[, value]) #!/usr/bin/python # -*- coding: UTF-8 -*- seq = ('Google', 'Runoob', 'Taobao') dict = dict.fromkeys(seq) print(\"新字典为 : %s\" % str(dict)) dict = dict.fromkeys(seq, 10) print(\"新字典为 : %s\"% str(dict)) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:5","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"get()方法 get() 函数返回指定键的值。 key – 字典中要查找的键。 default – 如果指定键的值不存在时，返回该默认值。 dict.get(key, default=None) #!/usr/bin/python # -*- coding: UTF-8 -*- seq = ('Google', 'Runoob', 'Taobao') dict = {'Name': 'Runoob', 'Age': 27} print (\"Value : %s\" % dict.get('Age')) print (\"Value : %s\" % dict.get('Sex', \"Not Available\")) 注意嵌套字典中无法通过get()方法来获取字典的键 ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:6","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"items()方法 items() 函数以列表返回可遍历的(键, 值) 元组数组。 dict.items() dict = {'Google': 'www.google.com', 'Runoob': 'www.runoob.com', 'taobao': 'www.taobao.com'} print (\"字典值 : %s\" % dict.items()) # 遍历字典列表 for key,values in dict.items(): print (key,values) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:7","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"keys()方法 keys() 函数以列表返回一个字典所有的键。 dict.keys() dict = {'Name': 'Zara', 'Age': 7} print (\"Value : %s\" % dict.keys()) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:8","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"setdefault()方法 setdefault() 函数和 get()类似, 如果键不存在于字典中，将会添加键并将值设为默认值。 key – 查找的键值。 default – 键不存在时，设置的默认键值。 dict.setdefault(key, default=None) dict = {'runoob': '菜鸟教程', 'google': 'Google 搜索'} print (\"Value : %s\" % dict.setdefault('runoob', None)) print (\"Value : %s\" % dict.setdefault('Taobao', '淘宝')) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:9","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"update()方法 update() 函数把字典dict2的键/值对更新到dict里。 dict2 – 添加到指定字典dict里的字典。 dict.update(dict2) dict = {'Name': 'Zara', 'Age': 7} dict2 = {'Sex': 'female' } dict.update(dict2) print (\"Value : %s\" % dict) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:10","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":["Python"],"content":"values()方法 values() 函数以列表返回字典中的所有值。 dict.values() dict = {'Name': 'Zara', 'Age': 7} print (\"Value : %s\" % dict.values()) ","date":"2021-11-21","objectID":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/:3:11","tags":["Python"],"title":"Python字典详细操作","uri":"/%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C/"},{"categories":null,"content":"常用网站 我的朋友们 ","date":"2021-08-23","objectID":"/link/:0:0","tags":null,"title":"友情链接","uri":"/link/"},{"categories":["Kubernetes"],"content":"编写你的Dockerfile FROM centos:8 # add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get added RUN groupadd -r -g 1000 redis \u0026\u0026 useradd -r -g redis -u 1000 redis # Redis信息 注意SHA校验 ENV REDIS_VERSION 6.0.8 ENV REDIS_DOWNLOAD_URL http://download.redis.io/releases/redis-6.0.8.tar.gz ENV REDIS_DOWNLOAD_SHA 98ed7d532b5e9671f5df0825bb71f0f37483a16546364049384c63db8764512b # set -eux 以Debug的方式执行shell 遇到错误会退出 RUN set -eux; \\ \\ sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g' \\ -i.bak \\ /etc/yum.repos.d/CentOS-*.repo RUN set -eux; \\ \\ yum makecache; \\ yum -y install zlib-devel \\ openssl-devel \\ gcc \\ wget \\ make \\ gcc-c++;\\ wget -O redis.tar.gz \"$REDIS_DOWNLOAD_URL\"; \\ echo \"$REDIS_DOWNLOAD_SHA *redis.tar.gz\" | sha1sum ; \\ mkdir -p /usr/local/redis; \\ tar -xzf redis.tar.gz -C /usr/local/redis --strip-components=1; \\ rm redis.tar.gz; \\ make -C /usr/local/redis; \\ make -C /usr/local/redis install; chown redis:redis /data VOLUME /usr/local/redis WORKDIR /usr/local/redis COPY redis.conf /usr/local/redis/ #COPY docker-entrypoint.sh /usr/local/bin/ #ENTRYPOINT [\"docker-entrypoint.sh\"] # 可选 # RUN chmod -R 777 /usr/local/redis EXPOSE 6379 # ENTRPOINT 参数可选 可以直接运行 也可以在yaml指定command ENTRYPOINT [\"redis-server\",\"/usr/local/redis/redis.conf\",\"--protected-mode\",\"no\"] redis.conf appendonly yes cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 dir /usr/local/redis/ port 6379 daemonize no redis-cluster.yaml 提醒您: 请挂载数据卷配置,注意保存数据,防止数据丢失！！！ --- kind: Service apiVersion: v1 metadata: name: redis-headless namespace: production-contract labels: app: redis annotations: kubesphere.io/alias-name: redis kubesphere.io/creator: admin kubesphere.io/serviceType: statefulservice spec: ports: - name: http-redis protocol: TCP port: 6379 targetPort: 6379 selector: app: redis clusterIP: None type: ClusterIP sessionAffinity: None --- kind: StatefulSet apiVersion: apps/v1 metadata: name: redis namespace: production-contract labels: app: redis annotations: kubesphere.io/creator: admin spec: replicas: 6 selector: matchLabels: app: redis template: metadata: creationTimestamp: null labels: app: redis annotations: kubesphere.io/containerSecrets: '{\"container-u4km8f\":\"harbor\"}' spec: containers: - name: container-u4km8f image: '10.1.6.15/apps/redis:prod' ports: - name: http-redis containerPort: 6379 protocol: TCP resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File imagePullPolicy: IfNotPresent restartPolicy: Always terminationGracePeriodSeconds: 30 dnsPolicy: ClusterFirst serviceAccountName: default serviceAccount: default securityContext: {} imagePullSecrets: - name: harbor affinity: {} schedulerName: default-scheduler serviceName: redis-headless podManagementPolicy: OrderedReady updateStrategy: type: RollingUpdate rollingUpdate: partition: 0 revisionHistoryLimit: 10 ","date":"2021-07-13","objectID":"/%E5%85%B3%E4%BA%8Ekubernetes%E6%9E%84%E5%BB%BAredis%E9%9B%86%E7%BE%A4/:1:0","tags":["Kubernetes"],"title":"关于Kubernetes构建Redis集群","uri":"/%E5%85%B3%E4%BA%8Ekubernetes%E6%9E%84%E5%BB%BAredis%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"错误排查 ","date":"2021-07-13","objectID":"/%E5%85%B3%E4%BA%8Ekubernetes%E6%9E%84%E5%BB%BAredis%E9%9B%86%E7%BE%A4/:2:0","tags":["Kubernetes"],"title":"关于Kubernetes构建Redis集群","uri":"/%E5%85%B3%E4%BA%8Ekubernetes%E6%9E%84%E5%BB%BAredis%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"关于容器启动退出问题 Docker容器后台运行,就必须有一个前台进程 redis.conf中的daemonize不要设置为yes ","date":"2021-07-13","objectID":"/%E5%85%B3%E4%BA%8Ekubernetes%E6%9E%84%E5%BB%BAredis%E9%9B%86%E7%BE%A4/:2:1","tags":["Kubernetes"],"title":"关于Kubernetes构建Redis集群","uri":"/%E5%85%B3%E4%BA%8Ekubernetes%E6%9E%84%E5%BB%BAredis%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":"关于kubernetes内部加入Redis集群错误 ERR Invalid node address specified: redis-1.redis-headless.production-contract.svc.cluster.local:6379 因为redis不支持主机名加入集群,你可以使用dig 命令将主机名解析成IP后,以解析结果为IP的方式加入。 如下所示 [root@redis-0 data]# redis-cli --cluster create `dig +short redis-0.redis-headless.production-contract.svc.cluster.local`:6379 \\ \u003e `dig +short redis-1.redis-headless.production-contract.svc.cluster.local`:6379 \\ \u003e `dig +short redis-2.redis-headless.production-contract.svc.cluster.local`:6379 \\ \u003e `dig +short redis-3.redis-headless.production-contract.svc.cluster.local`:6379 \\ \u003e `dig +short redis-4.redis-headless.production-contract.svc.cluster.local`:6379 \\ \u003e `dig +short redis-5.redis-headless.production-contract.svc.cluster.local`:6379 \\ \u003e --cluster-replicas 1 ","date":"2021-07-13","objectID":"/%E5%85%B3%E4%BA%8Ekubernetes%E6%9E%84%E5%BB%BAredis%E9%9B%86%E7%BE%A4/:2:2","tags":["Kubernetes"],"title":"关于Kubernetes构建Redis集群","uri":"/%E5%85%B3%E4%BA%8Ekubernetes%E6%9E%84%E5%BB%BAredis%E9%9B%86%E7%BE%A4/"},{"categories":["Kubernetes"],"content":" 注意：请各位记住把所有离线包全拿到本地….. ","date":"2021-04-07","objectID":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/:0:0","tags":["Kubernetes"],"title":"Kubernetes-离线部署skywalking","uri":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/"},{"categories":["Kubernetes"],"content":"在线部署chartmuseum 直接使用最简单的 docker run 方式，使用local 本地存储方式，通过 -v 映射到宿主机 /opt/charts 更多支持安装方式见官网 mkdir /opt/charts docker run -d \\ -p 8080:8080 \\ -e DEBUG=1 \\ -e STORAGE=local \\ -e STORAGE_LOCAL_ROOTDIR=/charts \\ -v /opt/charts:/charts \\ chartmuseum/chartmuseum:latest ","date":"2021-04-07","objectID":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/:0:1","tags":["Kubernetes"],"title":"Kubernetes-离线部署skywalking","uri":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/"},{"categories":["Kubernetes"],"content":"下载Skywalking包 git clone https://github.com/apache/skywalking-kubernetes.git # 更换仓库 cd skywalking-kubernetes-master/chart/skywalking/ vim Chats.yaml dependencies: - name: elasticsearch version: ~7.12.1 # 官网的版本号为7.5.1 最新的elastic版本为7.12.1 repository: http://localhost:8080 # 修改为你本地的Repo地址 condition: elasticsearch.enabled ","date":"2021-04-07","objectID":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/:0:2","tags":["Kubernetes"],"title":"Kubernetes-离线部署skywalking","uri":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/"},{"categories":["Kubernetes"],"content":"添加elasticsearch仓库 helm repo add elastic https://helm.elastic.co helm pull elastic/elasticsearch # 把elasticsearch内容拉下来 ","date":"2021-04-07","objectID":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/:0:3","tags":["Kubernetes"],"title":"Kubernetes-离线部署skywalking","uri":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/"},{"categories":["Kubernetes"],"content":"上传本地Helm 以防万一请先安装helmpush插件 https://github.com/chartmuseum/helm-push helm repo add chartmuseum http://localhost:8080 curl --data-binary \"@elasticsearch-7.12.1.tgz\" http://localhost:8080/api/charts helm push /root/skywalking-kubernetes-master/chart/skywalking/ chartmuseum helm repo update # 更新仓库 你可以尝试搜索一下 保证仓库中存在elasticsarch和skywalking [root@k-master1 ~]# helm search repo NAME CHART VERSION APP VERSION DESCRIPTION chartmuseum/elasticsearch 7.12.1 7.12.1 Official Elastic helm chart for Elasticsearch chartmuseum/skywalking 4.0.0 Apache SkyWalking APM System ","date":"2021-04-07","objectID":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/:0:4","tags":["Kubernetes"],"title":"Kubernetes-离线部署skywalking","uri":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/"},{"categories":["Kubernetes"],"content":"部署skywalking cd skywalking-kubernetes/chart helm dep up skywalking # change the release name according to your scenario export SKYWALKING_RELEASE_NAME=skywalking # change the namespace according to your scenario export SKYWALKING_RELEASE_NAMESPACE=default helm install \"${SKYWALKING_RELEASE_NAME}\" skywalking -n \"${SKYWALKING_RELEASE_NAMESPACE}\" \\ --set oap.image.tag=8.1.0-es7 \\ --set oap.storageType=elasticsearch7 \\ --set ui.image.tag=8.1.0 \\ --set elasticsearch.imageTag=7.5.1 helm uninstall skywalking # 卸载skywalking ","date":"2021-04-07","objectID":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/:0:5","tags":["Kubernetes"],"title":"Kubernetes-离线部署skywalking","uri":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/"},{"categories":["Kubernetes"],"content":"准备离线镜像 busybox:1.30 docker.elastic.co/elasticsearch/elasticsearch:7.5.1 apache/skywalking-oap-server:8.1.0-es7 apache/skywalking-ui:8.1.0 chartmuseum/chartmuseum:latest # 然后打包 上传....就OK ","date":"2021-04-07","objectID":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/:0:6","tags":["Kubernetes"],"title":"Kubernetes-离线部署skywalking","uri":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/"},{"categories":["Kubernetes"],"content":"Helm中的Elasticsearch可能会存在问题 你们也可以用我的这个elasticsearch配置 注意修改PVC kind: StatefulSet apiVersion: apps/v1 metadata: name: elasticsearch-master namespace: default labels: app: elasticsearch-master app.kubernetes.io/managed-by: Helm chart: elasticsearch heritage: Helm release: skywalking annotations: esMajorVersion: '7' meta.helm.sh/release-name: skywalking meta.helm.sh/release-namespace: default spec: replicas: 3 selector: matchLabels: app: elasticsearch-master template: metadata: name: elasticsearch-master creationTimestamp: null labels: app: elasticsearch-master chart: elasticsearch heritage: Helm release: skywalking spec: initContainers: - name: configure-sysctl image: 'docker.elastic.co/elasticsearch/elasticsearch:7.5.1' command: - sysctl - '-w' - vm.max_map_count=262144 resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File imagePullPolicy: IfNotPresent securityContext: privileged: true runAsUser: 0 containers: - name: elasticsearch image: 'docker.elastic.co/elasticsearch/elasticsearch:7.5.1' ports: - name: http containerPort: 9200 protocol: TCP - name: transport containerPort: 9300 protocol: TCP volumeMounts: - name: datadir mountPath: /usr/share/elasticsearch/data env: - name: node.name valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name - name: cluster.initial_master_nodes value: \u003e- elasticsearch-master-0,elasticsearch-master-1,elasticsearch-master-2, - name: discovery.seed_hosts value: elasticsearch-master-headless - name: cluster.name value: elasticsearch - name: network.host value: 0.0.0.0 - name: ES_JAVA_OPTS value: '-Xmx1g -Xms1g' - name: node.data value: 'true' - name: node.ingest value: 'true' - name: node.master value: 'true' resources: limits: cpu: '1' memory: 2Gi requests: cpu: 100m memory: 2Gi readinessProbe: exec: command: - sh - '-c' - \u003e #!/usr/bin/env bash -e # If the node is starting up wait for the cluster to be ready (request params: 'wait_for_status=green\u0026timeout=1s' ) # Once it has started only check that the node itself is responding START_FILE=/tmp/.es_start_file http () { local path=\"${1}\" if [ -n \"${ELASTIC_USERNAME}\" ] \u0026\u0026 [ -n \"${ELASTIC_PASSWORD}\" ]; then BASIC_AUTH=\"-u ${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}\" else BASIC_AUTH='' fi curl -XGET -s -k --fail ${BASIC_AUTH} http://127.0.0.1:9200${path} } if [ -f \"${START_FILE}\" ]; then echo 'Elasticsearch is already running, lets check the node is healthy and there are master nodes available' http \"/_cluster/health?timeout=0s\" else echo 'Waiting for elasticsearch cluster to become cluster to be ready (request params: \"wait_for_status=green\u0026timeout=1s\" )' if http \"/_cluster/health?wait_for_status=green\u0026timeout=1s\" ; then touch ${START_FILE} exit 0 else echo 'Cluster is not yet ready (request params: \"wait_for_status=green\u0026timeout=1s\" )' exit 1 fi fi initialDelaySeconds: 10 timeoutSeconds: 5 periodSeconds: 10 successThreshold: 3 failureThreshold: 3 terminationMessagePath: /dev/termination-log terminationMessagePolicy: File imagePullPolicy: IfNotPresent securityContext: capabilities: drop: - ALL runAsUser: 1000 runAsNonRoot: true restartPolicy: Always terminationGracePeriodSeconds: 120 dnsPolicy: ClusterFirst securityContext: runAsUser: 1000 fsGroup: 1000 affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: - elasticsearch-master topologyKey: kubernetes.io/hostname schedulerName: default-scheduler volumeClaimTemplates: - metadata: name: datadir annotations: volume.beta.kubernetes.io/storage-class: \"managed-nfs-storage-class\" spec: accessModes: [\"ReadWriteMany\"] resources: requests: storage: 10Gi serviceName: elasticsearch-master-headless podManagementPolicy: Parallel updateStrategy: type: RollingUpdate revisionHistoryLimit: 10 ","date":"2021-04-07","objectID":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/:0:7","tags":["Kubernetes"],"title":"Kubernetes-离线部署skywalking","uri":"/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking/"},{"categories":["Kubernetes"],"content":"ConfigMap了解 描述信息ConfigMap 功能在 Kubernetes1.2 版本中引入，许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。ConfigMap API 给我们提供了向容器中注入配置信息的机制，ConfigMap 可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制大对象 有点儿类似于zookeeper nacos这种服务注册中心 ","date":"2021-03-25","objectID":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:0:0","tags":["Kubernetes"],"title":"Kubernetes持久化配置文件","uri":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Kubernetes"],"content":"configMap的创建 使用目录创建 $ ls docs/user-guide/configmap/kubectl/ game.properties ui.properties $ cat docs/user-guide/configmap/kubectl/game.properties enemies=aliens lives=3 enemies.cheat=true enemies.cheat.level=noGoodRotten secret.code.passphrase=UUDDLRLRBABAS secret.code.allowed=true secret.code.lives=30 $ cat docs/user-guide/configmap/kubectl/ui.properties color.good=purple color.bad=yellow allow.textmode=true how.nice.to.look=fairlyNice $ kubectl create configmap game-config --from-file=docs/user-guide/configmap/kubectl --from-file指定的目录下的所有文件都会配置在configMap中以,以键值对的方式存在. ","date":"2021-03-25","objectID":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:1:0","tags":["Kubernetes"],"title":"Kubernetes持久化配置文件","uri":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Kubernetes"],"content":"使用文件创建 只要指定为一个文件就可以从单个文件中创建 ConfigMap kubectl create configmap game-config-2 --from-file=docs/user-guide/configmap/kubectl/game.properties game.properties是一个文件 ","date":"2021-03-25","objectID":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:2:0","tags":["Kubernetes"],"title":"Kubernetes持久化配置文件","uri":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Kubernetes"],"content":"使用字面值创建 kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm special.how键名 very键值 ","date":"2021-03-25","objectID":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:3:0","tags":["Kubernetes"],"title":"Kubernetes持久化配置文件","uri":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Kubernetes"],"content":"Pod中使用ConfigMap 使用ConfigMap代替环境变量 apiVersion: v1 kind: ConfigMap metadata: name: special-config namespace: default data: special.how: very special.type: charm apiVersion: v1 kind: ConfigMap metadata: name: env-config namespace: default data: log_level: INFO apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-api image: nginx:1.7.9 command: [\"/bin/sh\",\"-c\",\"env\"] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: spacial-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type envFrom: - configMapRef name: env-config restartPolicy: Never ","date":"2021-03-25","objectID":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:4:0","tags":["Kubernetes"],"title":"Kubernetes持久化配置文件","uri":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Kubernetes"],"content":"使用configMap设置命令行参数 apiVersion: v1 kind: ConfigMap metadata: name: special-config namespace: default data: special.how: very special.type: charm apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-api image: nginx:1.7.9 command: [\"/bin/sh\",\"-c\",\"echo $($SPECIAL_LEVEL_KEY)$(SPECIAL_TYPE_KEY)\"] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: spacial-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type envFrom: - configMapRef name: env-config restartPolicy: Never ","date":"2021-03-25","objectID":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:5:0","tags":["Kubernetes"],"title":"Kubernetes持久化配置文件","uri":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Kubernetes"],"content":"通过数据卷插件方式使用configMap 在数据卷里面使用configMap,有不同的选项。最基本的就是将文件填入数据卷中,键就是文件名，键值就是文件内容 apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-api image: nginx:1.7.9 command: [\"/bin/sh\",\"-c\",\"cat /etc/config/special.how\"] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config restartPolicy: Never ","date":"2021-03-25","objectID":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:6:0","tags":["Kubernetes"],"title":"Kubernetes持久化配置文件","uri":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Kubernetes"],"content":"configMap的热更新 apiVersion: v1 kind: ConfigMap metadata: name: log-config namespace: default data: log_level: INFO --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: my-nginx spec: replicas: 1 template: metadata: labels: app: mynginx spec: containers: - name: my-nginx image: nginx:1.7.9 ports: - containerPort: 80 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap name: log-config 修改configMap kubectl edit configmap log-comfig 修改log_level的值为DEBUG等待大概10秒 apiVersion: v1 kind: ConfigMap metadata: name: log-config namespace: default data: log_level: DEBUG 滚动更新Pod kubectl patch deployment my-nginx --patch'{\"spec\": {\"template\": {\"metadata\": {\"annotations\":{\"version/config\": \"20190411\" }}}}}' ","date":"2021-03-25","objectID":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:7:0","tags":["Kubernetes"],"title":"Kubernetes持久化配置文件","uri":"/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"修复解决漏洞 解决OPenssh7.x以前的绝大多数问题 OpenSSH 命令注入漏洞(CVE-2020-15778) OpenSSH 用户枚举漏洞(CVE-2018-15919) OpenSSH 安全漏洞(CVE-2017-15906) 升级能解决绝大多数的问题 ","date":"2021-03-12","objectID":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/:1:0","tags":["Linux"],"title":"SSH漏洞修复-升级openssh","uri":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/"},{"categories":["Linux"],"content":"安装依赖环境 yum -y install rpm-build gcc gcc-c++ glibc glibc-devel openssl-devel openssl prce pcre-devel zlib zlib-devel make wget krb5-devel pam-devel libX11-devel xmkmf libXt-devel initscripts libXt-devel imake gtk2-devel ","date":"2021-03-12","objectID":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/:2:0","tags":["Linux"],"title":"SSH漏洞修复-升级openssh","uri":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/"},{"categories":["Linux"],"content":"下载Openssh和Openssl wget ftp://mirrors.sonic.net/pub/OpenBSD/OpenSSH/portable/openssh-8.4p1.tar.gz wget https://www.openssl.org/source/openssl-1.1.1h.tar.gz ","date":"2021-03-12","objectID":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/:3:0","tags":["Linux"],"title":"SSH漏洞修复-升级openssh","uri":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/"},{"categories":["Linux"],"content":"安装Openssl tar -zxf openssl-1.1.1h.tar.gz cd openssl-1.1.1h ./config --prefix=/usr/local/openssl-1.1.1 -d shared make install echo \"/usr/local/openssl-1.1.1/lib\" \u003e\u003e /etc/ld.so.conf ","date":"2021-03-12","objectID":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/:4:0","tags":["Linux"],"title":"SSH漏洞修复-升级openssh","uri":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/"},{"categories":["Linux"],"content":"安装Openssh tar -zxf openssh-8.4p1.tar.gz cd openssh-8.4p1 mv /etc/ssh/ /home/ssh-back ./configure --prefix=/usr/local/openssh-8.4 --sysconfdir=/etc/ssh --with-ssl-dir=/usr/local/openssl-1.1.1/ --with-zlib make install ","date":"2021-03-12","objectID":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/:5:0","tags":["Linux"],"title":"SSH漏洞修复-升级openssh","uri":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/"},{"categories":["Linux"],"content":"备份SSH mv /usr/sbin/sshd /home/sshd_back cp -rf /usr/local/openssh-8.4/sbin/sshd /usr/sbin/sshd mv /usr/bin/ssh /home/ssh_back cp -rf /usr/local/openssh-8.4/bin/ssh /usr/bin/ mv /usr/bin/ssh-keygen /home/ssh-keygen_back cp -rf /usr/local/openssh-8.4/bin/ssh-keygen /usr/bin/ ","date":"2021-03-12","objectID":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/:6:0","tags":["Linux"],"title":"SSH漏洞修复-升级openssh","uri":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/"},{"categories":["Linux"],"content":"启动sshd服务 你可能会遇到sshd无法启动 sshd.service start operation timed out. Terminating 解决方法 systemctl stop sshd rm -rf /lib/systemd/system/sshd.service systemctl daemon-reload # openssh-8.4p1是你最开始tar解压的目录,而不是安装后的目录 cp openssh-8.4p1/contrib/redhat/sshd.init /etc/init.d/sshd /etc/init.d/sshd restart 或者 systemctl start sshd systemctl enable sshd ","date":"2021-03-12","objectID":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/:7:0","tags":["Linux"],"title":"SSH漏洞修复-升级openssh","uri":"/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh/"},{"categories":["Kubernetes"],"content":"持久化存储-NFS Emptydir：是本地存储,Pod重启,数据不存在了 Nfs：网络存储,Pod重启后,数据还是存在的 ","date":"2021-03-04","objectID":"/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80/:1:0","tags":["Kubernetes"],"title":"Kubernetes之持久化存储数据(一)","uri":"/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80/"},{"categories":["Kubernetes"],"content":"部署NFS服务器 可以单独设置一台服务器为NFS服务器 yum -y install nfs-utils systemctl start nfs ","date":"2021-03-04","objectID":"/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80/:2:0","tags":["Kubernetes"],"title":"Kubernetes之持久化存储数据(一)","uri":"/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80/"},{"categories":["Kubernetes"],"content":"设置挂载目录 mkdir /data/k8s_nfs -p vim /etc/exports /data/k8s_nfs *(rw,no_root_squash) ","date":"2021-03-04","objectID":"/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80/:3:0","tags":["Kubernetes"],"title":"Kubernetes之持久化存储数据(一)","uri":"/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80/"},{"categories":["Kubernetes"],"content":"在K8S节点上安装NFS yum -y install nfs-utils ","date":"2021-03-04","objectID":"/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80/:4:0","tags":["Kubernetes"],"title":"Kubernetes之持久化存储数据(一)","uri":"/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80/"},{"categories":["Kubernetes"],"content":"部署应用挂载NFS vim nginx-nfs.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-dep1 spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx volumeMounts: - name: wwwroot mountPath: /usr/share/nginx/html # NFS挂载到内部的目录 ports: - containerPort: 80 volumes: - name: wwwroot nfs: server: 172.16.87.100 path: /data/k8s_nfs # NFS文件夹地址 kubectl apply -f nginx-nfs.yaml # 注意,你需要进入到/data/k8s_nfs创建一个Index.html然后进入到容器中才能验证效果 ","date":"2021-03-04","objectID":"/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80/:5:0","tags":["Kubernetes"],"title":"Kubernetes之持久化存储数据(一)","uri":"/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80/"},{"categories":["Kubernetes"],"content":"概念 Helm是一个Kubernetes的包管理工具,就像Linux下的包管理工具,可以很方便的将之前打包好的yaml文件部署到Kubernetes上. ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:1:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"Helm可以解决那些问题 使用Helm可以把这些yaml作为一个整体管理 实现yaml高效复用 Helm应用级别的版本管理 ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:2:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"Helm基础 Charts: Helm使用的打包格式，一个Chart包含了一组K8s资源集合的描述文件。Chart有特定的文件目录结构，如果开发者想自定义一个新的 Chart，只需要使用Helm create命令生成一个目录结构即可进行开发。 Release: 通过Helm将Chart部署到 K8s集群时创建的特定实例，包含了部署在容器集群内的各种应用资源。 Tiller: Helm 2.x版本中，Helm采用Client/Server的设计，Tiller就是Helm的Server部分，需要具备集群管理员权限才能安装到K8s集群中运行。Tiller与Helm client进行交互，接收client的请求，再与K8s API Server通信，根据传递的Charts来生成Release。而在最新的Helm 3.x中，据说是为了安全性考虑移除了Tiller。 Chart Repository: Helm Chart包仓库，提供了很多应用的Chart包供用户下载使用，官方仓库的地址是https://hub.helm.sh，可以在上面发现很多有意思的项目。之后我们会在官方hub找一个应用做个简单的Demo。 helm：一个命令行管理工具,用来进行配置。 ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:3:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"部署Helm 官网地址：https://helm.sh/zh/ wget https://get.helm.sh/helm-v3.5.2-linux-amd64.tar.gz tar -zxf helm-v3.5.2-linux-amd64.tar.gz mv linux-amd64/helm /usr/bin/ ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:4:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"配置Helm仓库 helm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts helm repo list # 查看helm仓库地址 helm repo update # 更新仓库地址 helm repo remove aliyun # 移除aliyun仓库 ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:5:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"使用Helm部署一个应用 helm search repo weave # 搜索一个weave应用 helm install docker-ui aliyun/weave-scope # 安装一个应用 helm list # 查看安装列表 helm status docker-ui # 查看状态 ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:6:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"修改weave的Yaml文件 由于服务没有对外暴露端口,所以需要修改Yaml文件 kubectl edit svc weave-scope-weave-scope type: NodePort # type改为NodePort http://172.16.87.10:31556/ # 访问NodePort端口即可 Chart 使用chart部署一个应用 ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:7:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"创建一个Chart helm create chart # 先创建一个chart模板 ├── chart ├── Chart.yaml # 当前chart的属性配置信息 ├── templates # 存放模板的目录 │ ├── deployment.yaml │ ├── _helpers.tpl │ ├── hpa.yaml │ ├── ingress.yaml │ ├── NOTES.txt │ ├── serviceaccount.yaml │ ├── service.yaml │ └── tests │ └── test-connection.yaml └── values.yaml # 定义全局变量的文件 ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:8:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"创建一个应用 cd templates/ # 进入到模板目录 kubectl create deployment web-server --image=nginx:1.7.9 --dry-run -o yaml \u003e deployment.yaml kubectl expose deployment web-server --port=80 --target-port=80 --type=NodePort --dry-run -o yaml \u003e service.yaml helm install web-server chart/ # 使用helm直接创建应用 ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:9:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"Chart应用升级 helm upgrade web-server chart/ Release \"web-server\" has been upgraded. Happy Helming! NAME: web-server LAST DEPLOYED: Sun Feb 28 17:40:39 2021 NAMESPACE: default STATUS: deployed REVISION: 2 TEST SUITE: None 通过Helm高效复用 通过传递参数,动态渲染模板,动态传入参数生成。 yaml中大体上有几个不同的地方 image tag label port replicas ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:10:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"在Value.yaml中定义变量 vim value.yaml # base Infomation replicas: 1 image: nginx tag: 1.7.9 label: nginx port: 80 ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:11:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"引入Value.yaml变量方式 通过表达式的方式进行适用全局变量 # {{.Values.Name}} # {{.Release.Name}} 取一个动态生成的名字. ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:12:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"修改Deployment.yaml vim templates/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: creationTimestamp: null labels: app: {{ .Values.label }} # 改动处 name: {{ .Release.Name }}-deployment # 改动处 spec: replicas: 1 selector: matchLabels: app: {{ .Values.label }} # 改动处 strategy: {} template: metadata: creationTimestamp: null labels: app: {{ .Values.label }} # 改动处 spec: containers: - image: {{ .Values.image }} # 改动处 resources: {} status: {} ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:13:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"修改Service.yaml vim templates/service.yaml apiVersion: v1 kind: Service metadata: creationTimestamp: null labels: app: {{ .Values.label }} # 改动处 name: {{ .Release.Name }}-svc # 修改处 spec: ports: - port: {{ .Values.port }} # 修改处 protocol: TCP targetPort: 80 selector: app: {{ .Values.label }} # 修改处 type: NodePort status: loadBalancer: {} ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:14:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"尝试运行应用 helm install --dry-run web2 charts/ # 起的名字叫web2 --dry-run：表示尝试运行 helm install web2 charts/ # 实际运行 ","date":"2021-03-02","objectID":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/:15:0","tags":["Kubernetes"],"title":"Kubernete-Helm包管理工具","uri":"/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/"},{"categories":["Kubernetes"],"content":"有状态和无状态的区别 无状态 认为Pod都是一样的 没有顺序要求 不用考虑在哪个Node运行 随意进行伸缩和扩展 有状态 有关无状态的因素都需要考虑 让每个Pod都是独立的,保持Pod启动顺序的唯一性 唯一的网络标识符,持久化存储数据 有序化,例如MYSQL主从 无头Service ClusterIP：None ","date":"2021-03-01","objectID":"/kubernete-pod%E6%93%8D%E4%BD%9C%E7%AE%A1%E7%90%86/:0:0","tags":["Kubernetes"],"title":"Kubernete-Pod操作管理","uri":"/kubernete-pod%E6%93%8D%E4%BD%9C%E7%AE%A1%E7%90%86/"},{"categories":["Kubernetes"],"content":"部署StatefulSet # 首先构建一个无头Service apiVersion: v1 kind: Service metadata: name: nginx labels: app: nginx spec: ports: - port: 80 name: web clusterIP: None selector: app: nginx --- apiVersion: apps/v1 kind: StatefulSet metadata: name: nginx-statefulset namespace: default spec: serviceName: nginx replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 ","date":"2021-03-01","objectID":"/kubernete-pod%E6%93%8D%E4%BD%9C%E7%AE%A1%E7%90%86/:1:0","tags":["Kubernetes"],"title":"Kubernete-Pod操作管理","uri":"/kubernete-pod%E6%93%8D%E4%BD%9C%E7%AE%A1%E7%90%86/"},{"categories":["Kubernetes"],"content":"部署守护进程 在每个Node上运行一个Pod,新加入的node也同样运行一个Pod在里面 apiVersion: apps/v1 kind: DaemonSet metadata: name: ds-test labels: app: filebeat spec: selector: matchLabels: app: filebeat template: metadata: labels: app: filebeat spec: containers: - name: logs image: nginx ports: - containerPort: 80 volumeMounts: - name: varlog mountPath: /tmp/log volumes: - name: varlog hostPath: path: /var/log ","date":"2021-03-01","objectID":"/kubernete-pod%E6%93%8D%E4%BD%9C%E7%AE%A1%E7%90%86/:2:0","tags":["Kubernetes"],"title":"Kubernete-Pod操作管理","uri":"/kubernete-pod%E6%93%8D%E4%BD%9C%E7%AE%A1%E7%90%86/"},{"categories":["Kubernetes"],"content":"Job与Cronjob Job(一次性任务) apiVersion: batch/v1 kind: Job metadata: name: pi spec: template: spec: containers: - name: pi image: perl command: [\"perl\",\"-Mbignum=bpi\",\"-wle\",\"print bpi(2000)\"] restartPolicy: Never backoffLimit: 4 # 失败后尝试执行4次 Cronjob(定时任务) apiVersion: batch/v1beta1 kind: CronJob metadata: name: hallo spec: schedule: \"*/1 * * * *\" jobTemplate: spec: template: spec: containers: - name: hello image: busybox args: - /bin/sh - -c - date; echo Hello form the Kubernetes Cluster messages restartPolicy: OnFailure ","date":"2021-03-01","objectID":"/kubernete-pod%E6%93%8D%E4%BD%9C%E7%AE%A1%E7%90%86/:3:0","tags":["Kubernetes"],"title":"Kubernete-Pod操作管理","uri":"/kubernete-pod%E6%93%8D%E4%BD%9C%E7%AE%A1%E7%90%86/"},{"categories":["Kubernetes"],"content":"Deployment应用场景 部署无状态应用Web或者微服务 管理Pod和ReplicaSet 部署、滚动升级 ","date":"2021-02-28","objectID":"/kubernetes-deployment/:1:0","tags":["Kubernetes"],"title":"Kubernetes-Deployment","uri":"/kubernetes-deployment/"},{"categories":["Kubernetes"],"content":"Pod资源限制 resource: # 调度时候资源配置大小 requests: memory: \"64Mi\" cpu: \"250m\" limits: # Pod的最大值 memory: \"64Mi\" cpu: \"250m\" ","date":"2021-02-28","objectID":"/kubernetes-deployment/:2:0","tags":["Kubernetes"],"title":"Kubernetes-Deployment","uri":"/kubernetes-deployment/"},{"categories":["Kubernetes"],"content":"健康检查 livenessProbe: exec: command: - cat - /tmp/healthy initalDelaySeconds: 5 periodSeconds: 5 livenessProbe: 存活检查 readinessProbe:就绪检查 检测方式如下 HTTPGET：通过发送HTTP请求进行检测,范围200-400为正确 EXEC：通过进入容器执行命令进行检测 TCPSocker：通过建立Socker连接来进行检测 ","date":"2021-02-28","objectID":"/kubernetes-deployment/:3:0","tags":["Kubernetes"],"title":"Kubernetes-Deployment","uri":"/kubernetes-deployment/"},{"categories":["Kubernetes"],"content":"生成Yaml文件 kubectl create deployment web --image=nginx:1.7.9 -o yaml \u003e web.yaml ","date":"2021-02-28","objectID":"/kubernetes-deployment/:4:0","tags":["Kubernetes"],"title":"Kubernetes-Deployment","uri":"/kubernetes-deployment/"},{"categories":["Kubernetes"],"content":"对外暴露端口 kubectl expose deployment nginx --port=80 --type=NodePort --target-port=80 ","date":"2021-02-28","objectID":"/kubernetes-deployment/:5:0","tags":["Kubernetes"],"title":"Kubernetes-Deployment","uri":"/kubernetes-deployment/"},{"categories":["Kubernetes"],"content":"应用升级(更新镜像) kubectl set image deployment nginx nginx=nginx:1.8.1 kubectl rollout status deployment nginx # 查看升级状态 kubectl rollout history deployment nginx # 查看升级版本历史 kubectl rollout undo deployment nginx # 回滚到上一个版本 kubectl rollout undo deployment nginx --to-revision=3 # 指定版本回滚 ","date":"2021-02-28","objectID":"/kubernetes-deployment/:6:0","tags":["Kubernetes"],"title":"Kubernetes-Deployment","uri":"/kubernetes-deployment/"},{"categories":["Kubernetes"],"content":"动态扩容(属于弹性伸缩一部分) kubectl scale deployment nginx --replicas=4 # 扩容副本数量为4 ","date":"2021-02-28","objectID":"/kubernetes-deployment/:7:0","tags":["Kubernetes"],"title":"Kubernetes-Deployment","uri":"/kubernetes-deployment/"},{"categories":["Kubernetes"],"content":"Pod的重启策略 Pod的重启策略（RestartPolicy）应用与Pod内所有容器，并且仅在Pod所处的Node上由kubelet进行判断和重启操作。当某个容器异常退出或者健康检查失败时，kubelet将根据RestartPolicy的设置来进行相应的操作。 Pod的重启策略包括：Always、OnFailure和Never，默认值为Always。 Always：当容器失效时，由kubelet自动重启该容器。 OnFailure：当容器终止运行且退出码不为0时，由kubelet自动重启该容器。 Never：不论容器运行状态如何，kubelet都不会重启该容器。 ","date":"2021-02-28","objectID":"/kubernetes-deployment/:8:0","tags":["Kubernetes"],"title":"Kubernetes-Deployment","uri":"/kubernetes-deployment/"},{"categories":["Redis"],"content":"Redis Cluster（Redis集群）简介 redis是一个开源的key value存储系统，受到了广大互联网公司的青睐。redis3.0版本之前只支持单例模式，在3.0版本及以后才支持集群，我这里用的是redis3.0.0版本； redis集群采用P2P模式，是完全去中心化的，不存在中心节点或者代理节点； redis集群是没有统一的入口的，客户端（client）连接集群的时候连接集群中的任意节点（node）即可，集群内部的节点是相互通信的（PING-PONG机制），每个节点都是一个redis实例； 为了实现集群的高可用，即判断节点是否健康（能否正常使用），redis-cluster有这么一个投票容错机制：如果集群中超过半数的节点投票认为某个节点挂了，那么这个节点就挂了（fail）。这是判断节点是否挂了的方法； 那么如何判断集群是否挂了呢? -\u003e 如果集群中任意一个节点挂了，而且该节点没有从节点（备份节点），那么这个集群就挂了。这是判断集群是否挂了的方法； 那么为什么任意一个节点挂了（没有从节点）这个集群就挂了呢？ -\u003e 因为集群内置了16384个slot（哈希槽），并且把所有的物理节点映射到了这16384[0-16383]个slot上，或者说把这些slot均等的分配给了各个节点。当需要在Redis集群存放一个数据（key-value）时，redis会先对这个key进行crc16算法，然后得到一个结果。再把这个结果对16384进行求余，这个余数会对应[0-16383]其中一个槽，进而决定key-value存储到哪个节点中。所以一旦某个节点挂了，该节点对应的slot就无法使用，那么就会导致集群无法正常工作。 综上所述，每个Redis集群理论上最多可以有16384个节点。 Redis集群至少需要3个节点，因为投票容错机制要求超过半数节点认为某个节点挂了该节点才是挂了，所以2个节点无法构成集群。 要保证集群的高可用，需要每个节点都有从节点，也就是备份节点，所以Redis集群至少需要6台服务器。因为我没有那么多服务器，也启动不了那么多虚拟机，所在这里搭建的是伪分布式集群，即一台服务器虚拟运行6个redis实例，修改端口号为（7001-7006）1+1+1+1+1+1 = 6 ","date":"2021-02-19","objectID":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:1:0","tags":["Redis"],"title":"Redis集群搭建","uri":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"搭建集群 Redis版本6.0.8 Gcc7x.x.x ","date":"2021-02-19","objectID":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:0","tags":["Redis"],"title":"Redis集群搭建","uri":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"1.0 创建目录 mkdir /usr/local/redis-cluster cd /usr/local/redis-cluster wget http://download.redis.io/releases/redis-6.0.8.tar.gz mkdir {7001..7006} ","date":"2021-02-19","objectID":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:1","tags":["Redis"],"title":"Redis集群搭建","uri":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"1.1 复制配置文件 tar -zxf redis-6.0.8.tar.gz cd redis-6.0.8/ \u0026\u0026 make install cp -a redis-6.0.8/redis.conf 7001/ # 以此类推 cp -a redis-6.0.8/redis.conf 7002/ 如果你不想编译安装的话,你可以把redis中的/bin目录的命令移动到每个node节点文件夹中，这样以方便你使用redis-server命令 ","date":"2021-02-19","objectID":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:2","tags":["Redis"],"title":"Redis集群搭建","uri":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"1.2 编辑配置文件 此文件内容为集群模式最小配置文件内容. vim 7001/redis.conf # 以此类推,记得更改端口号和日志文件 bind 127.0.0.1 # IP可更换为内网IP port 7001 cluster-enabled yes cluster-config-file nodes7001.conf cluster-node-timeout 5000 appendonly yes daemonize yes logfile /usr/local/redis-cluster/7001/redis-7001.log maxmemory 4GB requirepass ******* dir /usr/local/redis-cluster/7001 masterauth **** port 7001 Redis运行端口 cluster-enabled yes启用集群模式 cluster-config-file nodes.conf集群模式配置文件 cluster-node-timeout 5000节点的超时时限 appendonly yes开启AOF持久化 daemonize yes开启后台运行 maxmemory 4GBRedis最大可用内存 requirepass连接Redis客户端密码 masterauth Slave连接master需要的认证 ","date":"2021-02-19","objectID":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:3","tags":["Redis"],"title":"Redis集群搭建","uri":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"1.3 启动集群 自己建一个启动脚本,要不然手动启动太麻烦了 #!/bin/bash redis-server /usr/local/redis-cluster/7001/redis.conf redis-server /usr/local/redis-cluster/7002/redis.conf redis-server /usr/local/redis-cluster/7003/redis.conf redis-server /usr/local/redis-cluster/7004/redis.conf redis-server /usr/local/redis-cluster/7005/redis.conf redis-server /usr/local/redis-cluster/7006/redis.conf chmod +x start.sh sh start.sh [root@bogon redis-cluster]# ps -aux | grep redis root 65558 0.0 0.0 64864 6256 ? Ssl 09:54 0:00 redis-server *:7001 [cluster] root 65564 0.0 0.0 61792 4760 ? Ssl 09:54 0:00 redis-server *:7002 [cluster] root 65566 0.0 0.0 61792 4736 ? Ssl 09:54 0:00 redis-server *:7003 [cluster] root 65572 0.0 0.0 61792 4712 ? Ssl 09:54 0:00 redis-server *:7004 [cluster] root 65578 0.0 0.0 61792 4704 ? Ssl 09:54 0:00 redis-server *:7005 [cluster] root 65580 0.0 0.0 61792 4780 ? Ssl 09:54 0:00 redis-server *:7006 [cluster] ","date":"2021-02-19","objectID":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:4","tags":["Redis"],"title":"Redis集群搭建","uri":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"1.4 加入集群 现在我们有许多实例正在运行，我们需要通过向节点写入一些有意义的配置来创建集群。 如果您使用的是Redis 5或更高版本，这很容易完成，因为嵌入到中的Redis Cluster命令行实用程序为我们提供了帮助，该实用程序redis-cli可用于创建新集群，检查或重新分片现有集群等。 对于Redis版本3或4，有一个称为的旧工具redis-trib.rb，它非常相似。您可以src在Redis源代码分发的目录中找到它。您需要安装redisgem才能运行redis-trib。 如果你是用的是Redis3.x或者4.x 请前往官网链接 点我进入 此方法为Redis5或者更高版本 redis-cli --cluster create 127.0.0.1:7001 127.0.0.1:7002 \\ 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 127.0.0.1:7006 \\ --cluster-replicas 1 Can I set the above configuration? (type 'yes' to accept): yes --cluster-replicas 1给Master只分配一个slave ","date":"2021-02-19","objectID":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:5","tags":["Redis"],"title":"Redis集群搭建","uri":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"1.5 连接集群 redis-cli -c -p 7001 -a *** 127.0.0.1:7001\u003e info # Replication role:master connected_slaves:1 127.0.0.1:7001\u003e set Host Linux7 -\u003e Redirected to slot [16156] located at 127.0.0.1:7003 OK -a是你设置的requirepass密码 注意：出现connected_slaves:1 表示连接到了一个从服务器 如果为0 请查看服务器错误日志 ","date":"2021-02-19","objectID":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:6","tags":["Redis"],"title":"Redis集群搭建","uri":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"1.6 故障切换 连接到7003的从服务器7005 查看数据是否同步 redis-cli -c -p 7005 -a *** master_host:127.0.0.1 master_port:7003 127.0.0.1:7005\u003e get Host \"Linux7\" 宕机7003服务器 [root@bogon redis-cluster]# ps -aux | grep 7003 root 70467 0.2 0.0 64352 5120 ? Ssl 11:20 0:01 redis-server *:7003 [cluster] root 70871 0.0 0.0 12112 1052 pts/0 S+ 11:29 0:00 grep --color=auto 7003 [root@bogon redis-cluster]# kill -15 70467 通过info发现7005已经成为主服务器 127.0.0.1:7005\u003e info # Replication role:master connected_slaves:0 再次启动7003发现已经更改为从服务器，并且已经被7005连接到 127.0.0.1:7005\u003e # Replication role:master connected_slaves:1 ","date":"2021-02-19","objectID":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:7","tags":["Redis"],"title":"Redis集群搭建","uri":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"总结 首先 先说结论：redis集群无法保证强一致性 既然无法保证强一致性，也就是说有可能出现写数据丢失的情况，比如一个客户端发一个写请求给master，master再同步到slave之前就给client一个回执。这个时候会存在一个时间窗口，master 和 slave之间的数据是不一致的。但是redis的最终一致性会使master和slave的数据是最终一致。 另外还有一个可能，在客户端收到了master的一个写请求回执之后，此时master准备把数据同步到slave，同步之前突然挂了，那么这个数据真的就是会丢失了。 如果为了保证强一致，比如我们每秒刷盘进行持久化，那么牺牲了这个吞吐量，就特别类似我们常说的同步复制了。但是redis集群是没有实现强一致的。 1、redis保证最终一致性 2、用最终一致性换取了高吞吐量 3、主节点挂了的时候，如果数据没有同步到备节点，是会出现数据丢失的情况 4、发生网络分区的时候也可能会丢数据，这个时候有个node timeout时间概念 ","date":"2021-02-19","objectID":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:3:0","tags":["Redis"],"title":"Redis集群搭建","uri":"/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Python"],"content":"什么是反射? 反射的概念是由Smith在1982年首次提出的，主要是指程序可以访问、检测和修改它本身状态或行为的一种能力（自省）。这一概念的提出很快引发了计算机科学领域关于应用反射性的研究。它首先被程序语言的设计领域所采用,并在Lisp和面向对象方面取得了成绩。 简而言之 ：反射就是通过字符串的去操作对象中的属性 ","date":"2021-01-25","objectID":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/:1:0","tags":["Python"],"title":"Python-方法反射","uri":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/"},{"categories":["Python"],"content":"反射的方法 getattr() : 用于返回一个对象属性值。 hasattr(): 用于判断对象是否包含对应的属性 delattr(): 用于删除属性。 setattr(): 用于设置属性值，该属性不一定是存在的。 ","date":"2021-01-25","objectID":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/:2:0","tags":["Python"],"title":"Python-方法反射","uri":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/"},{"categories":["Python"],"content":"实例化对象 class Person(): def __init__(self,name,age): self.name = name self.age = age def walk(self): print(\"%s is walking...\"% self.name) def talk(self): print(\"%s 调用成功\" % self.name) p = Person(\"Hopc\",'22') ","date":"2021-01-25","objectID":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/:3:0","tags":["Python"],"title":"Python-方法反射","uri":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/"},{"categories":["Python"],"content":"getattr()方法 a = getattr(p,\"age\") print(\"getattr调用: \",a) getattr调用: 22 # 此为打印结果 # 如果没有age这这个属性则会报错 AttributeError: 'Person' object has no attribute 'age' ","date":"2021-01-25","objectID":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/:3:1","tags":["Python"],"title":"Python-方法反射","uri":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/"},{"categories":["Python"],"content":"hasattr()方法 if hasattr(p,\"name2\"): # 通过hasattr判断p实例中的name2属性 print(\"successSecret\") else: print(\"None\") ","date":"2021-01-25","objectID":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/:3:2","tags":["Python"],"title":"Python-方法反射","uri":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/"},{"categories":["Python"],"content":"setattr方法 \"static属性\" setattr(p,\"sex\",\"Famale\") print(p.sex) Famale # 此为打印结果 \"设置一个方法\" setattr(p,\"talk\",talk) p.talk(p) # 需要再把p对象传入才能调用 Hopc 调用成功 # 此为打印结果 \"对类直接进行绑定\" setattr(Person,\"talks\",talk) p.talks() Hopc is walking... ","date":"2021-01-25","objectID":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/:3:3","tags":["Python"],"title":"Python-方法反射","uri":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/"},{"categories":["Python"],"content":"delattr方法 del p.age p.age() AttributeError: 'Person' object has no attribute 'age' ","date":"2021-01-25","objectID":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/:3:4","tags":["Python"],"title":"Python-方法反射","uri":"/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84/"},{"categories":["Python"],"content":"不过，抢票软件并非万能，巧coder难为无票之炊，除了技术，你可能还需要一点点运气。 无论采取哪种交通方式，祝大家都能开开心心过年回家，平平安安回来搬砖~ 原生项目地址 其实作者已经没有在维护了… 我只是拿剩下的进行了二开 多多少少会有些问题..🐷 ","date":"2021-01-11","objectID":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/:0:0","tags":["实用工具","Python"],"title":"12306抢票小助手","uri":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/"},{"categories":["Python"],"content":"支持的Python版本 2.7.10 - 2.7.15(目前根据作者代码来看已经不支持) 3.6 - 3.7.4(推荐) 2.7.9(不太确定) 3.8.x(今天测试-不支持) ","date":"2021-01-11","objectID":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/:1:0","tags":["实用工具","Python"],"title":"12306抢票小助手","uri":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/"},{"categories":["Python"],"content":"已实现功能 自动打码 自动登录 准点预售和捡漏 智能候补 邮件通知 server酱通知 短信通知提示(2020-1-11日新增) 更新Token参数(优先调用) 预获取Cookie(待增加) 设置支付接口(直接调用支付-(这个暂且不太想考虑了...有些不安全)) ","date":"2021-01-11","objectID":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/:2:0","tags":["实用工具","Python"],"title":"12306抢票小助手","uri":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/"},{"categories":["Python"],"content":"依赖库 验证码目前可以本地识别，需要下载模型，放于项目根目录 git clone https://github.com/testerSunshine/12306model.git # 依赖模型 自托管云打码服务器搭建：12306_code_server version: \"3\" services: code_12306: image: yinaoxiong/12306_code_server ports: - 5002:80 #可以根据需要修改端口 environment: - WORKERS=1 #gunicorn works 默认为1可以根据服务器配置自行调整 restart: always 项目依赖[requirements.txt] Python依赖--with-ssl ","date":"2021-01-11","objectID":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/:3:0","tags":["实用工具","Python"],"title":"12306抢票小助手","uri":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/"},{"categories":["Python"],"content":"部署教程 推荐root用户直接安装 # 这个项目是我自己的 git clone https://gitee.com/lanmy/why_12305.git cd why_12305 pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt 关于无法安装tensorflow 1. tensorflow的兼容版本 1.14.0rc\\1.14.0rc\\1.15.0\\1.15.0rc 2.如果出现以下问题 ERROR: Could not find a version that satisfies the requirement tensorflow==1.15.0rc ERROR: No matching distribution found for tensorflow==1.15.0rc # 请看我写的支持的Python版本！！！ 3.有必要时请更新你的PIP pip3 install --upgrade pip 安装Docker与Docker-compose 部署12306_code_serveryml文件在上面 git clone https://gitee.com/lanmy/auto_dev.git python install_docker.py mkdir 12305_code cd 12305_code 启动code_server docker-compose up -d ","date":"2021-01-11","objectID":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/:4:0","tags":["实用工具","Python"],"title":"12306抢票小助手","uri":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/"},{"categories":["Python"],"content":"1.0 服务启动说明 筛选CDN 修改配置文件 测试配置邮箱我不做了 启动服务 ","date":"2021-01-11","objectID":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/:4:1","tags":["实用工具","Python"],"title":"12306抢票小助手","uri":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/"},{"categories":["Python"],"content":"1.1 修改配置文件 vim TickerConfig.py # 如果你没有抢到票，寄希望于其他人退票后捡漏，则TICKET_TYPE = 2 TICKET_TYPE = 1 # 填入一串你想要抢的车次例如[G2313,G1221] STATION_TRAINS = [G2313,G1221,G267] # 出发城市，比如深圳北，就填深圳就搜得到 FROM_STATION = \"北京\" # 到达城市 比如深圳北，就填深圳就搜得到 TO_STATION = \"合肥\" # 乘车人(list) 多个乘车人ex: TICKET_PEOPLES = [\"张三,李四\"] # 设置token,获取Tk方法看最下面 tk = \"ROKCqQNWEh-asdsadSNQOOasxvzvOO4gBA7qZakafm1m0\" # COOKIE_TYPE设置为1或2都有些问题，建议设置为3 COOKIE_TYPE = 3 # 获取Cookie RAIL_EXPIRATION = \"xxx\" RAIL_DEVICEID = \"xxx\" # 此处设置云打码服务器地址，如果有自建的服务器，可以自行更改 HOST = \"172.16.87.10:5002\" REQ_URL = \"/verify/base64/\" HTTP_TYPE = \"http\" **关于无法安装tensorflow** 车票日期记得写对例如：2021-01-12 ","date":"2021-01-11","objectID":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/:4:2","tags":["实用工具","Python"],"title":"12306抢票小助手","uri":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/"},{"categories":["Python"],"content":"1.2 筛选CDN 至此，准备工作已全部完成，启动前请先筛选cdn，这点很重要！ python3 run.py c ","date":"2021-01-11","objectID":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/:4:3","tags":["实用工具","Python"],"title":"12306抢票小助手","uri":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/"},{"categories":["Python"],"content":"1.3 启动服务 python3 run.py r 成功Log 车次: G2515 始发车站: 北京 终点站: 宣化北 二等座:有 正在尝试提交订票... 尝试提交订单... 出票成功 排队成功, 当前余票还剩余: 359 张 正在使用自动识别验证码功能 验证码通过,正在提交订单 提交订单成功！ 排队等待时间预计还剩 -12 ms 排队等待时间预计还剩 -6 ms 排队等待时间预计还剩 -7 ms 排队等待时间预计还剩 -4 ms 排队等待时间预计还剩 -4 ms 恭喜您订票成功，订单号为：EB52743573, 请立即打开浏览器登录12306，访问‘未完成订单’，在30分钟内完成支付！ ","date":"2021-01-11","objectID":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/:4:4","tags":["实用工具","Python"],"title":"12306抢票小助手","uri":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/"},{"categories":["Python"],"content":"Cookie以及Token获取 别再问我怎么获取Cookie了！！！ 登录网页版12306官网 网址旁边有个锁子🔐 点击锁子\u003e点击Cookie\u003e点击12306.cn 在12306.cn的Cookie项下面找到RAIL_EXPIRATION和RAIL_DEVICEID 把值复制进去 再有不懂！直接百度🙅‍♀️ Token 打开12306.cn 打开开发者工具(F12) 点击Network选项-\u003e过滤请求类型选择XHR 登录12306,然后返回到开发者工具 找到uamauthclient -\u003e Headers-\u003e一直往下拉会有tk ","date":"2021-01-11","objectID":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/:5:0","tags":["实用工具","Python"],"title":"12306抢票小助手","uri":"/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B/"},{"categories":["Ansible"],"content":"问题 Ansible调用shell远程启动java包，找不到JAVA_HOME或者直接输出为空。 [root@bogon ~]# ansible testserver -m shell -a \"nohup java -jar /server/share-0.0.1-SNAPSHOT.jar --spring.profiles.active=test3 \u003e /server/nohup.out \u0026\" 172.16.87.11 | CHANGED | rc=0 \u003e\u003e nohup: failed to run command ‘java’: No such file or directory ","date":"2021-01-06","objectID":"/ansible%E6%89%A7%E8%A1%8Cshell%E6%A8%A1%E5%9D%97%E9%97%AE%E9%A2%98/:1:0","tags":["Ansible问题相关处理"],"title":"Ansible执行Shell模块问题","uri":"/ansible%E6%89%A7%E8%A1%8Cshell%E6%A8%A1%E5%9D%97%E9%97%AE%E9%A2%98/"},{"categories":["Ansible"],"content":"解决过程 首先，在/etc/profile中声明java的变量,发现执行ansible-playbook返回为空 export JAVA_HOME=/usr/local/java export JRE_HOME=/usr/local/java/jre export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin 其次，在~/.bash_profile中添加环境变量，用ansible远程执行脚本，发现依然输出为空和找不到java…. 最后…考虑ansible执行的环境变量与登录时使用的环境变量是否有所不同,所以将JAVA_HOME写在/etc/bashrc里面,发现执行结果正常… ","date":"2021-01-06","objectID":"/ansible%E6%89%A7%E8%A1%8Cshell%E6%A8%A1%E5%9D%97%E9%97%AE%E9%A2%98/:2:0","tags":["Ansible问题相关处理"],"title":"Ansible执行Shell模块问题","uri":"/ansible%E6%89%A7%E8%A1%8Cshell%E6%A8%A1%E5%9D%97%E9%97%AE%E9%A2%98/"},{"categories":["Ansible"],"content":"原因 由于我的猜测可能是由于ansible执行的时候并没有调用/etc/profile里面的环境变量配置,只加载/etc/bashrc和~/.bashrc里面环境变量 ","date":"2021-01-06","objectID":"/ansible%E6%89%A7%E8%A1%8Cshell%E6%A8%A1%E5%9D%97%E9%97%AE%E9%A2%98/:3:0","tags":["Ansible问题相关处理"],"title":"Ansible执行Shell模块问题","uri":"/ansible%E6%89%A7%E8%A1%8Cshell%E6%A8%A1%E5%9D%97%E9%97%AE%E9%A2%98/"},{"categories":["Ansible"],"content":"善意的提醒 建议以后把一些Devops或者持续交付的环境变量全部配置到~/.bashrc或者/etc/bashrc ","date":"2021-01-06","objectID":"/ansible%E6%89%A7%E8%A1%8Cshell%E6%A8%A1%E5%9D%97%E9%97%AE%E9%A2%98/:4:0","tags":["Ansible问题相关处理"],"title":"Ansible执行Shell模块问题","uri":"/ansible%E6%89%A7%E8%A1%8Cshell%E6%A8%A1%E5%9D%97%E9%97%AE%E9%A2%98/"},{"categories":["Redis"],"content":"哨兵模式简介 主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。 哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。 这里的哨兵有两个作用 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。 然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。 用文字描述一下故障切换（failover）的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线。这样对于客户端而言，一切都是透明的。 ","date":"2021-01-04","objectID":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/:1:0","tags":["Redis"],"title":"Redis哨兵模式搭建","uri":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"搭建Redis哨兵 配置3个哨兵和1主2从的Redis服务器 服务类型 是否是主服务器 IP地址 端口 Redis 是 172.16.87.10 6379 Redis 否 172.16.87.11 6379 Redis 否 172.16.87.12 6379 Sentinel - 172.16.87.10 26379 Sentinel - 172.16.87.11 26379 Sentinel - 172.16.87.12 26379 ","date":"2021-01-04","objectID":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/:2:0","tags":["Redis"],"title":"Redis哨兵模式搭建","uri":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"部署Redis(三台全搞) Redis6.x版本以上需要GCC4.9X wget http://download.redis.io/releases/redis-6.0.8.tar.gz yum -y install centos-release-scl scl-utils-build yum -y install devtoolset-7-gcc* gcc scl enable devtoolset-7 bash echo \"511\" \u003e /proc/sys/net/core/somaxconn echo \"vm.overcommit_memory = 1\" \u003e\u003e /etc/sysctl.conf \u0026\u0026 sysctl -p mv redis-6.0.8 /usr/local/ \u0026\u0026 cd /usr/local/redis-6.0.8/ \u0026\u0026 make install mkdir /usr/local/redis-6.0.8/logs 更改Redis 主配置文件172.16.87.10 修复master认证密码 [root@localhost redis]# vim /usr/local/redis/redis.conf bind 172.16.87.10 # 改为本机IP port 6379 # 默认6379 daemonize yes # 改为yes允许后台运行 pidfile /var/run/redis_6379.pid # pid文件位置 maxmemory 750mb # 设置最大内存 一般为3/4,生产建议 dbfilename redis-master.rdb # 改一下rdb文件名称 logfile \"/usr/local/redis/logs/redis-master.log\" requirepass 123.com masterauth 123.com 更改Redis从配置文件172.16.87.11` [root@localhost redis]# vim /usr/local/redis/redis.conf bind 172.16.87.11 # 改为本机IP port 6379 # 默认6379 daemonize yes # 改为yes允许后台运行 pidfile /var/run/redis_6379.pid # pid文件位置 maxmemory 750mb # 设置最大内存 一般为3/4,生产建议 dbfilename redis-slove.rdb # 改一下rdb文件名称 logfile \"/usr/local/redis/logs/redis-slove1.log\" requirepass 123.com # 指定主服务器，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置 slaveof 172.16.87.10 6379 # 主服务器密码 masterauth 123.com 更改Redis从配置文件172.16.87.12 [root@localhost redis]# vim /usr/local/redis/redis.conf bind 172.16.87.12 # 改为本机IP port 6379 # 默认6379 daemonize yes # 改为yes允许后台运行 pidfile /var/run/redis_6379.pid # pid文件位置 maxmemory 750mb # 设置最大内存 一般为3/4,生产建议 dbfilename redis-slove.rdb # 改一下rdb文件名称 logfile \"/usr/local/redis/logs/redis-slove2.log\" requirepass 123.com slaveof 172.16.87.10 6379 # 主服务器密码 masterauth 123.com 上述内容主要是配置Redis服务器，从服务器比主服务器多一个slaveof的配置和密码。 ","date":"2021-01-04","objectID":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/:3:0","tags":["Redis"],"title":"Redis哨兵模式搭建","uri":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"配置哨兵文件 在Redis安装目录下有一个sentinel.conf文件 三台Redis都需要更改此配置文件 注意logfile的命名 cp sentinel.conf sentinel.conf.back # 先备份一个 vim sentinel.conf protected-mode no daemonize yes logfile \"/usr/local/redis-6.0.8/logs/redis-sentinel10.log\" # 记得创建logs目录 sentinel monitor mymaster 172.16.87.10 6379 2 sentinel auth-pass mymaster 123.com protected-mode no 禁止保护模式 daemonize yes 后台运行 sentinel monitor mymaster 172.16.87.10 6379 2 配置监听的主服务器 2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作. sentinel auth-pass mymaster 123.com mymaster为服务名 123.com为密码,与上述一样即可 logfile我相信大家都能看得懂…我是这样命名的 redis-sentinel10.log(172.16.87.10) redis-sentinel11.log(172.16.87.11)以此类推 上述都修改完成可以启动redis了 ","date":"2021-01-04","objectID":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/:4:0","tags":["Redis"],"title":"Redis哨兵模式搭建","uri":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"启动Redis和哨兵 注意启动的顺序：首先是主的Redis服务进程，然后启动从机的Redis服务进程，最后启动3个哨兵的服务进程。 redis-server /usr/local/redis-6.0.8/redis.conf # 三台Redis服务都用这个命令启动 redis-sentinel /usr/local/redis-6.0.8/sentinel.conf # 三台Redis哨兵服务 ","date":"2021-01-04","objectID":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/:5:0","tags":["Redis"],"title":"Redis哨兵模式搭建","uri":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"检查Redis主从是否同步成功 查看Redis日志 tail -f /usr/local/redis-6.0.8/logs/redis-master.log 9040:M 03 Jan 2021 11:46:53.570 * Synchronization with replica 172.16.87.11:6379 succeeded 9040:M 03 Jan 2021 11:48:19.065 * Synchronization with replica 172.16.87.12:6379 succeeded 出现两个successed并且成功同步复制即成功. ","date":"2021-01-04","objectID":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/:6:0","tags":["Redis"],"title":"Redis哨兵模式搭建","uri":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/"},{"categories":["Redis"],"content":"检测哨兵的主从切换是否成功 你可以直接kill掉Redis的master killall -9 redis-server # 然后查看从上的哨兵日志. +sdown master mymaster 172.16.87.10 6379 可以看出master已经宕机,然后更换新的master为11 13706:X 03 Jan 2021 21:54:34.755 # +sdown master mymaster 172.16.87.10 6379 13706:X 03 Jan 2021 21:54:34.816 # +new-epoch 1 13706:X 03 Jan 2021 21:54:34.818 # +vote-for-leader d8c5bbbb14158ccb0ff962c4b0ed2e7e6bb9067c 1 13706:X 03 Jan 2021 21:54:34.818 # +odown master mymaster 172.16.87.10 6379 #quorum 3/2 13706:X 03 Jan 2021 21:54:34.819 # Next failover delay: I will not start a failover before Sun Jan 3 22:00:35 2021 13706:X 03 Jan 2021 21:54:35.344 # +config-update-from sentinel d8c5bbbb14158ccb0ff962c4b0ed2e7e6bb9067c 172.16.87.12 26379 @ mymaster 172.16.87.10 6379 13706:X 03 Jan 2021 21:54:35.344 # +switch-master mymaster 172.16.87.10 6379 172.16.87.11 6379 13706:X 03 Jan 2021 21:54:35.344 * +slave slave 172.16.87.12:6379 172.16.87.12 6379 @ mymaster 172.16.87.11 6379 13706:X 03 Jan 2021 21:54:35.345 * +slave slave 172.16.87.10:6379 172.16.87.10 6379 @ mymaster 172.16.87.11 6379 连接到Redis172.16.87.11 [root@localhost redis-6.0.8]# redis-cli -h 172.16.87.11 -a 123.com 172.16.87.11:6379\u003e info replication # Replication role:master # 角色已经变成了master connected_slaves:1 slave0:ip=172.16.87.12,port=6379,state=online,offset=133347,lag=0 master_replid:dbee8e7470ab8f5fddadc8958659a39d75033521 master_replid2:bd20b8c1ab987db5bc6bfa6eaca6df5d6ffdfa53 master_repl_offset:133486 second_repl_offset:93027 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:197 repl_backlog_histlen:133290 ","date":"2021-01-04","objectID":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/:7:0","tags":["Redis"],"title":"Redis哨兵模式搭建","uri":"/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA/"},{"categories":["Elasticsearch"],"content":"GET方式 ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:1:0","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.0 查询Elastic节点状态 curl -v 192.168.10.1:9200/_cat/health?v ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:1:1","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.1 初始化索引 # 在创建索引之前 对索引进行初始化操作,指定shards数量和replicas数量 curl -XPUT 'http://192.168.10.1:9200/library' -d { \"settings\":{ \"index\":{ \"number_of_shards\":5, \"number_of_replicas\":1, } } } ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:1:2","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.2 查看索引信息 GET 地址/索引名称/_settings curl -X GET http://192.168.10.1:9200/test/_settings ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:1:3","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.3 查看多个索引信息 GET 地址/索引名称，索引名称/_settings curl -X GET http://192.168.10.1:9200/test,test2/_settings ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:1:4","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.4 查询所有索引的信息 curl -X GET http://192.168.10.1:9200/_all/_settings ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:1:5","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.5 查看所有索引列表 curl -X GET 'http://192.168.10.1:9200/_cat/indices?v=' ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:1:6","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.6 查看索引相关信息 1.根据id查看文档信息 get 地址/索引名称/type名称/文档id curl -X GET http://192.168.10.1:9200/test10/people/1 2.通过source获取指定字段 get /索引名称/type名称/文档id?_source=字段 curl -X GET http://192.168.10.1:9200/test10/people/1?_source=title ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:1:7","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"PUT方式 ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:2:0","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.0 创建索引 # 创建一个索引名称为test9的索引 curl -X PUT http://192.168.10.1:9200/test9/ { \"acknowledged\": true, \"shards_acknowledged\": true } ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:2:1","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.1 创建索引及类型和文档 PUT 地址/索引名称/type名称/文档id curl -X PUT http://192.168.10.1:9200/test10/people/1 -d '{ \"title\": \"test10\" }' ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:2:2","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.2 创建索引及类型,不设置文档ID（因为会自动设置文档ID） POST 地址/索引名称/type名称/ curl -X POST http://192.168.10.1:9200/test11/people/ -d '{ \"title\": \"test11\" } ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:2:3","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.3 更新同一id下的信息 PUT 地址/索引名称/type名称/文档id curl -X PUT http://192.168.10.1:9200/test10/people/1 -d '{ \"title\": \"test10\" }' ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:2:4","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.4 更新指定字段 POST 地址/索引名称/type名称/文档id/_update curl -X POST http://192.168.10.1:9200/test10/people/1 -d '{ \"doc\":{ \"title\": \"testt12\" } }' ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:2:5","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"DELETE ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:3:0","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.0 delete 地址/索引名称 curl -X DELETE http://192.168.10.1:9200/test10 ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:3:1","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Elasticsearch"],"content":"1.1 删除文档 delete 地址/索引名称/type名称/文档id curl -X DELETE http://192.168.10.1:9200/test10/people/1 ","date":"2020-12-29","objectID":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/:3:2","tags":["Elasticsearch"],"title":"Elasticsearch常用的RESTAPI","uri":"/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi/"},{"categories":["Linux"],"content":"阿里云 OSS 是对象存储服务，价格也比较便宜，算得上是一个免费的 CDN，我们可以利用 OSSFS 这个工具，将 OSS 挂载到阿里云 ECS 服务器上，可以达到存储、备份的目的。当然，最主要的是可以减轻服务器的压力。 注意阿里云 OSS 下行流量没有免费额度，都需要收费。 本次仅针对Centos7.x Centos8目前不支持挂载OSS存储,不知道支不支持,老教程了。 – 2022-03-21 ","date":"2020-12-20","objectID":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/:0:0","tags":["Linux"],"title":"挂载OSS到ECS服务器","uri":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["Linux"],"content":"OSSFS 通过OSSFS，您可以将阿里云OSS存储桶安装到Linux / Mac OS X系统中的本地文件中。在系统中，您可以方便地在OSS中的对象上进行操作，同时使用本地文件系统维护数据共享。 ","date":"2020-12-20","objectID":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/:1:0","tags":["Linux"],"title":"挂载OSS到ECS服务器","uri":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["Linux"],"content":"特征 OSSFS基于S3FS构建，并具有S3FS的所有功能。主要特点： 支持大多数POSIX文件系统功能，包括文件读/写，目录，链接操作，权限，uid / gid和扩展属性）。 支持通过OSS多部分功能上传大文件。 支持MD5验证，以确保数据完整性。 ","date":"2020-12-20","objectID":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/:2:0","tags":["Linux"],"title":"挂载OSS到ECS服务器","uri":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["Linux"],"content":"下载安装包 到官方仓库下载最新的rpm 选择 ossfs_1.80.5_centos7.0_x86_64.rpm yum -y localinstall ossfs_1.80.5_centos7.0_x86_64.rpm ","date":"2020-12-20","objectID":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/:3:0","tags":["Linux"],"title":"挂载OSS到ECS服务器","uri":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["Linux"],"content":"配置OSSFS 首先需要拿到阿里云的 AccesskeyID 和 Accesskeysecret。登录阿里云账号，然后打开密钥管理页面，然后在列表里随便选择一个并记录下来。然后还需要去 oss 控制台创建一个 bucket，我这里 bucket 的名称叫做test-dev 为了演示假如我的 AccessKey ID 为 OIUASIODN89821NK， Access Key Secret 为 76\u0026*NQWEUIIOQW echo \"test-dev:OIUASIODN89821NK:76\u0026*NQWEUIIOQW\" \u003e /etc/passwd-ossfs 在系统上创建一个系统目录比如为 /dev/mount , 将此目录作为 ossfs 的挂载目录 ossfs test-dev /dev/mount -ourl=oss-cn-hangzhou-internal.aliyuncs.com -o allow_other -ourl 表示的是 oss 的 EndPoint 地址 -o 表示运行非 root 用户使用此目录 ","date":"2020-12-20","objectID":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/:4:0","tags":["Linux"],"title":"挂载OSS到ECS服务器","uri":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["Linux"],"content":"开机启动挂载 这里需要用到rc.local chmod +x /etc/rc.local echo \"ossfs test-dev /dev/mount -ourl=oss-cn-hangzhou-internal.aliyuncs.com -o allow_other\" \u003e\u003e /etc/rc.local ","date":"2020-12-20","objectID":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/:5:0","tags":["Linux"],"title":"挂载OSS到ECS服务器","uri":"/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":null,"content":"163镜像源 镜像地址 ","date":"2020-12-12","objectID":"/repo/:1:0","tags":null,"title":"推荐一些个人觉得比较不错的Linux镜像源","uri":"/repo/"},{"categories":null,"content":"CentOS镜像使用帮助 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup # 如果需要Centos6甚至Centos5 请更换CentOS7 | CentOS6 | Centos5 wget http://mirrors.163.com/.help/CentOS7-Base-163.repo Centos7 # CentOS-Base.repo # # The mirror system uses the connecting IP address of the client and the # update status of each mirror to pick mirrors that are updated to and # geographically close to the client. You should use this for CentOS updates # unless you are manually picking other mirrors. # # If the mirrorlist= does not work for you, as a fall back you can try the # remarked out baseurl= line instead. # # [base] name=CentOS-$releasever - Base - 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever\u0026arch=$basearch\u0026repo=os baseurl=http://mirrors.163.com/centos/$releasever/os/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #released updates [updates] name=CentOS-$releasever - Updates - 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever\u0026arch=$basearch\u0026repo=updates baseurl=http://mirrors.163.com/centos/$releasever/updates/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that may be useful [extras] name=CentOS-$releasever - Extras - 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$releasever\u0026arch=$basearch\u0026repo=extras baseurl=http://mirrors.163.com/centos/$releasever/extras/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$releasever - Plus - 163.com baseurl=http://mirrors.163.com/centos/$releasever/centosplus/$basearch/ gpgcheck=1 enabled=0 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 ","date":"2020-12-12","objectID":"/repo/:1:1","tags":null,"title":"推荐一些个人觉得比较不错的Linux镜像源","uri":"/repo/"},{"categories":null,"content":"中科大镜像源 镜像地址 ","date":"2020-12-12","objectID":"/repo/:2:0","tags":null,"title":"推荐一些个人觉得比较不错的Linux镜像源","uri":"/repo/"},{"categories":null,"content":"CentOS镜像使用帮助 CentOS CentOS 8（非 Stream 版本）已被官方移除出该仓库。如有需要，请使用 CentOS-Vault 镜像。 CentOS 9 Stream 及以后的版本的镜像位于 CentOS-Stream。 对于 CentOS 8 Stream，使用以下命令替换默认的配置 sudo sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://mirror.centos.org/$contentdir|baseurl=https://mirrors.ustc.edu.cn/centos|g' \\ -i.bak \\ /etc/yum.repos.d/CentOS-Stream-AppStream.repo \\ /etc/yum.repos.d/CentOS-Stream-BaseOS.repo \\ /etc/yum.repos.d/CentOS-Stream-Extras.repo \\ /etc/yum.repos.d/CentOS-Stream-PowerTools.repo 对于 CentOS 7，使用以下命令替换默认配置 sudo sed -e 's|^mirrorlist=|#mirrorlist=|g' \\ -e 's|^#baseurl=http://mirror.centos.org/centos|baseurl=https://mirrors.ustc.edu.cn/centos|g' \\ -i.bak \\ /etc/yum.repos.d/CentOS-Base.repo ","date":"2020-12-12","objectID":"/repo/:2:1","tags":null,"title":"推荐一些个人觉得比较不错的Linux镜像源","uri":"/repo/"},{"categories":["Linux"],"content":"为rm -rf 的手残党准备的 注意事项：虽然有软件可以对误删的数据进行恢复，但是完全恢复数据的概率并不是百分百的。 在提醒：适用rm -rf 的时候依旧慎用 ","date":"2020-12-11","objectID":"/linux-%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D%E5%91%BD%E4%BB%A4%E5%8F%8A%E6%96%B9%E6%B3%95/:0:0","tags":["Linux"],"title":"Linux 误删文件恢复命令及方法","uri":"/linux-%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D%E5%91%BD%E4%BB%A4%E5%8F%8A%E6%96%B9%E6%B3%95/"},{"categories":["Linux"],"content":"extundelete恢复 使用存储在分区日志中的信息，尝试恢复已从ext3或ext4的分区中删除的文件 extundelete官方地址(官网文档) extundelete(下载地址)最新版本的extundelete是0.2.4，于2013年1月发布 在数据删除之后，要卸载被删除数据所在的磁盘或是分区 如果是系统根分区遭到误删除，就要进入单用户模式,将根分区以只读的方式挂载,尽可能避免数据被覆盖 数据被覆盖后无法找回 恢复仍有一定的机率失败，平时应对重要数据作备份，小心使用rm 1.0安装依赖 Centos7 yum -y install e2fsprogs-devel e2fsprogs* gcc* Ubuntu apt-get install build-essential e2fslibs-dev e2fslibs-dev 2.0安装编译 wget http://downloads.sourceforge.net/project/extundelete/extundelete/0.2.4/extundelete-0.2.4.tar.bz2 tar -xf extundelete-0.2.4.tar.bz2 cd extundelete-0.2.4 ./configure --prefix=/usr/local/extundelete make install ln -s /usr/local/extundelete/bin/extundelete /usr/bin/ 使用extundelete -v可以查看版本 [root@VM-0-13-centos extundelete-0.2.4]# extundelete -v extundelete version 0.2.4 libext2fs version 1.42.9 Processor is little endian. 3.0 进行文件恢复 1、查看要恢复文件的分区的文件系统 df -Th Filesystem Type Size Used Avail Use% Mounted on devtmpfs devtmpfs 909M 0 909M 0% /dev tmpfs tmpfs 920M 24K 920M 1% /dev/shm tmpfs tmpfs 920M 468K 919M 1% /run tmpfs tmpfs 920M 0 920M 0% /sys/fs/cgroup /dev/vda1 ext4 50G 11G 37G 23% / tmpfs tmpfs 184M 0 184M 0% /run/user/0 2、对要恢复文件的分区解除挂载 umount /xxx 3、查看可以恢复的数据 指定误删文件的分区进行查找 最后一列标记为Deleted的文件，即为删除了的文件 extundelete /dev/vdb1 --inode 2 （根分区的inode值是2） 4、恢复单个目录 指定要恢复的目录名 如果是空目录，则不会恢复 extundelete /dev/vdb1 --restore-directory ferris 当执行恢复文件的命令后，会在执行命令的当前的目录下生成RECOVERED_FILES目录，恢复的文件都会放入此目录中。如未生成目录，即为失败。 5、恢复单个文件 指定要恢复的文件名 如果几k大小的小文件，有很大几率恢复失败 extundelete /dev/vdb1 --restore-file openssh-7.7p1.tar.g 6、恢复全部删除的文件 无需指定文件名或目录名，恢复全部删除的数据 extundelete /dev/vdb1 --restore-all ","date":"2020-12-11","objectID":"/linux-%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D%E5%91%BD%E4%BB%A4%E5%8F%8A%E6%96%B9%E6%B3%95/:0:1","tags":["Linux"],"title":"Linux 误删文件恢复命令及方法","uri":"/linux-%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D%E5%91%BD%E4%BB%A4%E5%8F%8A%E6%96%B9%E6%B3%95/"},{"categories":["Linux"],"content":"简单了解一下 WebSocket 现在，很多网站为了实现推送技术，所用的技术都是轮询。轮询是在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTP请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会浪费很多的带宽等资源。 在这种情况下，HTML5定义了WebSocket协议，能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。 WebSocket一种在单个 TCP 连接上进行全双工通讯的协议。使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。 简单点说，WebSocket 就是减小客户端与服务器端建立连接的次数，减小系统资源开销，只需要一次 HTTP 握手，整个通讯过程是建立在一次连接/状态中，也就避免了HTTP的非状态性，服务端会一直与客户端保持连接，直到你关闭请求，同时由原本的客户端主动询问，转换为服务器有信息的时候推送。当然，它还能做实时通信、更好的二进制支持、支持扩展、更好的压缩效果等这些优点。 ","date":"2020-12-07","objectID":"/nginx%E9%85%8D%E7%BD%AEwss/:1:0","tags":["Linux","Nginx"],"title":"Nginx配置WSS","uri":"/nginx%E9%85%8D%E7%BD%AEwss/"},{"categories":["Linux"],"content":"ws 和 wss Websocket使用 ws 或 wss 的统一资源标志符，类似于 HTTP 或 HTTPS ，其中 wss 表示在 TLS 之上的 Websocket ，相当于 HTTPS 了。如： ws://example.com/echo wss://example.com/echo 默认情况下，Websocket 的 ws 协议使用 80 端口；运行在TLS之上时，wss 协议默认使用 443 端口。其实说白了，wss 就是 ws 基于 SSL 的安全传输，与 HTTPS 一样样的道理。 如果你的网站是 HTTPS 协议的，那你就不能使用 ws:// 了，浏览器会 block 掉连接，和 HTTPS 下不允许 HTTP 请求一样 ","date":"2020-12-07","objectID":"/nginx%E9%85%8D%E7%BD%AEwss/:2:0","tags":["Linux","Nginx"],"title":"Nginx配置WSS","uri":"/nginx%E9%85%8D%E7%BD%AEwss/"},{"categories":["Linux"],"content":"Nginx配置webscoket upstream websocket { server 127.0.0.1:1132; # wss接口 } # upstream 的位置你们应该都知道放在哪儿 location /websocket { proxy_pass http://websocket; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\";} location部分一般根据开发的接口来 proxy_pass http://websocket; 表示代理到websocket 重启nginx nginx -s reload ","date":"2020-12-07","objectID":"/nginx%E9%85%8D%E7%BD%AEwss/:3:0","tags":["Linux","Nginx"],"title":"Nginx配置WSS","uri":"/nginx%E9%85%8D%E7%BD%AEwss/"},{"categories":["Python"],"content":" 函数的嵌套调用是在\"函数调用中再调用其他函数\"。也就是说:函数嵌套允许在一个函数中调用另外一个函数。如下： name = \"Forest\" def change(): name = \"Forest1\" def change2(): # global name 如果声明了这句，下面的name改的是最外层的全局变层 name = \"Forest2\" #这句注释掉的话,则打印Forest1 print(\"第3层打印\", name) change2() # 调用内层函数 print(\"第2层打印\", name) change() print(\"最外层打印\", name) 函数的查找顺序优先局部变量\u003e全局变量 ","date":"2020-12-03","objectID":"/python%E5%B5%8C%E5%A5%97%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/:0:0","tags":["Python"],"title":"Python嵌套函数与匿名函数","uri":"/python%E5%B5%8C%E5%A5%97%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/"},{"categories":["Python"],"content":"匿名函数 正常情况下我们写的函数如下,对函数声明了cacl的名称 def cacl(x): return x**2 b = cacl(3) print(b) 那么匿名函数则不需要对其进行定义 res = map(lambda x:x**2,[1,2,5,6,7,9]) # 只能写三元运算 res = map(lambda x:x**2 if x \u003e10 else x**3,[1,2,5,6,7,9]) # 最复杂写三元运算 # 如果x\u003e10执行x**2 如果x\u003c10 执行x**3 lambda生成匿名函数 map(func,seq) 就是将函数作用在序列的每个元素上，然后创建由函数返回值组成的列表。 map(lambda x: x**x)，遍历mylist每个元素，执行lambda函数，并返回一个列表 ","date":"2020-12-03","objectID":"/python%E5%B5%8C%E5%A5%97%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/:1:0","tags":["Python"],"title":"Python嵌套函数与匿名函数","uri":"/python%E5%B5%8C%E5%A5%97%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0/"},{"categories":["Linux"],"content":"1 查找txt和pdf文件 find . ( -name \"*.txt\"-o -name \"*.pdf\") -print 2 正则方式查找.txt和pdf find . -regex \".*(.txt|.pdf)$\" 3 否定参数 查找所有非txt文本 find . ! -name \"*.txt\" -print 4 指定搜索深度 打印出当前目录的文件（深度为1） find . -maxdepth 1 -type f 5 定制搜索 按类型搜索： find . -type d -print # 只列出所有目录-type f 文件 / l 符号链接 按时间搜索： -atime 访问时间 (单位是天，分钟单位则是-amin，以下类似） -mtime 修改时间 （内容被修改） -ctime 变化时间 （元数据或权限变化） 最近7天被访问过的所有文件： find . -atime 7 -type f -print 按大小搜索： w字 k M G 寻找大于2k的文件 find . -type f -size +2k 按权限查找： find . -type f -perm 644-print # 找具有可执行权限的所有文件 按用户查找： find . -type f -user weber -print # 找用户weber所拥有的文件 6 找到后的后续动作 删除： 删除当前目录下所有的swp文件： find . -type f -name \"*.swp\"-delete 执行动作（强大的exec） find . -type f -user root -exec chown weber {} ; //将当前目录下的所有权变更为weber 注：{}是一个特殊的字符串，对于每一个匹配的文件，{}会被替换成相应的文件名； eg：将找到的文件全都copy到另一个目录： find . -type f -mtime +10-name \"*.txt\"-exec cp {} OLD ; 7 结合多个命令 tips: 如果需要后续执行多个命令，可以将多个命令写成一个脚本。然后 -exec 调用时执行脚本即可； -exec ./commands.sh {} ; -print的定界符 默认使用’ ‘作为文件的定界符； -print0 使用’‘作为文件的定界符，这样就可以搜索包含空格的文件； ","date":"2020-11-24","objectID":"/%E7%AE%80%E5%8D%95%E5%9C%B0shell%E5%A4%84%E7%90%86/:0:0","tags":["Linux"],"title":"Linux Shell 文本处理工具集锦-find篇","uri":"/%E7%AE%80%E5%8D%95%E5%9C%B0shell%E5%A4%84%E7%90%86/"},{"categories":["Linux"],"content":"部署副本集 1.0 更改Mongo配置文件 [root@localhost mongo]# vim conf/mongo.conf port=27017 fork=true logpath=/usr/local/mongo/logs/mongodb.log logappend=true dbpath=/usr/local/mongo/data replSet=rs0 # 加入副本集名称,此名称要一致 启动Mongo [root@localhost mongo]# mongod -f conf/mongo.conf 1.1 主Mongo配置 [root@localhost mongo]# mongo \u003e conf= { \"_id\" : \"rs0\", \"members\" : [ { \"_id\" : 0, \"host\" : \"172.17.100.193:27017\" }, { \"_id\" : 1, \"host\" : \"172.17.100.191:27017\" } ] } # 填写mongo的ip地址即可 \u003e rs.initiate(conf) # 初始化副本集 { \"ok\" : 1 } # 如果出现ok1则表示成功 1.2 副本集更新 # 向副本集中添加成员 rs.add(\"172.17.100.191:27017\") # 从副本集中删除成员 rs.remove(\"172.17.100.191:27017\") # 向副本集中添加仲裁 rs.addArb(\"172.17.100.191:27017\") # 向副本集中添加备份节点 rs.add({\"_id\":3,\"host\":\"172.17.100.191:27017\",\"priority\":0,\"hidden\":true}) // _id请依次递增 1.4 更新副本集优先级 cfg = rs.conf() cfg.members[0].priority = 5 # 设置权重为5 # members[0]里面填写你要更改的节点数字 id是1就写1 是2就设置2 rs.reconfig(cfg) # 重新加载配置 1.5 查看副本集状态 rs0:PRIMARY\u003e rs.status() 1.6 查看副本集的配置信息 rs0:PRIMARY\u003e rs.conf() 1.7 查看节点复制信息 rs0:PRIMARY\u003e db.printSlaveReplicationInfo() 1.8 插入测试数据 rs0:PRIMARY\u003e for(var i=0;i\u003c10000;i++){db.customer.insert({\"name\":\"user\"+i})} WriteResult({ \"nInserted\" : 1 }) rs0:PRIMARY\u003e db.customer.count() 10000 # 在Secondary上查看客户数据是否已经同步： rs0:SECONDARY\u003e rs.slaveOk() rs0:SECONDARY\u003e db.customer.count() 10000 ","date":"2020-10-26","objectID":"/mongodb%E9%83%A8%E7%BD%B2%E5%89%AF%E6%9C%AC%E9%9B%86/:1:0","tags":["Linux","Mongo"],"title":"Mongo部署副本集","uri":"/mongodb%E9%83%A8%E7%BD%B2%E5%89%AF%E6%9C%AC%E9%9B%86/"},{"categories":["Linux"],"content":"开启安全验证 先停止从上面的mongo然后在停止主上面的mongo 在master上进行操作 2.0 创建用户 rs0:PRIMARY\u003e use admin rs0:PRIMARY\u003e db.createUser({user: 'root', pwd: '123.com', roles: ['root']}) # 创建root用户并且给予root权限,密码为123.com # 例如对某个库授权 rs0:PRIMARY\u003e use test rs0:PRIMARY\u003e db.createUser({user:\"admin\",pwd:\"admin\",roles:[{role:\"readWrite\",db:\"test\"}]}) # role角色具体可以看官网的分配权限 # db: 指定授权的库 2.1 创建秘钥文件 [root@localhost mongo]# openssl rand -base64 666 \u003e /usr/local/mongo/keyfile 将生成的keyFile文件拷贝到其他节点服务器上，并修改文件的操作权限为 600 # 更新启动配置文件,master上配置 [root@localhost mongo]# vim conf/mongo.conf auth=true oplogSize=100 keyFile=/usr/local/mongo/keyfile # 更新启动配置文件,slave上配置 [root@localhost mongo]# vim conf/mongo.conf oplogSize=100 keyFile=/usr/local/mongo/keyfile 2.2 启动副本集 [root@localhost mongo]# mongod -f /usr/local/mongo/conf/mongo.conf # 先开master [root@localhost mongo]# mongod -f /usr/local/mongo/conf/mongo.conf # 然后再从上开启服务,不加auth认证 ","date":"2020-10-26","objectID":"/mongodb%E9%83%A8%E7%BD%B2%E5%89%AF%E6%9C%AC%E9%9B%86/:2:0","tags":["Linux","Mongo"],"title":"Mongo部署副本集","uri":"/mongodb%E9%83%A8%E7%BD%B2%E5%89%AF%E6%9C%AC%E9%9B%86/"},{"categories":["Linux"],"content":" 点我进入官网 服务发现和服务运行状况检查 Nacos支持基于DNS和基于RPC（Dubbo / gRPC）的服务发现。服务提供商向本机，OpenAPI或专用代理注册服务后，使用者可以使用DNS或HTTP查找服务。 Nacos提供实时运行状况检查，以防止服务将请求发送到不正常的主机或服务实例。Nacos支持传输层（PING或TCP）运行状况检查和应用程序层（例如HTTP，Redis，MySQL和用户定义的协议）运行状况检查。对于复杂云和网络拓扑（例如VPC，边缘服务等）的运行状况检查，Nacos提供代理模式和服务器模式运行状况检查。Nacos还提供统一的服务运行状况仪表板，以帮助您管理服务的可用性和流量。 动态配置管理 动态配置服务使您可以在所有环境中以集中，外部化和动态的方式管理所有应用程序和服务的配置。 动态配置消除了在更新配置时重新部署应用程序和服务的需要。 配置的集中管理使您更方便地实现无状态服务和按需弹性扩展服务实例。 Nacos提供了易于使用的UI TODO，可帮助您管理所有应用程序或服务的配置。它提供了一些现成的功能，包括配置版本跟踪，canary / beta版本，配置回滚和客户端配置更新状态跟踪，以确保安全并控制配置更改的风险。 动态DNS服务 支持加权路由的动态DNS服务使您可以更轻松地在数据中心内的生产环境中实施中间层负载平衡，灵活的路由策略，流量控制和简单的DNS解析服务。动态DNS服务使您更容易实现基于DNS的服务发现。 Nacos提供了一些简单的DNS API TODO，供您管理DNS域名和IP。 服务治理和元数据管理 Nacos允许您从微服务平台构建器的角度管理所有服务和元数据。这包括管理服务描述，生命周期，服务静态依赖关系分析，服务运行状况，服务流量管理，路由和安全规则，服务SLA和一线指标。 特征大图：从功能特征和非功能特征介绍我们要解决的问题域的特征。 更大的体系结构：清晰的体系结构可快速进入Nacos世界 业务图：当前功能和最佳实践可以支持的业务场景 生态大图：系统地整理Nacos与主流技术生态之间的关系 优势大图：展示Nacos核心竞争力 战略图片：Nacos从战略到战术层面的宏观优势 ","date":"2020-10-26","objectID":"/nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:0:0","tags":["Linux"],"title":"Nacos集群部署","uri":"/nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"配置清单 192.168.20.10 Mysql-master nacos 192.168.20.11 mysql-slave nacos 192.168.20.12 mysql-slave nacos ","date":"2020-10-26","objectID":"/nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:1:0","tags":["Linux"],"title":"Nacos集群部署","uri":"/nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"1.0 三台数据库配置 [root@localhost ~]# vim /etc/my.cnf [mysqld] log-bin=mysql-bin # 非必需 server-id=1　# 必需 master的server-id为1 那么slave1的server-id就是2 然后以此类推 [root@localhost ~]# systemctl restart mysqld 1.0.1 创建数据库同步用户 # 此操作在master进行 [root@localhost ~]# mysql -u root -p mysql\u003e CREATE USER 'repl'@'192.168.20.%' IDENTIFIED BY '123.comA'; /IP段写自己的 mysql\u003e GRANT REPLICATION SLAVE ON *.* TO 'repl'@'192.168.20.%'; mysql\u003e FLUSH PRIVILEGES; mysql\u003e show master status\\G //查看master状态 *************************** 1. row *************************** File: mysql-bin.000001 Position: 875 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec) 1.0.2 从库配置 // 此操作在从服务器上执行 [root@bogon ~]# mysql -u root -p change master to master_host='192.168.20.10', master_user='repl', master_password='123.comA', master_log_file='mysql-bin.000001', master_log_pos=875; mysql\u003e start slave; //开启从数据同步 mysql\u003e show slave status\\G //查看从服务器状态 *************************** 1. row *************************** 如果都是yes的话就表示成功,如果一个yes一个no就查看报错信息,主从排错我就不多说了 Slave_IO_Running: Yes Slave_SQL_Running: Yes 1.0.3 检测主从同步 # 主服务器上创建一个数据库 mysql\u003e create database nacos; # 从服务器上进行查询 mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | nacos | +--------------------+ 5 rows in set (0.04 sec) # 查询到有nacos库即同步成功 grant all privileges on nacos to 'root'@'%' identified by '123.comA'; ","date":"2020-10-26","objectID":"/nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:1:1","tags":["Linux"],"title":"Nacos集群部署","uri":"/nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"2.0 单实例版nacos集群 下载地址 这里使用源代码方式部署 集群最少3节点以上(采用端口号方式) nacos1.0.0没有集群功能 JDK8+ maven3.2+ 2.1 安装nacos [root@localhost ~]# tar -zxf nacos-server-1.3.2.tar.gz [root@localhost ~]# mv nacos /usr/local/nacos [root@localhost ~]# mv nacos /usr/local/nacos1 [root@localhost ~]# mv nacos /usr/local/nacos2 2.2 修改nacos端口号 # 默认不用修改nacos 直接修改nacos1和nacos2 [root@localhost bin]# vim /usr/local/nacos1/conf/application.properties server.port=8849 # 更改为8849 [root@localhost bin]# vim /usr/local/nacos2/conf/application.properties server.port=8850 # 更改为8850 2.3 配置集群文件 [root@localhost nacos]# cd /usr/local/nacos/conf/ [root@localhost conf]# cp cluster.conf.example cluster.conf // 三台机器都这么执行 [root@localhost conf]# vim cluster.conf # 采用这种不同端口号来充当nacos实例 192.168.20.10:8848 192.168.20.10:8849 192.168.20.10:8850 2.4 修改启动脚本 [root@bogon bin]# vim /usr/local/nacos/bin/startup.sh JAVA_OPT=\"${JAVA_OPT} -server -Xms1g -Xmx1g # 修改启动内存为 2.5 启动nacos集群 [root@localhost conf]# cd /usr/local/nacos/bin/ sh startup.sh -p embedded //三个配置全部启动 # -p embedded # 表示采用内置数据源 [root@localhost bin]# tail -f ../logs/nacos.log # 启动成功提示 2020-10-18 22:13:26,644 INFO Nacos started successfully in cluster mode. use embedded storage 访问：http://192.168.20.10:8848/nacos/index.html ","date":"2020-10-26","objectID":"/nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:1:2","tags":["Linux"],"title":"Nacos集群部署","uri":"/nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"3.0 多实例版nacos集群 # 三台全部修改cluster.conf配置文件 192.168.20.10:8848 192.168.20.21:8848 192.168.20.22:8848 sh startup.sh -p embedded # 启动 http://192.168.20.21:8848/nacos/index.html 3.1 nacos连接mysql存储源 # 三台配置文件都修改 [root@bogon nacos]# vim conf/application.properties spring.datasource.platform=mysql db.num=1 # 数据库个数 db.url.0=jdbc:mysql://192.168.20.22:3306/nacos_config?characterEncoding=utf8\u0026connectTimeout=1000\u0026socketTimeout=3000\u0026autoReconnect=true\u0026useUnicode=true\u0026useSSL=false\u0026serverTimezone=UTC # 此处填写mysql的ip db.user=root # 用户 db.password=xxx # 此为mysql的密码 3.2 导入mysql数据 mysql\u003e CREATE DATABASE nacos_config; # 先进入mysql创建一个库 [root@bogon conf]# mysql -u root -p nacos_config \u003c nacos-mysql.sql //把nacos的表结构导入进去 [root@bogon bin]# ./startup.sh 启动nacos 3.3 测试nacos持久化 然后访问nacos新建一个测试的数据 然后停止掉nacos [root@bogon bin]# ./shutdown.sh 进入mysql查询数据 mysql\u003e use nacos_config mysql\u003e select * from config_info\\G *************************** 1. row *************************** id: 1 data_id: 1 group_id: DEFAULT_GROUP content: test md5: 098f6bcd4621d373cade4e832627b4f6 gmt_create: 2020-10-19 07:54:39 gmt_modified: 2020-10-19 07:54:39 src_user: NULL src_ip: 192.168.20.1 app_name: tenant_id: c_desc: NULL c_use: NULL effect: NULL type: text c_schema: NULL 1 row in set (0.00 sec) ","date":"2020-10-26","objectID":"/nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:1:3","tags":["Linux"],"title":"Nacos集群部署","uri":"/nacos%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["Kubernetes"],"content":" Kubernetes中的基于角色的访问控制 Role ClusterRole(角色) 主体如下 User Group ServiceAccount 一般选择角色与主体进行绑定 ","date":"2020-04-07","objectID":"/kubernetes-rbac/:0:0","tags":["Kubernetes"],"title":"kubernetes-Rbac","uri":"/kubernetes-rbac/"},{"categories":["Kubernetes"],"content":"角色 当角色可以做什么事情的时候,主体就可以做什么操作 Role：特定的命名空间的访问权限 Cluster Role: 所有命名空间的访问权限 ","date":"2020-04-07","objectID":"/kubernetes-rbac/:1:0","tags":["Kubernetes"],"title":"kubernetes-Rbac","uri":"/kubernetes-rbac/"},{"categories":["Kubernetes"],"content":"角色绑定 roleBinding: 角色绑定到主体 ClusterRoleBinding: 集群角色绑定到主体 ","date":"2020-04-07","objectID":"/kubernetes-rbac/:2:0","tags":["Kubernetes"],"title":"kubernetes-Rbac","uri":"/kubernetes-rbac/"},{"categories":["Kubernetes"],"content":"主体 user：用户 group：用户组 ServiceAccount：服务账户(一般用于Pod访问) ","date":"2020-04-07","objectID":"/kubernetes-rbac/:3:0","tags":["Kubernetes"],"title":"kubernetes-Rbac","uri":"/kubernetes-rbac/"},{"categories":["Kubernetes"],"content":"创建命名空间 kubectl create ns roletest ","date":"2020-04-07","objectID":"/kubernetes-rbac/:4:0","tags":["Kubernetes"],"title":"kubernetes-Rbac","uri":"/kubernetes-rbac/"},{"categories":["Kubernetes"],"content":"在新的空间中创建Pod apiVersion: apps/v1 kind: Deployment metadata: name: nginx-dep namespace: roletest spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 ","date":"2020-04-07","objectID":"/kubernetes-rbac/:5:0","tags":["Kubernetes"],"title":"kubernetes-Rbac","uri":"/kubernetes-rbac/"},{"categories":["Kubernetes"],"content":"创建一个角色 apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: namespace: roletest name: Pod-role rules: - apiGroups: [\"\"] resources: [\"pods\"] # 只对pods有权限 verbs: [\"get\",\"watch\",\"list\"] # 只拥有get watch list权限 ","date":"2020-04-07","objectID":"/kubernetes-rbac/:6:0","tags":["Kubernetes"],"title":"kubernetes-Rbac","uri":"/kubernetes-rbac/"},{"categories":["Kubernetes"],"content":"绑定一个用户 apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: read-pods namespace: roletest subjects: - kind: User name: alex apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: Pod-role apiGroup: rbac.authorization.k8s.io ","date":"2020-04-07","objectID":"/kubernetes-rbac/:7:0","tags":["Kubernetes"],"title":"kubernetes-Rbac","uri":"/kubernetes-rbac/"},{"categories":["Kubernetes"],"content":"简单安装使用 最新版本应该是1.4.1 git clone https://github.com/nacos-group/nacos-k8s.git 简单使用 如果你使用简单方式快速启动,请注意这是没有使用持久化卷的,可能存在数据丢失风险:!!! cd nacos-k8s chmod +x quick-startup.sh ./quick-startup.sh 演示使用 服务注册 curl -X PUT 'http://cluster-ip:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName\u0026ip=20.18.7.10\u0026port=8080' 服务发现 curl -X GET 'http://cluster-ip:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName' 发布配置 curl -X POST \"http://cluster-ip:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId\u0026group=test\u0026content=helloWorld\" 获取配置 curl -X GET \"http://cluster-ip:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId\u0026group=test\" ","date":"2020-04-07","objectID":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/:1:0","tags":["Kubernetes"],"title":"kubernetes-部署NACOS","uri":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/"},{"categories":["Kubernetes"],"content":"高级用法 在高级使用中,Nacos在K8S拥有自动扩容缩容和数据持久特性,请注意如果需要使用这部分功能请使用PVC持久卷,Nacos的自动扩容缩容需要依赖持久卷,以及数据持久化也是一样,本例中使用的是NFS来使用PVC. ","date":"2020-04-07","objectID":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/:2:0","tags":["Kubernetes"],"title":"kubernetes-部署NACOS","uri":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/"},{"categories":["Kubernetes"],"content":"部署NFS nfs-client-provisioner 可动态为kubernetes提供pv卷，是Kubernetes的简易NFS的外部provisioner，本身不提供NFS，需要现有的NFS服务器提供存储。持久卷目录的命名规则为: ${namespace}-${pvcName}-${pvName} 创建角色 kubectl create -f deploy/nfs/rbac.yaml 修改NFS的yaml vim nacos-k8s/deploy/nfs/deployment.yaml apiVersion: v1 kind: ServiceAccount metadata: name: nfs-client-provisioner --- kind: Deployment apiVersion: apps/v1 metadata: name: nfs-client-provisioner spec: replicas: 1 strategy: type: Recreate selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-client-provisioner containers: - name: nfs-client-provisioner image: quay.io/external_storage/nfs-client-provisioner:latest volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: fuseim.pri/ifs - name: NFS_SERVER value: 10.1.6.93 # 修改NFS的IP为你本地的NFSIP地址 - name: NFS_PATH value: /server/nacos volumes: - name: nfs-client-root nfs: server: 10.1.6.93 # 同上 path: /server/nacos 部署NFS-client kubectl create -f deploy/nfs/deployment.yaml 部署NFS StorageClass kubectl create -f deploy/nfs/class.yaml 验证nfs-client-provisioner是否成功 kubectl get pod -l app=nfs-client-provisioner ","date":"2020-04-07","objectID":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/:2:1","tags":["Kubernetes"],"title":"kubernetes-部署NACOS","uri":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/"},{"categories":["Kubernetes"],"content":"部署mysql kubectl create -f deploy/mysql/mysql-nfs.yaml ","date":"2020-04-07","objectID":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/:2:2","tags":["Kubernetes"],"title":"kubernetes-部署NACOS","uri":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/"},{"categories":["Kubernetes"],"content":"部署Nacos 修改 deploy/nacos/nacos-pvc-nfs.yaml 可以自行选择更改 data: mysql.master.db.name: \"主库名称\" mysql.master.port: \"主库端口\" mysql.slave.port: \"从库端口\" mysql.master.user: \"主库用户名\" mysql.master.password: \"主库密码\" 创建Nacos kubectl create -f nacos-k8s/deploy/nacos/nacos-pvc-nfs.yaml ","date":"2020-04-07","objectID":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/:2:3","tags":["Kubernetes"],"title":"kubernetes-部署NACOS","uri":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/"},{"categories":["Kubernetes"],"content":"扩容测试 在扩容前，使用 kubectl exec获取在pod中的Nacos集群配置文件信息 for i in 0 1; do echo nacos-$i; kubectl exec nacos-$i cat conf/cluster.conf; done StatefulSet控制器根据其序数索引为每个Pod提供唯一的主机名。 主机名采用 - 的形式。 因为nacos StatefulSet的副本字段设置为3，所以当前集群文件中只有三个Nacos节点地址 使用kubectl scale 对Nacos动态扩容 kubectl scale sts nacos --replicas=5 ","date":"2020-04-07","objectID":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/:2:4","tags":["Kubernetes"],"title":"kubernetes-部署NACOS","uri":"/kubernetes-%E9%83%A8%E7%BD%B2nacos/"},{"categories":["Kubernetes"],"content":"PersistentVolume 是由管理员设置的存储,他是集群的一部分。就像节点是集群中的资源一样,PV也是集群中的资源。 PV是Volume之类的卷插件,但具有独立于适用PV的Pod的生命周期。此API对象包含存储实现的细节 即NFS、ISCSI或特定于云供应商存储系统 ","date":"2020-04-07","objectID":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/:1:0","tags":["Kubernetes"],"title":"kubernetes-卷的概念","uri":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"categories":["Kubernetes"],"content":"有关于PV的分类 静态PV: 集群管理员创建一些PV ,他们带有可供集群用户使用的实际存储的细节。,他们存在于KubernetesAPI中 动态PV：当管理员创建的静态PV都不匹配用户的persistenVolumeClaim时候,集群可能会尝试动态的为PVC创建卷。此配置基于StorageClasses也就是说PVC必须请求StorangeClasses并且管理员必须创建并且配置类才能动态创建 绑定：master中的控制环路监视新的PVC,寻找匹配的PV(如果可能),并将它们绑定在一起。如果为新的PVC动态调配PV,则该环路将始终会把PV绑定到PVC,否则,用户总会得到它们所请求的存储,但是容量可能超出要求的数量。一旦PV和PVC绑定完成之后 不管他们是如何绑定的 PVC和PV是一对一的映射。 ","date":"2020-04-07","objectID":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/:2:0","tags":["Kubernetes"],"title":"kubernetes-卷的概念","uri":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"categories":["Kubernetes"],"content":"PVC 根据容量和读写模式进行匹配 使用户存储的请求。它与Pod相似。Pod消耗节点资源,PVC消耗PV资源,Pod可以请求特定级别的CPU和内存 PVC可以请求特定的大小和访问模式。 ","date":"2020-04-07","objectID":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/:3:0","tags":["Kubernetes"],"title":"kubernetes-卷的概念","uri":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"categories":["Kubernetes"],"content":"持久化卷声明的保护 PVC保护的目的是确保Pod正在使用的PVC不会从系统中移除 当启用PVC保护alpha的功能时候,如果用户删除了一个Pod正在使用的PVC,则该PVC不会被立即删除 ,PVC的删除将会被延迟,直到PVC不再被任何Pod使用 ","date":"2020-04-07","objectID":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/:4:0","tags":["Kubernetes"],"title":"kubernetes-卷的概念","uri":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"categories":["Kubernetes"],"content":"持久化卷类型 GcePersistentDisk FlexVolume Cinder HostPath ","date":"2020-04-07","objectID":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/:5:0","tags":["Kubernetes"],"title":"kubernetes-卷的概念","uri":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"categories":["Kubernetes"],"content":"PV创建 选择NFS作为PV的底层存储 apiVersion: v1 kind: PersistentVolume metadata: name: web-pv spec: capacity: storage: 6Gi volumeMode: Filesystem accessModes: - ReadWriteOnce # 仅读写一人 persistentVolumeReclaimPolicy: Recyle # 回收策略 storageClassName: slow # 类的名字 mountOptions: - hard - nfsvers=4.1 nfs: path: /tmp server: 10.1.6.110 # NFS服务器地址 ","date":"2020-04-07","objectID":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/:6:0","tags":["Kubernetes"],"title":"kubernetes-卷的概念","uri":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"categories":["Kubernetes"],"content":"PV访问模式 PersistentVolume可以以资源提供者支持的任何方式挂载到主机上。如下图所示 供应商具有不同的功能,每个PV的访问模式都将被设置为该卷支持的特定模式。 注意：并不是所有的插件都支持多个读/写客户端 例如可以指定NFS的PV只能以读的方式导出到服务器上. ReadWriteOnce：该卷可以被单个Pod以读/写模式挂载 ReadOnlyMany：该卷可以被多个Pod以只读模式挂载 ReadWriteMany：该卷可以被多个Pod以读/写模式挂载 ","date":"2020-04-07","objectID":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/:7:0","tags":["Kubernetes"],"title":"kubernetes-卷的概念","uri":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"categories":["Kubernetes"],"content":"回收策略 Retain：保留–手动回收 Recycle：回收–基本擦除(差不多类似于rm -rf /*) 新版本已经删除了 Delete(删除)–关联的存储资产(例如AWS EBS) 当前只有NFS和HostPath支持回收策略 AWS EBS Azure Disk支持删除 ","date":"2020-04-07","objectID":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/:8:0","tags":["Kubernetes"],"title":"kubernetes-卷的概念","uri":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"categories":["Kubernetes"],"content":"状态 卷可以处于以下某种的状态 Available：可用-一块空闲资源还没有被任何声明绑定. Bound：已绑定-卷已经声明绑定 Released：已释放-声明被删除,但是资源还未被集群重新声明 Failed：失败-该卷的自动回收失败 ","date":"2020-04-07","objectID":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/:9:0","tags":["Kubernetes"],"title":"kubernetes-卷的概念","uri":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"categories":["Kubernetes"],"content":"PVC创建 安装NFS的我就不写了 # 先部署PV apiVersion: v1 kind: PersistentVolume metadata: name: nfs-pvalksjdf2 spec: capacity: storage: 1Gi accessModes: - ReadWriteMany storageClassName: \"nfs\" nfs: path: /data server: 10.1.6.110 创建服务并且使用Pvc apiVersion: apps/v1 kind: Deployment metadata: name: nginx-dep spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 volumeMounts: - name: wwwroot mountPath: /usr/share/nginx/html ports: - containerPort: 80 volumes: - name: wwwroot persistentVolumeClaim: claimName: my-pvc --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: my-pvc spec: accessModes: - ReadWriteMany storageClassName: \"nfs\" resources: requests: storage: 1Gi 面介绍的PV和PVC模式是需要运维人员先创建好PV，然后开发人员定义好PVC进行一对一的Bond，但是如果PVC请求成千上万，那么就需要创建成千上万的PV，对于运维人员来说维护成本很高，Kubernetes提供一种自动创建PV的机制，叫StorageClass，它的作用就是创建PV的模板。 具体来说，StorageClass会定义一下两部分： PV的属性 ，比如存储的大小、类型等 创建这种PV需要使用到的存储插件，比如Ceph等 有了这两部分信息，Kubernetes就能够根据用户提交的PVC，找到对应的StorageClass，然后Kubernetes就会调用 StorageClass声明的存储插件，创建出需要的PV。 这里我们以NFS为例，要使用NFS，我们就需要一个nfs-client的自动装载程序，我们称之为Provisioner，这个程序会使用我们已经配置好的NFS服务器自动创建持久卷，也就是自动帮我们创建PV。 说明： 自动创建的PV会以${namespace}-${pvcName}-${pvName}的目录格式放到NFS服务器上； 如果这个PV被回收，则会以archieved-${namespace}-${pvcName}-${pvName}这样的格式存放到NFS服务器上； ","date":"2020-04-07","objectID":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/:10:0","tags":["Kubernetes"],"title":"kubernetes-卷的概念","uri":"/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"categories":null,"content":"\r这是我个人开发的个人社区项目(H2os/有氧社区)\r项目地址: https://gitee.com/brave_heart_one/h2os/tree/development/ ","date":"2017-01-14","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"友情链接申请 友情链接我研究研究怎么放得下 来自 Unsplash 的随机图片 ","date":"2017-01-14","objectID":"/about/:1:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"一些我常用的技术栈 Linux: 熟悉Centos、RedHat系列,基于Rocky Linux的分支正在进行学习. Docker Nginx Kubernetes MySQL Tomcat Ansible Prometheus Redis Python/FastAPI 正在学习Go+Gin开发后端项目 投稿邮箱是💌：beilanzhisen@163.com 站长联系🌍：3441789878 新年愿望：祝大家在新的一年里越来越好 最后感谢各位一年多以来的阅读陪伴 ","date":"2017-01-14","objectID":"/about/:2:0","tags":null,"title":"关于","uri":"/about/"}]