[["Kubernetes低版本中内存泄漏问题","2022年10月10日","/2022/10/08/kubernetes%E4%BD%8E%E7%89%88%E6%9C%AC%E4%B8%AD%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98.html/"," Kubernetes中Cgroup泄漏问题 Cgorup文档: https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt 绝大多数的kubernetes集群都有这个隐患。只不过一般情况下，泄漏得比较慢，还没有表现出来而已。 一个pod可能泄漏两个memory cgroup数量配额。即使pod百分之百发生泄漏， 那也需要一个节点销毁过三万多个pod之后，才会造成后续pod创建失败。 一旦表现出来，这个节点就彻底不可用了，必须重启才能恢复。 故障表现 该内容的故障信息已经提交给Github: https://github.com/kubernetes/kubernetes/issues/112940 我在服务器中更新Pod出现如下错误 使用 查看系统日志的错误内容信息 服务器配置信息 操作系统: 系统内核: Kubernetes: dockerVersion: 问题原因1 Kubernetes在1.9版本开启了对kmem的支持,因此 1.9以后的所有版本都有该问题，但必须搭配3.x内核的机器才会出问题。一旦出现会导致新 pod 无法创建，已有 pod不受影响，但pod 漂移到有问题的节点就会失败，直接影响业务稳定性。因为是内存泄露，直接重启机器可以暂时解决，但还会再次出现。 cgroup的kmem account特性在3.x 内核上有内存泄露问题，如果开启了kmem account特性会导致可分配内存越来越少，直到无法创建新 pod 或节点异常。 kmem account 是cgroup 的一个扩展，全称CONFIG_MEMCG_KMEM，属于机器默认配置，本身没啥问题，只是该特性在 3.10 的内核上存在漏洞有内存泄露问题，4.x的内核修复了这个问题。 因为 kmem account 是 cgroup 的扩展能力，因此runc、docker、k8s 层面也进行了该功能的支持，即默认都打开了kmem 属性。 因为3.10 的内核已经明确提示 kmem 是实验性质，我们仍然使用该特性，所以这其实不算内核的问题，是 k8s 兼容问题。 问题原因2 memcg是 Linux 内核中用于管理 cgroup 内存的模块，整个生命周期应该是跟随 cgroup 的，但是在低版本内核中 ，一旦给某个 memory cgroup 开启 kmem accounting 中的 memory.kmem.limit_in_bytes 就可能会导致不能彻底删除 memcg 和对应的 cssid，也就是说应用即使已经删除了 cgroup (/sys/fs/cgroup/memory 下对应的 cgroup 目录已经删除), 但在内核中没有释放 cssid，导致内核认为的 cgroup 的数量实际数量不一致，我们也无法得知内核认为的 cgroup 数量是多少。 这个问题可能会导致创建容器失败，因为创建容器为其需要创建 cgroup 来做隔离，而低版本内核有个限制：允许创建的 cgroup 最大数量写死为 65535，如果节点上经常创建和销毁大量容器导致创建很多 cgroup，删除容器但没有彻底删除 cgroup 造成泄露(真实数量我们无法得知)，到达 65535 后再创建容器就会报创建 cgroup 失败并报错 no space left on device，使用 kubernetes 最直观的感受就是 pod 创建之后无法启动成功。 解决方案 目前官方给出的解决方案如下: kernel upgrade to 4.0+: application crash due to k8s 1.9.x open the kernel memory accounting by default #61937 (comment) rebuild the kubelet with nokmem args. See Failed to create container, mkdir /sys/fs/cgroup/memory/kubepods/besteffort/pod98211fca-b27e-4316-b1ae-c0d27925aa84: cannot allocate memory #96701 (comment) Set cgroup.memory=nokmem in grub: see application crash due to k8s 1.9.x open the kernel memory accounting by default #61937 (comment) 解决方案一 感谢提供的解决方案: https://cloud.tencent.com/developer/article/1739289 https://github.com/torvalds/linux/commit/d6e0b7fa11862433773d986b5f995ffdf47ce672 https://support.mesosphere.com/s/article/Critical-Issue-KMEM-MSPH-2018-0006 这种方式的缺点是： 1、要升级所有节点，节点重启的话已有 pod 肯定要漂移，如果节点规模很大，这个升级操作会很繁琐，业务部门也会有意见，要事先沟通。 2、这个问题归根结底是软件兼容问题，3.x 自己都说了不成熟，不建议你使用该特性，k8s、docker却 还要开启这个属性，那就不是内核的责任，因为我们是云上机器，想替换4.x 内核需要虚机团队做足够的测试和评审，因此这是个长期方案，不能立刻解决问题。 3、已有业务在 3.x 运行正常，不代表可以在 4.x 也运行正常，即全量升级内核之前需要做足够的测试，尤其是有些业务需求对os做过定制。 解决方案2 修改虚机启动的引导项 grub 中的 ，让机器启动时直接禁用 cgroup的 kmem 属性 更改完成后你需要生成一下新的cgroup配置. 解决方案3 如果你想在Kubernetes中禁用该属性。issue 中一般建议修改 kubelet代码并重新编译。 对于v1.13及其之前版本的kubelet，需要手动替换以下两个函数。 重新编译并替换 对于v1.14及其之后版本的kubelet,通过添加BUILDTAGS来禁止 kmem accounting. 遇到1.16 版本的BUILDTAGS=”nokmem“编译出来的 let 还是有问题，还是通过修改代码的方式使其生效 编译前，可以编辑下文件 hack/lib/version.sh，将 改为 ，确保版本号干净。 影响范围 k8s在1.9版本开启了对kmem的支持，因此1.9以后的所有版本都有该问题,但必须搭配 3.x内核的机器才会出问题。一旦出现会导致新pod无法创建,已有 pod不受影响，但pod 漂移到有问题的节点就会失败，直接影响业务稳定性。因为是内存泄露，直接重启机器可以暂时解决，但还会再次出现。 大概得原理理解 keme是什么? kmem是Cgroup的一个扩展，全称CONFIG_MEMCG_KMEM，属于机器默认配置。 内核内存与用户内存： 内核内存：专用于Linux内核系统服务使用，是不可swap的，因而这部分内存非常宝贵的。但现实中存在很多针对内核内存资源的攻击，如不断地fork新进程从而耗尽系统资源，即所谓的“fork bomb”。 为了防止这种攻击，社区中提议通过linux内核限制 cgroup中的kmem 容量，从而限制恶意进程的行为，即kernel memory accounting机制。 使用如下命令查看KMEM是否打开： cgroup与kmem机制 使用 cgroup 限制内存时，我们不但需要限制对用户内存的使用，也需要限制对内核内存的使用。kernel memory accounting 机制为 cgroup 的内存限制增加了 stack pages（例如新进程创建）、slab pages(SLAB/SLUB分配器使用的内存)、sockets memory pressure、tcp memory pressure等，以保证 kernel memory 不被滥用。 当你开启了kmem 机制，具体体现在 memory.kmem.limit_in_bytes 这个文件上： 实际使用中，我们一般将 memory.kmem.limit_in_bytes 设置成大于 memory.limit_in_bytes，从而只限制应用的总内存使用。 docker与k8s使用kmem 以上描述都是cgroup层面即机器层面，但是 runc 和 docker 发现有这个属性之后，在后来的版本中也支持了 kmem ，k8s 发现 docker支持，也在 1.9 版本开始支持。 1.9版本及之后，kubelet 才开启 kmem 属性 kubelet 的这部分代码位于： 对于k8s、docker 而言，kmem 属性属于正常迭代和优化，至于3.x的内核上存在 bug 不能兼容，不是k8s 关心的问题。但 issue 中不断有人反馈，因此在 k8s 1.14 版本的 kubelet 中，增加了一个编译选项 make BUILDTAGS=\u0026ldquo;nokmem\u0026rdquo;，就可以编译 kubelet 时就禁用 kmem，避免掉这个问题。而1.8 到1.14 中间的版本，只能选择更改 kubelet 的代码。 "],["Kubeadm部署Kubernetes1.22.10","2022年09月09日","/2022/09/22/kubeadm%E9%83%A8%E7%BD%B2kubernetes1.22.10.html/"," 准备工作 兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及那些没有包管理器的发行版提供了通用说明。 每台机器 2 GB 或更多 RAM（任何更少都会为您的应用程序留下很小的空间）。 2 个 CPU 或更多。 集群中所有机器之间的完整网络连接（公共或专用网络都可以）。 每个节点的唯一主机名、MAC 地址和 product_uuid。有关更多详细信息，请参见此处 。 您的机器上的某些端口是开放的。有关更多详细信息，请参见此处 。 交换Swap分区。必须禁用Swap才能使 kubelet 正常工作。 我的服务器配置列表 没有必要按照我的环境来,个人一般机器建议以下配置. master: 2核4G work1: 2核2G work2: 2核2G IP 主机名称 CPU 内存 硬盘 10.1.6.45 containerd-kube-master 4 8 60 10.1.6.46 containerd-kube-work1 4 8 60 10.1.6.47 containerd-kube-work2 4 8 60 你所需要开放的端口 协议 方向 端口范围 目的 使用者 TCP 入站 6443 Kubernetes API 服务器 全部 TCP 入站 2379-2380 etcd 服务器客户端 API kube-apiserver, etcd TCP 入站 10250 Kubelet API 自我，控制平面 TCP 入站 10259 kube-调度器 自己 TCP 入站 10257 kube-控制器-管理器 自己 虽然 etcd 端口包含在控制平面部分，但您也可以在外部或自定义端口上托管自己的 etcd 集群。 协议 方向 端口范围 目的 使用者 TCP 入站 10250 Kubelet API 自我，控制平面 TCP 入站 30000-32767 NodePort端口范围 全部 可以覆盖所有默认端口号。当使用自定义端口时，这些端口需要打开而不是此处提到的默认值。 一个常见的例子是 API 服务器端口，有时会切换到 443。或者，默认端口保持原样，API 服务器放在负载均衡器后面，该负载均衡器监听 443 并将请求路由到默认端口上的 API 服务器。 准备主机地址 修改每一台主机的 配置 关闭swap分区以及防火墙 如果你的系统使用的并不是Rocky而是CentOS默认是应该没有挂载SWAP分区到fastab当中的 所有内容准备完成后重启三台服务器! 安装Containerd 本文档后续基于 + + containerd Docker CRI-O 需要注意的是,根据Kubernetes官方给出的公告。Kubernetes 1.20x版本将会废弃对 参考链接 通过阿里云镜像源安装 官方镜像站 三台主机全部执行此操作 查看一下 的版本 生成containerd的配置文件 三台主机全部执行此操作 默认情况下在 已经有这个文件了,但是里面是一些简短的配置. 修改sandbox_img ： 此镜像是kubernetes的基础容器 三台主机全部执行此操作 由于部分用户无法进入 资源地址,需要对此地址进行替换. 启动containerd 三台主机全部执行此操作 保证 的状态即可 准备配置IP转发 三台全部执行 配置完成后请全部重启机器! kubernetes安装 通过阿里云镜像源安装 三台全部安装 由于官网未开放同步方式, 可能会有索引gpg检查失败的情况, 这时请用 安装 可以通过yum \u0026ndash;showduplicates list kubelet查看当前仓库中可用的版本 安装命令提示 安装后可以使用tab进行快捷提示 如果你想要 的使其生效,请把他们加入到 当中 启动kubelet 初始化集群配置信息 创建admin配置目录 创建集群网络 因为flannel不支持网络隔离,所以不想用了! 不再基于 ,而是基于 编辑 创建 网络 加入集群 如果初始化成功会出现 在node节点执行 验证集群 查看master节点的 是否全部启动 从master上查看节点是否已经全部 到此为止,1.24的kubernetes已经安装完毕 提一个小问题 看一下你们的 是否在同一个节点上,如果在同一个节点上,建议重新分配一下coredns保证其高可用性 重新分配 问题解决 01 使用crictl image出现 出现该问题的原因是由于crictl不知道使用那个 导致的 01-解决方法 默认情况下 的 存放于 默认生成的 存放在 02 Master主集群加入token过期如何处理 默认情况下,该token只有24小时,如果token值过期的话需要重新生成 查看当前master集群的token列表 重新生成一份token 通过证书hashtokne "],["Ansible-Tasks任务控制","2022年08月08日","/2022/08/29/ansible-tasks%E4%BB%BB%E5%8A%A1%E6%8E%A7%E5%88%B6.html/"," Ansible-with_items 通过 进行循环 语法 : 为读取 的固定写法 : 是一个列表,下面可以有多个不同的内容 普通写法 使用变量的循环写法 使用变量字典循环方式批量创建用户 使用变量字典循环拷贝文件 Ansible-Handlers 通过 进行监控-\u0026gt;通过 触发 关于 的一些小注意事项 无论你拥有多少个notify通知相同的 , 仅仅会在所有tasks正常执行完成后运行一次 只有tasks发生改变了才会通知 ,没有改变则不会触发 不能使用 替代tasks,因为handlers是一个特殊的tasks 的名称要与 的名称一致 Ansible-Tags 根据 中的指定标签的内容进行执行、调试等操作. 对一个tasks指定一个tags标签 对一个tasks指定多个tags标签(真没啥意义,感觉不实用。) 对多个tasks指定一个标签 执行指定Tags标签内容 : 指定标签名称 : 通过 选项参数进行选择指定标签进行运行 跳过指定标签执行其他内容 跳过指定的标签内容,执行标签内容外的其他内容 Ansible-Include 一个可以将 简单的进行复用的一个功能! 简单应用 编写一个重启http服务的配置 PlayBook中的应用 ： 查找的文件目录为你当前所在的目录,可以通过 命令进行查看。 多个playbook合成 如果你写的playbook存在多个文件,你只想执行一个playbook,那么可以使用 。 : 引入你需要的playbook文件,必须是一个完整的 文件 Ansible-ignore_errors 在Ansible中进行错误的忽略 输出结果大概是这样的 Ansible-changed_when 通常用于失败后所执行一些操作: 例如失败后强制调用 、失败后强制删除等. 通常而言，如果任务失败并且play在该主机上中止，则收到play中早前任务通知的处理程序将不会运行。如果在play中设置 关键字，则即使play因为后续任务失败而中止也会调用被通知的处理程序。 force_handlers 虽然任务是失败的,但是依旧调用了最后执行的 changed_when 当前命令确保不会对被控端主机进行变更的时候,可以使用 来进行忽略提示中的 还可以检查 任务返回的结果 查找输出当中是否存在 如果没有则不执行 "],["本站即将同步腾讯开发者社区","2022年08月08日","/2022/08/25/%E6%9C%AC%E7%AB%99%E5%8D%B3%E5%B0%86%E5%90%8C%E6%AD%A5%E8%85%BE%E8%AE%AF%E5%BC%80%E5%8F%91%E8%80%85%E7%A4%BE%E5%8C%BA.html/","我的博客即将同步至腾讯云开发者社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=359l3zwqzko4c"],["Ansible变量进阶","2022年08月08日","/2022/08/15/ansible%E5%8F%98%E9%87%8F%E8%BF%9B%E9%98%B6.html/"," 1.0 Ansible怎么定义变量 通过 中的 进行变量的定义 通过 主机清单进行变量定义 通过执行 的时候增加 选项进行定义 1.0.1 通过Playbook中的vars定义变量 在 中通过写入 语法定义变量 通过 进行引用! 1.0.2 通过定义变量文件进行使用 定义一个名字为 的变量配置文件 注意: 当你引用了变量文件中的变量,请在读取变量的时候增加双引号 1.0.3 通过编辑 主机清单进定义 这种方法一般用的很少 官方推荐的方法: 在项目目录中创建两个变量目录 和 group_vars 创建一个同名文件,用于写入变量内容 必须与hosts清单中的组名保持一致,如果不同名会报错。但是如果你想要多个配置文件使用同一个组中的变量,只需要在 新建一个 文件,所有组可用! host_vars 在 中创建一个文件,文件名与 清单中的主机名称要保持完全一致,如果是IP地址,则创建相同IP地址的文件即可 "],["MySQL全面优化思路-基础内容","2022年07月07日","/2022/07/20/mysql%E5%85%A8%E9%9D%A2%E4%BC%98%E5%8C%96%E6%80%9D%E8%B7%AF-%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9.html/"," MySQL性能优化-优化思路 大概的优化思路分为以下几个内容 PS: 优化是有风险的,如果你要优化就要变更。 硬件层面优化 系统层面优化 MySQL版本选择优化 MySQL三层结构及参数优化 MySQL开发规范 MySQL的索引优化 MySQL的事务以及锁优化 MySQL架构优化 MySQL安全优化 硬件层面优化 这个地方就略过了就是一些加大硬件配置的需求. 系统层面优化 id: 空闲状态,如果数值越大,表示空闲状态越多。如果可能达到0的情况下,表示当前CPU的核心处于满负荷状态。 us: 表示当前CPU核心数量的使用率。 sy: 表示CPU与内核交互的频率,内核与CPU处理请求的占用,如果此参数高,表示内核很忙。 wa: CPU从内存中刷数据到硬盘中的占用,可能会出现I/O的问题。 通过 指定占用高的进程,可以看到具体是那些线程占用过高 假设 线程占用过高,可以从数据库中查看 库中具体的信息 定位操作系统线程-\u0026gt;从系统线程中定位数据库线程 如果可能存在的是IO问题 查询 中的 库中存在记录 的表 如果存在IO问题： 可以选择用内存换取时间的方法.. MySQL版本选择优化 在这里\u0026hellip;笔者非常推荐MySQL8.0x!!! 同样的机器,8.0比5.7快2.5倍左右吧 选择稳定版,选择开源社区的稳定版和GA版本 选择MySQL数据库GA版本发布后6-12个月的GA双数版本 要选择开发兼容的MySQL版本 MySQL三层结构及参数优化 连接层优化 一切根据自己或者项目需要自由设置吧! Server层优化 一切根据自己或者项目需要自由设置吧! Engine层优化 一切根据自己或者项目需要自由设置吧! 全局锁读Global Read Lock (GRL） 加锁方法：FTWRL,flush tables with read lock. 解锁方法：unlock tables； 可能出现的场景 记录binlog日志-\u0026gt;不让所有事务提交 FTWRL-\u0026gt;不让新的修改进入 snapshot innodb-\u0026gt; 允许所有的DML语句,但是不允许DDL 属于类型: MDL(matedatalock)层面锁 影响情况: 加锁的期间,阻塞所有事务的写入,阻塞所有事务的commit,时间受到 全局读锁的排查方法 5.7版本全局读锁排查 经典故障案例 假设模拟一个大的查询或者事物 模拟备份时的TWRL,此时会发现命令阻塞 发起正常查询请求,发现查询被阻塞 5.7版本的Xbackup/mysqldump备份数据库出现锁表状态,所有的查询不能正常进行. Table Lock(表级锁) 加锁方式: 所有会话只读,属于MDL锁。 当前会话可以可以RW,属于MDL锁. 解锁方式: ; 检测方式 MetaDataLock(元数据锁) 作用范围: global、commit、tablespace、schema、table 默认时间： 检测方式 AutoincLock(自增锁) 通过参数: 0 表锁：每次插入都请求表锁,效率低下 1 mutex： 预计插入多少行,预申请自增序列.如果出现load或者insert select方式会退化为0。 2 : 强制使用mutex的方式,并发插入会更高效！ Innodb Row Lock(行级锁) record lock、gap、next、lock 优化方向 优化索引 减少事务的更新范围 RC级别 拆分语句 Dead Lock死锁 dead lock 多个并发事务之间发生交叉依赖的时候,会出现死锁. "],["Docker常见的几个问题处理","2022年07月07日","/2022/07/04/docker%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86.html/"," 总结了一下平常Docker常见的错误处理,大概二十几个左右。 Docker迁移存储目录 问题起因 由于公司最开始的服务器在 没有挂载存储,容量只有40G,导致服务器磁盘用满。现将原有的Docker目录数据进行迁移。 请各位Kubernetes用户不要操作,因为容器编排不支持!\u0026quot; 方法一: 软连接方式 方法二: 修改docker配置文件 Docker存储空间不足 问题一: No space left on device 问题描述： 的时候系统提示 ! 这个问题无非就两种情况 一种是磁盘满了 一种是磁盘inode满了 因为 文件系统使用 存储 信息，而 文件系统使用 来进行存储。考虑到性能问题，默认情况下这个 只会使用前 空间，当这 空间被写满后，就会导致无法写入 信息，报磁盘空间不足的错误。我们可以在 时，指定 即可将这个 使用的空间扩展到整个文件系统。 如果不知道小文件如何查找 如果是硬盘空间满了的话 优雅地重启Docker 不停止重启,重启docker是一件多么美妙的事情! 当 守护程序终止时，它会关闭正在运行的容器。从 开始，可以在配置文件中添加 参数，以便在守护程序变得不可用时容器保持运行。需要注意的是 平台暂时还是不支持该参数的配置。 在守护进程关闭的时候保持容器运行 live-restore的限制 当前的Live Restore特性可以在进行Daemon维护，或者在Daemon发生问题导致不可用的情况，减少容器的停机时间，不过其也有一定的限制。 Docker版本升级限制 Live Restore仅支持Docker补丁版本升级时可用，也就是 YY.MM.x 最后一位发生变化的升级，而不支持大版本的升级。在进行大版本升级后，可能会导致Daemon无法重新连接到运行中容器的问题，这时候需要手动停止运行的容器。 Daemon选项变更 也就是说Live Restore仅仅在某些Daemon级别的配置选项不发生改变的情况工作，例如Bridge的IP地址，存储驱动类型等。如果在重启Daemon时候，这些选项发生了改变，则可能会到Daemon无法重新连接运行中的容器，这时也需要手动停止这些容器。 影响容器的日志输出 如果Daemon长时间停止，会影响运行容器的日志输出。因为默认情况下，日志管道的缓冲区大小为64k，当缓冲写满之后，必须启动Daemon来刷新缓冲区。 不支持Docker Swarm Live Restore只是独立Docker引擎的特性，而Swarm的服务是由Swarm管理器管理的。当Swarm管理器不可用时，Swarm服务是可以在工作节点上继续运行的，只是不同通过Swarm管理器进行管理，直到Swarm管理恢复工作。 容器内部中文异常 问题描述: 容器内部中文乱码、无法正常显示中文、 例如显示中文： 然而 字符集是不支持中文的，而 是支持中文的只要把系统中的环境 改为 格式即可解决问题。同理，在 进入 不能输入中文也可用此方法解决。 "],["数据库表关系之-多对多关系","2022年06月06日","/2022/06/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%85%B3%E7%B3%BB%E4%B9%8B-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB.html/"," 本章内容针对 进行多对多关系的数据分析 Access表ER图 role角色表 简单的多对多关系介绍 如上ER图中看到了我们的三张表：分别是 、 、 (user这张表我没放上去). 多对多关系: role角色表的一条记录能够对应另外一张user用户表中的多条记录，同时user表中的一条记录也能对应role表中的多条记录,被称之为我们的多对多关系。 在 的 关系中,默认是使用 字段作为关联字段的 表结构如下 根据ER图进行关系分析 tortoise-orm维护多对多的表关系才用的是中间表的形式,通过 来生成表中间表前缀. 角色对用户 一个角色可以对应多个用户 系统管理员角色可以对应多个用户： 张三是管理员、李四是管理员、王五也是管理员。多个用户对应的同时都是系统管理员的角色。 兄弟们: 以后在更新,torroise-orm这个多对多关系的查询我真是搞得不太明白\u0026hellip; "],["Ansible-Playbook","2022年04月04日","/2022/04/01/ansible-playbook.html/"," 是由一个或多个 组成的列表 的主要功能在于将预定义的一组主机，装扮成事先通过ansible中的task定义好的角色。 Task实际是调用ansible的一个module，将多个play组织在一个 中， 即可以让它们联合起来，按事先编排的机制执行预定义的动作 采用 语言编写 1.0 PlayBook核心元素 ：playbook中的每一个play的目的都是为了让特定主机以某个指定的用户身份执行任务,hosts用于指定要执行指定任务的主机，须事先定义在主机清单中. 详细请看 : 可用于Host和task中。也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务.此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户. : 内置变量或自定义变量在playbook中调用 : 可替换模板文件中的变量并实现一些简单逻辑的文件 : 结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行 : 指定某条任务执行，用于选择运行playbook中的部分代码. -C 选项检查剧本是否成功,并不实际执行 1.0.1 忽略错误信息 也可以使用 来忽略错误信息 1.0.2 常用选项 : 只检测可能会发生的改变,但是不会执行 : 列出运行任务的主机 : 主机列表,只针对主机列表中的主机执行 : 显示过程 : 查看任务列表 2.0 Handlers和notify 由于playbook执行会有次序问题,所以当出现次序问题的时候,可以使用handlers结合notify : 是 列表,这些task与前述的task没有本质的区别,用于当不同的资源发生变化的时候,才会采取一定的操作. : 此action可以用在每个play的最后被触发,这样可以避免多次有改变的发生时每次都执行指定的操作,仅仅在所有变化发生完后,一次性执行制定操作,在notify中列出的操作称为 ，也就是notify中定义的操作. 和 可以写多个 3.0 PlayBook的tags使用 给特定的内容打上tags可以单独的执行标签内容 4.0 PlayBook中变量的使用 变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量的来源 通过 模块 在 中定义 普通变量：主机组中的主机单独定义,优先级高于公共变量 公共变量：针对主机组所有主机定义统一变量 通过命令行指定变量： 优先级最高 4.0.1 通过命令行指定变量 4.0.2 在playbook中定义 4.0.3 通过setup模块获取变量 4.0.4 在hosts中定义变量 定义主机组单独的变量 定义公共变量 4.0.5 通过文件加载变量 5.0 模板Templates 采用 语言，使用字面量，有下面形式 数字：整数，浮点数 列表：[item1, item2, \u0026hellip;] 元组：(item1, item2, \u0026hellip;) 字典：{key1:value1, key2:value2, \u0026hellip;} 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;= 逻辑运算：and，or，not 流表达式：For，If，When 5.0.1 When语法 条件测试:如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试, 通过when语句实现，在task中使用，jinja2的语法格式 在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法 当 =CentOS的时候才会去执行template 5.0.2 With_item 迭代写法 迭代嵌套子变量 5.0.3 for循环 创建一个模板文件 5.0.4 if判断 "],["Redis缓存击穿、雪崩、穿透","2022年03月03日","/2022/03/24/redis%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E9%9B%AA%E5%B4%A9%E7%A9%BF%E9%80%8F.html/"," 缓存穿透 简单地就是用户请求透过 直接进入到 当中进行查询，通常是一个不存在的 ,在数据库查询为 。每次请求落在数据库、并且高并发。数据库扛不住会挂掉。 当用户的请求进入到 当中的时候, 当中并没有用户查询的键。 会告诉用户没有查询到此 ，随后请求会被直接转发到后台 当中 当中自然也不会存在此键值对,所以当大量的请求落在 当中则会导致数据库宕机 解决缓存穿透的方案 可以将查到的null设成该key的缓存对象。 当然，也可以根据明显错误的key在逻辑层就就行 。 同时，你也可以分析用户行为，是否为故意请求或者爬虫、攻击者。针对用户访问做限制。 其他等等，比如用布隆过滤器(超大型hashmap)先过滤。 缓存雪崩 和雪崩一样。在这里，就是 缓存集体 ，在高并发情况下突然使得key大规模访问 ，使得数据库崩掉。 解决缓存雪崩 通常的解决方案是将key的过期时间后面加上一个 ，让key均匀的失效。 考虑用队列或者锁让程序执行在压力范围之内，当然这种方案可能会影响并发量。 热点数据可以考虑不失效 缓存击穿 缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库。 击穿和穿透不同，穿透的意思是想法 redis去使得数据库崩掉。而击穿你可以理解为 击穿,这种通常为大量并发对一个key进行大规模的读写操作。这个key在缓存失效期间大量请求数据库，对数据库造成太大压力使得数据库崩掉。就 在秒杀场景下10000块钱的mac和100块的mac这个100块的那个订单肯定会被抢到爆，不断的请求(当然具体秒杀有自己处理方式这里只是举个例子)。所以缓存击穿就是针对某个常用key大量请求导致数据库崩溃。 解决缓存击穿 可以使用互斥锁避免大量请求同时落到db。 布隆过滤器，判断某个容器是否在集合中 可以将缓存设置永不过期(适合部分情况) 做好熔断、降级，防止系统崩溃。 "],["Coturn穿透服务器搭建","2022年03月03日","/2022/03/20/coturn%E7%A9%BF%E9%80%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA.html/"," 1.1下载编译安装coturn 1.2查看是否安装成功 1.3配置文件 1.4 配置证书 生成的证书默认放在./当前目录 可以通过pwd进行查看 1.5修改配置信息 1.6 启动turnserver 千万注意，如果你是阿里云服务器直接去安全组里面放行TCP/UDP 3478端口即可,下面操作是给本地内网测试做的 ICE测试 地址 https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/ 网页配置如下 "],["Elasticsearch+kibana+Logstash部署","2022年03月03日","/2022/03/20/elasticsearch-kibana-logstash%E9%83%A8%E7%BD%B2.html/"," 1.0 准备条件 准备如下： filebeat-6.3.2 elasticsearch-6.3.2 kibana-6.3.2 logstash-6.3.2 内存3GB以上, 这东西太吃内存了,实验环境建议内存给到4G. 官网地址 https://www.elastic.co/cn/elasticsearch/ 如果你嫌弃官网下载的太慢,可以使用以下微云地址下载 https://share.weiyun.com/fnAz5I2f 版本最好是和我这个一致吧 教程是老教程了,微云这会儿也限速了 - 2022-03-21 2.0 搭建Elasticsearch 2.0.1 准备JDK环境 下载 2.0.2 部署Elasticsearch单机版 修改以下内容 2.0.3 安装Kibana 修改以下内容 2.0.4 安装Logstash 修改以下内容 2.0.5 安装filebeat 修改以下内容 2.0.6 编写nginx-access.conf nginx-access.conf 2.0.7 启动服务 2.0.8 验证结果 "],["MySQL常用存储引擎之InnoDB","2022年03月03日","/2022/03/20/mysql%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8Binnodb.html/","MySQL5.5以后版本的默认存储引擎 支持事物的ACID特性 Innodb使用表空间存储 innodb_file_per_table (如果此参数为ON) 则会创建一个独立的表空间: 系统表空间: X表示一个数字 演示参数ON 演示参数OFF 1.0 系统表空间和独立表空间怎么选 比较 系统表空间无法简单的收缩文件大小 独立表空间可以通过 命令收缩文件大小 系统表空间会产生IO瓶颈 独立表空间可以同时向多个文件刷新数据 建议对Innodb使用独立表空间 1.1 如何把原来存在于系统表空间的表转移到独立表空间 步骤 使用mysqldump导出所有数据库表数据 停止mysql服务,修改参数,并删除innodb相关文件 重启mysql服务,重建innodb系统表空间 重新导入数据 注意: Innodb数据字典信息,这种信息还是很重要的 1.3 Innodb存储引擎的特性 Innodb是一种事务性存储引擎 完全支持事物的ACID特性 和 查看Redo log大小 以字节为单位 redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。 Undo log用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。 包括MVCC Innodb支持行级锁 行级锁可以最大程度的支持并发 行级锁由存储引擎层实现 1.4 什么是数据库中的锁 锁的主要作用是管理共享资源的并发访问 锁用于实现事物的隔离性 所保证一个用户写入数据时候另一个用户进行写的时候会被阻塞 锁的类型 共享锁(读锁) 独占锁(写锁) 独占锁以及共享锁演示 当存在锁的情况下 select的语句会被阻塞需要进行解锁 锁的粒度 表级锁 通过mysql的服务器层实现 行级锁 阻塞和死锁 阻塞是为了保证并发的正常运行 过多的阻塞会导致数据库的连接进行堆积 死锁是两个或两个以上的事务在执行的过程中占用相互等待的资源导致异常,少量死锁不会有影响 当有大量的死锁就会有问题了 1.5 Innodb状态检查 适用场景 适合于大多数的OLTP应用 "],["MySQL常用存储引擎之MyISAM","2022年03月03日","/2022/03/20/mysql%E5%B8%B8%E7%94%A8%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B9%8Bmyisam.html/","**MySQL 版本之前的默认存储引擎就是 ** 系统表 临时表(查询优化器建立的临时表) MyISAM存储引擎表由 和 组成 MyISAM的特性 并发性与锁级别 对于读写混合的并发性不会太好 表损坏修复 通过 check table tablename 进行检查 通过 repair table tablename 进行恢复 演示实例 MyISAM表支持的索引类型 MyISAM表支持数据压缩 压缩可以使用 演示实例 对于表中的读写 限制 版本\u0026lt;5.0的默认表大小为4Gb 如存储大表则需要修改 和 修改会导致表重建 版本\u0026gt;5.0的默认表大小为256TB 适用场景 非事务型应用 只读类应用 空间类应用(例如GPS 利用空间函数) "],["MySQL的事务属性","2022年03月03日","/2022/03/20/mysql%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%B1%9E%E6%80%A7.html/"," 1.0 什么是事务 1.事务： 2.事务是一组具有 的SQL语句,或是一个独立的工作单元 1.1 MySQL事务的特性 ：SQL要么全部执行完成,要么全部失败,不可能执行部分语句。 举个例子 如果要去中国银行向建设银行存钱 查看中国银行中的账户余额是否大于2000元 从中国银行的帐户中转出2000元 在建设银行的账户上增加2000元 如果上面的任何一步拿出来单独执行,后果你懂的\u0026hellip;😂 ：数据库的完整性不发生改变 举个例子 不管怎么转钱,总的余额不变 ：一个事务对数据库中的数据修改,未提交事务之前对于其他事务不可见 SQL标准的四种隔离级别 未提交读：简称脏读 已提交读：只能看到已提交事物的修改 可重复读：多次读取事物的数据是一致的,包括已提交的事务 可串行化：读取的每一行进行加锁 可能会导致锁超时, . ：一旦事务提交,其所做的修改会永久的存入数据库,即使系统崩溃 数据也不会丢失. 1.2 什么是大事务 运行时间比较长,操作的数据量比较多的事务. 大事务可能会造成的影响 锁定太多的数据,造成大量的阻塞和锁超时 回滚时所需要的时间较长 执行时间长,容易造成主从延迟 1.3 如何处理大事务 避免一次处理太多的数据 移除不必要在事务中的 操作 做到这两点基本上大事务就解决了 "],["MySQL复制功能介绍","2022年03月03日","/2022/03/20/mysql%E5%A4%8D%E5%88%B6%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D.html/"," 分担数据库的读负载 对服务器进行水平扩展 异步复制(无法保证主库和从库的延迟) 复制解决了什么问题？ 不同服务器上的数据分布 利用二进制日志进行增量备份 不需要太多带宽 但是基于行复制 需要大量的带宽 跨IDC环境下可能有问题 应该进行分批复制 实现数据读取的负载均衡 采用非共享架构 增加数据安全性 减少主库服务器的负载 数据库之间的故障切换 binlog日志 记录了所有MySQL数据库的修改事件 包括增删改查时间和对表结构的修改事件 二进制日志格式 基于段的格式 日志记录量相对较,节约磁盘及网络I/O 缺点如下 必须记录上下文信息 必须保证从数据库的语句与主数据库相同 查看日志使用的格式 如果启动报错 查看二进制日志所记录的内容 基于行的日志格式binlog_formart=ROW Row可以解决主从同步不一致的问题(记录所有行) 例如 同一个SQL语句修改了10000条数据的情况,基于段的日志格式只会记录这个SQL语句基于行的日志会有10000条记录分别记录每一行SQL语句. 使MySQL主从复制更加安全 对每一行数据的修改比基于段的复制搞笑 记录日志量较大 混合日志格式binlog_format=MIXED 根据SQL语句由系统决在基于段和基于行的日志格式中进行选择 数据量的大小由所执行的SQL语句决定 对于二进制日志选择 建议 binlog_format=mixed binlog_formart=row 这两个还是作为首选 注意,在使用binlog_formart=row的时候注意也应该设置 "],["Nginx优化-常规优化","2022年03月03日","/2022/03/20/nginx%E4%BC%98%E5%8C%96-%E5%B8%B8%E8%A7%84%E4%BC%98%E5%8C%96.html/"," 1.1 nginx连接数优化 进程优化 1.2 选项参数优化 1.3系统内核层面优化 1.4 允许打开最大文件数 1.5 nginx 添加统计模块及配置 访问即可http://192.168.20.21/status 1.6 限制同一个IP访问频率 "],["Redis主从复制搭建","2022年03月03日","/2022/03/20/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%90%AD%E5%BB%BA.html/"," 准备环境 192.168.1.100 MASTER 6379 192.168.1.101 SLAVE 6379 脚本每个人的环境不同.可能有的会有问题，按照自己的环境来改和执行 1.0 修改主Redis配置文件 1.1 修改从Redis配置文件 1.3 启动Redis主从 检测主从是否同步 "],["探讨一下大促销当中数据库可能出现的问题","2022年03月03日","/2022/03/20/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8B%E5%A4%A7%E4%BF%83%E9%94%80%E5%BD%93%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98.html/","究竟哪些东西可以影响到我们服务器的性能呢？ 无非就是：CPU、磁盘IO、内存等等一系列硬件 在研究性能时候,先带大家来了解三个术语 QPS: 每秒查询率 是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准,简言之就是数据库每秒能查多少数据 TPS: 服务器每秒处理的事务数。 包括一条消息入和一条消息出，加上一次用户数据库访问。（业务TPS = CAPS × 每个呼叫平均 ） 并发量: ，注意不要和同时连接数搞混,连接数要比并发量多的多的多 如果存在超高的QPS和TPS 效率低下的SQL 在访问量急剧增大的情况下,数据库每秒能处理多少个 就显得很重要了。 假设我们现在只有一个CPU进行处理SQL语句 处理1个SQL 处理100个SQL 在假设如果处理SQL语句的时间变长 处理一个SQL 处理10个SQL 解决方法 的数据库QPS可以通过优化SQL语句来进行一定的优化. 大量的并发和超高的CPU 大量的并发: 数据库连接数被占满(导致网页提示503) 超高的CPU使用率: 因CPU的资源耗尽出现了宕机 解决方法 你需要设置一下 的最大连接数 选择性能更高的CPU 磁盘IO 风险 磁盘IO性能突然下降 其他大量消耗磁盘性能的计划任务(调整计划任务,做好此盘维护) 解决方法 使用更快的磁盘设备 网卡流量 风险 网卡流量被占满导致无法连接数据库 解决方法 减少从服务器的数量 进行分级缓存 避免使用 进行查询 分离业务网络和服务器网络 大表 记录行数巨大,单表超过千万行 表数据文件巨大,表数据文件超过10GB 大表对查询的影响 慢查询: 很难在一定的时间内过滤出所需要的数据 大表对DDL语句操作的影响 建立索引需要很长时间 如果MySQL版本\u0026lt;5.5建立索引会被锁表 如果MySQL版本\u0026gt;=5.5虽然不会被锁表但是会引起主从延迟 修改表结构需要长时间锁表 同建立索引一样,会造成长时间的主从延迟 影响正常数据的操作,阻塞数据 因为所有的Insert语句都会阻塞,都需要等到你的表结构修改完成后才能处理。 解决数据库中的大表 分库分表把一张大表分成多个小表 难点 分表主键的选择 分表后跨分区数据的查询和统计 可能会影响后端业务,需要大量的人力物力 大表的历史数据归档 优点 减少对前后端业务的影响 难点 归档时间点的选择 如何进行归档操作 "],["有关于Nginx跨域问题","2022年03月03日","/2022/03/20/%E6%9C%89%E5%85%B3%E4%BA%8Enginx%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98.html/","项目中使用Nginx服务实现文件的访问，由于和tomcat的接口不是一个域，前端VUE做了图片处理，导致出现跨域问题 添加跨域配置： "],["Mongodb主从搭建","2022年03月03日","/2022/03/20/mongodb%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA.html/"," Mongodb主从搭建 内存2以上 无特殊要求 主IP：192.168.1.100 从IP：192.168.1.101 准备配置如下，每台服务器都执行 1.0 下载安装Mongo 1.2 主mongo配置 1.3 从Mongo配置 测试mongo主从同步 问题解决 原因分析：新版本的MongDB增加了安全性设计，推荐用户创建使用数据库时进行验证。如果用户想建立简单连接，则会提示警示信息。 解决方法 \u0026ldquo;errmsg\u0026rdquo; : \u0026ldquo;not master and slaveOk=false\u0026rdquo; 如果从服务器上进入mongo以后使用show dbs查看是否同步数据库报这个错误是正常的 因为SECONDARY是禁止读的 解决方法 关于Mongo认证机制 :表示带着认证方式进行启动 进入到mongo使用 发现报错 此时应该先到admin库中进行验证 "],["MySQL8.0安装","2022年03月03日","/2022/03/20/mysql8.0%E5%AE%89%E8%A3%85.html/"," 1.0 下载安装包 下载地址 1.1 服务启动 关于MySQL启动报错 如果定位是如上错误 解决办法如下 1.2 修改密码 继 以后默认生成密码,密码可以在 中查看 如果是 如果出现 错误提示表示你的密码不符合安全策略要求,一般都是字母+数字+符号+大写构成。 1.3 授权用户远程登录 "],["Django实现调用腾讯云短信接口","2022年02月02日","/2022/02/22/django%E5%AE%9E%E7%8E%B0%E8%B0%83%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E7%9F%AD%E4%BF%A1%E6%8E%A5%E5%8F%A3.html/"," 腾讯云短信接口 注册 登录 具体怎么注册腾讯云接口看下面的文章吧 腾讯云接口注册 1.0 安装SDK 1.1 编写发送短信接口 我的环境是基于django : 分别都写在了 配置文件下 发送短信出现问题汇总 SSLERROR at /send/sms/ 如何灵活的设置短信正文模板ID "],["dockershim究竟是什么","2022年02月02日","/2022/02/13/dockershim%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88.html/"," 先前了解 参考链接：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md#dockershim-deprecation 参考链接：https://github.com/kubernetes/kubernetes/pull/94624 kubelet中的Docker支持现在已弃用，并将在未来的版本中删除。kubelet使用了一个名为 的模块，该模块实现了对Docker的CRI支持，并在Kubernetes社区中发现了维护问题。我们鼓励您评估迁移到一个容器运行时的情况，该容器运行时是CRI（v1alpha1或v1兼容）的完整实现。 也就是说,在后续的Kubernetes 版本以后会删除 组件,但是由于目前Docker的使用用户众多,中间必然会有替换的一个过渡期,所以大家可以更多的关注一下其他的 。 例如我们的 、 、 等其他容器运行时来运行kubernetes。 下面我们就具体来看看Kubernetes所提到的弃用 到底是什么东西. CRI容器运行时接口 参考链接：https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md CRI：容器运行时接口 container runtime interface，CRI 中定义了容器和镜像两个接口，实现了这两个接口目前主流的是：CRI-O、Containerd。（目前 PCI 产品使用的即为 Containerd）。 CRI接口的具体用处就在于 对容器操作的接口，包括容器的创建、启动和停止.即 、 等操作。 对镜像的操作，下载、删除镜像等. 即 、 等操作。 podsandbox OCI开放容器标准 OCI：开放容器标准 open container initiative，OCI 中定义了两个标准：容器运行时标准 和 容器镜像标准，实现了这一标准的主流是：runc（也即我们日常说的 Docker）、Kata-Container。 OCI的作用在于 ： 文件系统：以 layer 保存的文件系统，每个 layer 保存了和上层之间变化的部分，layer 应该保存哪些文件，怎么表示增加、修改和删除的文件等 config 文件：保存了文件系统的层级信息（每个层级的 hash 值，以及历史信息），以及容器运行时需要的一些信息（比如环境变量、工作目录、命令参数、mount 列表），指定了镜像在某个特定平台和系统的配置。比较接近我们使用 看到的内容 manifest 文件：镜像的 config 文件索引，有哪些 layer，额外的 annotation 信息，manifest 文件中保存了很多和当前平台有关的信息 index 文件：可选的文件，指向不同平台的 manifest 文件，这个文件能保证一个镜像可以跨平台使用，每个平台拥有不同的 manifest 文件，使用 index 作为索引 : :是该州遵守的开放容器倡议运行时规范的版本。 ： 容器的 ID。这在此主机上的所有容器中必须是唯一的。不要求它在主机之间是唯一的。 : 是容器的运行时状态。该值可以是以下之一 1. creating 2. created 3. running 4. stopped : host上看到的容器进程 ：host上容器bundle目录的绝对路径 ：容器相关的标注，可选 所以在Json的序列化时,必须遵守以下格式 Dockershim 作用：把外部收到的请求转化成 能听懂的请求，让 Docker Daemon 执行创建、删除等容器操作。 具体看一下 是怎样创建容器的 Kubelet 通过 CRI 接口（gRPC）调用 ,请求创建一个容器。CRI 即容器运行时接口，这一步中，Kubelet 可以视作一个简单的 ，而 dockershim 就是接收请求的 Server。目前 是内嵌在 Kubelet 中的，所以接收调用就是 Kubelet 进程。 收到请求后，转化成 docker daemon的请求，发到docker daemon 上请求创建一个容器。 Docker Daemon 早在 1.12 版本中就已经将针对容器的操作移到另一个守护进程 containerd 中，因此 Docker Daemon 仍然不能帮我们创建容器，而是要请求 containerd 创建一个容器。 containerd 收到请求后，并不会自己直接去操作容器，而是创建一个叫做 containerd-shim 的进程，让 去操作容器。是因为容器进程需要一个父进程来做诸如收集状态，维持 stdin 等 fd 打开等工作。而假如这个父进程就是 containerd，那每次 containerd 挂掉或升级，整个宿主机上所有的容器都得退出了。而引入了 就规避了这个问题（containerd 和 shim 并不是父子进程关系）。 我们知道创建容器需要做一些设置 namespaces 和 cgroups，挂载 root filesystem 等等操作，而这些事该怎么做已经有了公开的规范，那就是 OCI。它的一个参考实现叫做 runC。于是，containerd-shim 在这一步需要调用 runC 这个命令行工具，来启动容器。 runC 启动完容器后本身会直接退出， 则会成为容器进程的父进程，负责收集容器进程的状态，上报给 containerd，并在容器中 pid 为 1 的进程退出后接管容器中的子进程进行清理，确保不会出现僵尸进程。 image.png 参考链接 别慌: Kubernetes 和 Docker "],["Kubernetes基本存储","2022年02月02日","/2022/02/08/kubernetes%E5%9F%BA%E6%9C%AC%E5%AD%98%E5%82%A8.html/"," 本章了解内容 EmptyDir HostPath NFS PV和PVC 生命周期 StorageClass EmptyDir ​ 是基础的Volume类型,一个 就是Host上的一个空目录。 是在Pod被分配到节点时创建的,它的初始化内容为空,并且无需指定宿主机上对应的目录文件,因为Kubernetes会自动的为他分配一个目录。当Pod被销毁的时候, 中的数据也会永久的被删除。 1. EmptyDir的用途 作为临时空间使用,例如某些应用程序所运行时所需要的临时目录,并且无需永久保留 一个容器需要从另一个容器中获取数据的目录(多容器共享目录) 2. 模拟容器文件共享 在一个Pod中准备两个容器nginx和busybox,然后声明一个Volume分别挂载在两个容器的目录中,然后nginx负责向Volume中写日志,busybox负责读取日志内容到控制台。 你可以进入到你的busybox容器查看 实际上就是相当于Nginx挂载了/var/log/nginx/目录,然后Busybox也挂载了/var/log/nginx/下的内容到自己的/logs/目录。 HostPath ​由于 的生命周期是与Pod相关联的,如果Pod销毁的话,那么 也会随之删除。如果想要简单的将数据持久化到主机中,可以选择 。 ​ 就是主机中的实际目录挂载在Pod中,以供给容器进行使用。这样的设计就可以保证Pod销毁掉以后,数据依然还在主机节点中。 在说一下 的具体类型 ：目录存在就是用,不存在就先创建后使用。 ：目录必须存在 ：文件存在就是用,不存在就创建使用 : 文件必须存在 ：套接字必须存在 ：字符设备必须存在 ：块儿设备必须存在 NFS 虽然可以用来解决数据持久化问题,但是一旦节点故障了,Pod转移到了其他的节点上又会出现问题了,此时我们就需要准备单独的网络存储系统。比如 、 等。 是一个网络文件存储系统,可以搭建一台NFS服务器。然后将Pod中的存储直接连接到 系统中,无论Pod如何转移,只要Node跟 的连接没有问题,数据就可以成功的进行访问。 1. 安装NFS服务器 PV和PVC ​\tPV(Persistent Volume)是持久化卷的意思,是对底层共享存储的一种抽象。一般情况下PV由Kubernetes管理员创建和配置，它与底层具体的共享存储技术有关,并且通过插件完成共享存储的对接。 ​\tPVC(Persistent Volume Claim)是持久卷声明的意思,是用户对存储需求的一种声明。换句话说，实际就是用户向Kubernetes发出的一种需要存储资源的申请。 PVPVC.png 1. PV ​\tPv是存储资源的抽象,下面是资源清单文件 存储类型：底层实际存储的类型,kubernetes支持多种存储类型,每种存储类型的配置都有所差异。 存储能力：目前只支持存储空间的设置,不过未来可能会加入IOPS、吞吐量等指标配置。 访问模式：用户描述用户对存储资源的访问权限。 ：读写权限,但是只能被单个节点挂载。 ：只读权限，可以被多个节点挂载。 ：读写权限，可以被多个节点挂载。 注意：底层不同的存储类型可能支持的访问模式不同。 回收策略：当Pv不在被使用的时候,对这个Pv的处理方式。 ：保留数据,需要管理员手动清理数据。 ：清除PV中的数据。 ：与PV项链的后端存储完成Volume的删除操作 注意：底层不同的存储类型可能支持的访问模式不同。 存储类别：PV可以通过 参数绑定一个存储类别。具有特定类型的PV智能与请求了该类型的Pvc进行绑定。未设定类型的PV只能与不请求任何类型的PVC进行绑定。 状态：一个PV的生命周期中,可能会处于4种不同的阶段 ：表示可用状态,还没有被任何PVC绑定。 ：表示该PV已经被PVC绑定 ：表示PVC被删除,但是资源还未被集群重新声明。 ：表示该PV的自动回收失败。 简单的演示一下PV的使用 2. PVC ​\tPVC是资源的申请,用来声明对存储空间、访问模式、存储类别需求信息。 ：用于描述用户对存储资源的访问权限。 ：通过selector的设置,可使PVC对于系统中已经存在的PVC进行筛选。 ：PVC在定义的时候设定需要后端存储的类别,只有设置了该Class的Pv才能被系统选出。 简单的演示一下Pvc的使用 生命周期 ​\tPV和PVC是一一对应的,PV和PVC之间的相互作用遵循以下生命周期。 1.资源供应：管理员手动创建底层存储和PV。 2.资源绑定：用户创建PVC请求,Kubernetes负责根据PVC的请求去寻找PV,并且进行绑定,在用户定义好PVC之后,系统将根据PVC对存储资源的请求已存在的PV中选择一个满足条件的。 一旦找到,就会将该PV与用户定义的PVC进行绑定,用户的应用就可以使用此PVC了。 如果找不到,PVC则会无限期处于 状态,直到找到符合要求的PVC。 3.资源使用：用户可在Pod中像Volume一样使用Pvc,Pod使用Volume的定义,将Pvc挂载到容器内的某个路径进行使用。 4.资源释放：用户删除PVC释放PV,当存储资源使用完毕后,用户可以删除PVC,与该PVC绑定的PV会被标记完已释放,但不能立刻的与其他PVC进行绑定。通过之前PVC写入的数据可能还留存在存储设备上,只有清楚之后该PV才能再次使用。 5.资源回收：kubernetes根据pv设置的回收策略进行资源的回收,对于PV，管理员可以设定回收策略,用于设置与之绑定的PVC释放资源之后如何处理数据遗留的问题。只有PV的存储空间完成回收,才能与新的PVC绑定和使用。 PVC.png "],["有关于Kubernetes中影响Pod调度的问题","2021年12月12日","/2021/12/21/%E6%9C%89%E5%85%B3%E4%BA%8Ekubernetes%E4%B8%AD%E5%BD%B1%E5%93%8Dpod%E8%B0%83%E5%BA%A6%E7%9A%84%E9%97%AE%E9%A2%98.html/"," 此问题引出的是生产环境中所有的资源完全充足,但是会出现更新Pod、删除Pod、新建Pod无法调度的情况。 生产环境解决问题办法 找到问题跟原所在,默认的 ,K8S默认一个节点上的pod调度数是110，当前有限制pod数的需求。 影响Pod调度的情况 requests资源限制 ：是一种硬限制,Kubernetes在进行Pod请求调度的时候,节点的可用资源必须满足 的CPU才能进行调度,且使用最大限制为 个CPU,如果该Pod超过请求的最大限制,则Kubernetes将会把该Pod进行Kill重启。 当你设置request为 以及limit为 的时候,当你使用 kubectl\rdescribe node查看节点资源的时候可能会与你设置的请求量不符合,这是以你Pod 的实际使用量为标准的。 节点标签的Label 标签选择器： 通过此命令对相应的节点加入标签 当然,你也可以通过 命令查看当前节点的标签 节点亲和性 节点亲和性： 和之前 基本上是一样的,有的话满足进行调度,如果没有的话则依旧也可以调度。 硬亲和性： ,当前约束的条件表示为在 这个键中有 / 有的话即满足的调度,如果不满足则不调度。 软亲和性: ,进行尝试是否满足测试,如果满足则满足调度,如果不满足则依旧会进行调度。 支持的操作符： / / / / 分别为 存在、不存在、大于、小于、不存在。 污点和污点容忍 污点： 和 Pod调度在某些节点上,是属于Pod的属性,在调度的时候进行实现,而污点是对节点做不分配调度,是节点属性。 污点容忍：当一个污点不允许被调度的时候,同时又想让他可能会参与调度,类似于软亲和性。 场景：作为专用节点、配置特定硬件节点、基于Taint驱逐 NoSchedule：一定不被调度 PreferNoSchdule: 尽量不被调度 NoExecute: 不调度,并且会驱逐在该节点上Pod 使用 进行查看是否为污点。 使用 "],["Python元祖详解","2021年11月11日","/2021/11/28/python%E5%85%83%E7%A5%96%E8%AF%A6%E8%A7%A3.html/"," 元组 Python 的元组与列表类似，不同之处在于元组的元素不能修改。 元组使用小括号 ( )，列表使用方括号 [ ]。 元组创建很简单，只需要在括号中添加元素，并使用逗号隔开即可。 创建一个空元祖 元组中只包含一个元素时，需要在元素后面添加逗号 , ，否则括号会被当作运算符使用： 元组与字符串类似，下标索引从 0 开始，可以进行截取，组合等。 访问元组 元组可以使用下标索引来访问元组中的值，如下实例: 修改元组 元组中的元素值是不允许修改的，但我们可以对元组进行连接组合，如下实例: 删除元组 元组中的元素值是不允许删除的，但我们可以使用del语句来删除整个元组，如下实例: 元组运算符 字符串一样，元组之间可以使用 + 号和 * 号进行运算。这就意味着他们可以组合和复制，运算后会生成一个新的元组。 Python 表达式 结果 描述 len((1, 2, 3)) 3 计算元素个数 (1, 2, 3) + (4, 5, 6) (1, 2, 3, 4, 5, 6) 连接 (\u0026lsquo;Hi!\u0026rsquo;,) * 4 (\u0026lsquo;Hi!\u0026rsquo;, \u0026lsquo;Hi!\u0026rsquo;, \u0026lsquo;Hi!\u0026rsquo;, \u0026lsquo;Hi!\u0026rsquo;) 复制 3 in (1, 2, 3) True 元素是否存在 for x in (1, 2, 3): print (x,) 1 2 3 迭代 元组索引，截取 因为元组也是一个序列，所以我们可以访问元组中的指定位置的元素，也可以截取索引中的一段元素，如下所示： 元组： Python 表达式 结果 描述 tup[1] \u0026lsquo;Runoob\u0026rsquo; 读取第二个元素 tup[-2] \u0026lsquo;Weibo\u0026rsquo; 反向读取，读取倒数第二个元素 tup[1:] (\u0026lsquo;Runoob\u0026rsquo;, \u0026lsquo;Taobao\u0026rsquo;, \u0026lsquo;Wiki\u0026rsquo;, \u0026lsquo;Weibo\u0026rsquo;, \u0026lsquo;Weixin\u0026rsquo;) 截取元素，从第二个开始后的所有元素。 tup[1:4] (\u0026lsquo;Runoob\u0026rsquo;, \u0026lsquo;Taobao\u0026rsquo;, \u0026lsquo;Wiki\u0026rsquo;) 截取元素，从第二个开始到第四个元素（索引为 3）。 元组内置函数 len方法 计算元组元素个数。 max方法 返回元组中元素最大值。 min方法 返回元组中元素最小值。 tuple方法 将可迭代系列转换为元组。 关于元组是不可变的 "],["Python装饰器详解","2021年11月11日","/2021/11/22/python%E8%A3%85%E9%A5%B0%E5%99%A8%E8%AF%A6%E8%A7%A3.html/","本博客的内容要点 什么是函数闭包(function closure)? 什么是语法糖(Syntactic sugar)? 什么是装饰器(decorator)? 什么是函数闭包(function closure)？ 看下方的一段代码 函数的主要功能(输出奇数)和辅助功能(统计函数执行时间)全部都放在一个函数中,一旦要对其进行修改,如果修改错误就会导致出现Bug,导致该函数不可用。 不方便修改 我们的目的是为了能不能在直接调用主要函数的同时调用辅助函数？ 接着上面的 我们能不能直接调用主要函数的同时调用辅助函数？ 该段代码的缺点 1.我们期望的是直接调用主要函数,同时执行辅助函数,而并不是把辅助函数写在前面。 2.并且对于使用者来说 函数是不应该被看到的,在可读性上与我们的期望相反 所以,究竟什么是函数的闭包呢？ 一个函数参数和返回值都是函数 用于增强函数功能 面向切面编程(AOP) 究竟如何理解函数闭包 传入的是一个函数,其 的 也是一个函数 在返回的函数中既执行了主要函数 也执行了统计函数的功能 闭包函数本身就是一个函数,闭包函数的返回值函数是对传入函数的增强函数 很方便的解耦,只需要在主要函数中写主要函数 在辅助函数中写辅助函数即可 什么是语法糖(Syntactic sugar)? 指的是计算机语言中添加的某种语法,这种语法 ,但是更方便程序员使用。 语法糖没有增加新功能,只是更方便的写法 语法糖可以完全等价的装换为原本非语法糖的代码 装饰器在 调用被装饰的函数时进行增强 强调一下装饰器第一次调用 装饰器在第一次调用之前才会增强,如果没有被调用则不会增强。 装饰器的增强只增强一次,但是对于增强过得函数可以调用很多次。 对于有返回值和参数的函数 问题1. 对于有返回值的函数和带参数的函数,不能正常返回,但是可以进行增强 问题2. 对于含有参数的函数调用增强后,并不能成功的接收参数 "],["Python字典详细操作","2021年11月11日","/2021/11/21/python%E5%AD%97%E5%85%B8%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C.html/","字典是另一种可变容器模型，且可存储任意类型对象。 字典的每个键值 key=\u0026gt;value 对用冒号 : 分割，每个键值对之间用逗号 , 分割，整个字典包括在花括号 {} 中 ,格式如下所示： 键一般是唯一的，如果重复最后的一个键值对会替换前面的，值不需要唯一。 访问字典里的值 把相应的键放入熟悉的方括弧，如下实例: 如果用字典里没有的键访问数据，会输出错误如下： 字典键的特性 字典值可以没有限制地取任何python对象，既可以是标准的对象，也可以是用户定义的，但键不行。 不允许同一个键出现两次。创建时如果同一个键被赋值两次，后一个值会被记住，如下实例： 字典内置的函数、方法 len()方法 函数计算字典元素个数，即键的总数。 dict: 要计算元素个数的字典 str()方法 函数将值转化为适于人阅读的形式，以可打印的字符串表示。 dict \u0026ndash; 字典 ，返回字符串 clear()方法 函数用于删除字典内所有元素 copy()方法 函数返回一个字典的浅复制。 返回一个字典的浅复制。 直接赋值和 copy 的区别 fromkeys()方法 函数用于创建一个新字典，以序列 seq 中元素做字典的键，value 为字典所有键对应的初始值。 seq \u0026ndash; 字典键值列表。 value \u0026ndash; 可选参数, 设置键序列（seq）的值。 get()方法 函数返回指定键的值。 key \u0026ndash; 字典中要查找的键。 default \u0026ndash; 如果指定键的值不存在时，返回该默认值。 注意嵌套字典中无法通过get()方法来获取字典的键 items()方法 items() 函数以列表返回可遍历的(键, 值) 元组数组。 keys()方法 函数以列表返回一个字典所有的键。 setdefault()方法 函数和 类似, 如果键不存在于字典中，将会添加键并将值设为默认值。 key \u0026ndash; 查找的键值。 default \u0026ndash; 键不存在时，设置的默认键值。 update()方法 函数把字典dict2的键/值对更新到dict里。 dict2 \u0026ndash; 添加到指定字典dict里的字典。 values()方法 函数以列表返回字典中的所有值。 "],["关于Kubernetes构建Redis集群","2021年07月07日","/2021/07/13/%E5%85%B3%E4%BA%8Ekubernetes%E6%9E%84%E5%BB%BAredis%E9%9B%86%E7%BE%A4.html/"," 编写你的Dockerfile redis.conf redis-cluster.yaml 提醒您: 请挂载数据卷配置,注意保存数据,防止数据丢失！！！ 错误排查 关于容器启动退出问题 Docker容器后台运行,就必须有一个前台进程 redis.conf中的 不要设置为 关于kubernetes内部加入Redis集群错误 因为 不支持主机名加入集群,你可以使用 命令将主机名解析成IP后,以解析结果为IP的方式加入。 如下所示 "],["Kubernetes-离线部署skywalking","2021年04月04日","/2021/04/07/kubernetes-%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2skywalking.html/"," 注意：请各位记住把所有离线包全拿到本地\u0026hellip;.. 在线部署chartmuseum 直接使用最简单的 docker run 方式，使用local 本地存储方式，通过 -v 映射到宿主机 /opt/charts 更多支持安装方式见官网 下载Skywalking包 添加elasticsearch仓库 上传本地Helm 以防万一请先安装helmpush插件 https://github.com/chartmuseum/helm-push 你可以尝试搜索一下 保证仓库中存在elasticsarch和skywalking 部署skywalking 准备离线镜像 Helm中的Elasticsearch可能会存在问题 你们也可以用我的这个elasticsearch配置 注意修改PVC "],["Kubernetes持久化配置文件","2021年03月03日","/2021/03/25/kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.html/","ConfigMap了解 描述信息ConfigMap 功能在 Kubernetes1.2 版本中引入，许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。ConfigMap API 给我们提供了向容器中注入配置信息的机制，ConfigMap 可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制大对象 有点儿类似于 这种服务注册中心 configMap的创建 使用目录创建 指定的目录下的所有文件都会配置在configMap中以,以键值对的方式存在. 使用文件创建 只要指定为一个文件就可以从单个文件中创建 ConfigMap 是一个文件 使用字面值创建 键名 键值 Pod中使用ConfigMap 使用ConfigMap代替环境变量 使用configMap设置命令行参数 通过数据卷插件方式使用configMap 在数据卷里面使用configMap,有不同的选项。最基本的就是将文件填入数据卷中,键就是文件名，键值就是文件内容 configMap的热更新 修改configMap 修改 的值为DEBUG等待大概10秒 滚动更新Pod "],["SSH漏洞修复-升级openssh","2021年03月03日","/2021/03/12/ssh%E6%BC%8F%E6%B4%9E%E4%BF%AE%E5%A4%8D-%E5%8D%87%E7%BA%A7openssh.html/"," 修复解决漏洞 升级能解决绝大多数的问题 安装依赖环境 下载Openssh和Openssl 安装Openssl 安装Openssh 备份SSH 启动sshd服务 你可能会遇到sshd无法启动 解决方法 "],["Kubernetes之持久化存储数据(一)","2021年03月03日","/2021/03/04/kubernetes%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B8%80.html/"," 持久化存储-NFS Emptydir：是本地存储,Pod重启,数据不存在了 Nfs：网络存储,Pod重启后,数据还是存在的 部署NFS服务器 可以单独设置一台服务器为NFS服务器 设置挂载目录 在K8S节点上安装NFS 部署应用挂载NFS "],["Kubernete-Helm包管理工具","2021年03月03日","/2021/03/02/kubernete-helm%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7.html/"," 概念 Helm是一个Kubernetes的包管理工具,就像Linux下的包管理工具,可以很方便的将之前打包好的yaml文件部署到Kubernetes上. Helm可以解决那些问题 使用Helm可以把这些yaml作为一个整体管理 实现yaml高效复用 Helm应用级别的版本管理 Helm基础 Charts: Helm使用的打包格式，一个Chart包含了一组K8s资源集合的描述文件。Chart有特定的文件目录结构，如果开发者想自定义一个新的 Chart，只需要使用Helm create命令生成一个目录结构即可进行开发。 Release: 通过Helm将Chart部署到 K8s集群时创建的特定实例，包含了部署在容器集群内的各种应用资源。 Tiller: Helm 2.x版本中，Helm采用Client/Server的设计，Tiller就是Helm的Server部分，需要具备集群管理员权限才能安装到K8s集群中运行。Tiller与Helm client进行交互，接收client的请求，再与K8s API Server通信，根据传递的Charts来生成Release。而在最新的Helm 3.x中，据说是为了安全性考虑移除了Tiller。 Chart Repository: Helm Chart包仓库，提供了很多应用的Chart包供用户下载使用，官方仓库的地址是https://hub.helm.sh ，可以在上面发现很多有意思的项目。之后我们会在官方hub找一个应用做个简单的Demo。 helm：一个命令行管理工具,用来进行配置。 部署Helm 官网地址：https://helm.sh/zh/ 配置Helm仓库 使用Helm部署一个应用 修改weave的Yaml文件 由于服务没有对外暴露端口,所以需要修改Yaml文件 Chart 使用chart部署一个应用 创建一个Chart 创建一个应用 Chart应用升级 通过Helm高效复用 通过传递参数,动态渲染模板,动态传入参数生成。 yaml中大体上有几个不同的地方 在Value.yaml中定义变量 引入Value.yaml变量方式 通过表达式的方式进行适用全局变量 修改Deployment.yaml 修改Service.yaml 尝试运行应用 ：表示尝试运行 "],["Kubernete-Pod操作管理","2021年03月03日","/2021/03/01/kubernete-pod%E6%93%8D%E4%BD%9C%E7%AE%A1%E7%90%86.html/","有状态和无状态的区别 无状态 认为Pod都是一样的 没有顺序要求 不用考虑在哪个Node运行 随意进行伸缩和扩展 有状态 有关无状态的因素都需要考虑 让每个Pod都是独立的,保持Pod启动顺序的唯一性 唯一的网络标识符,持久化存储数据 有序化,例如MYSQL主从 无头Service ClusterIP：None 部署StatefulSet 部署守护进程 在每个Node上运行一个Pod,新加入的node也同样运行一个Pod在里面 Job与Cronjob Job(一次性任务) Cronjob(定时任务) "],["Kubernetes-Deployment","2021年02月02日","/2021/02/28/kubernetes-deployment.html/"," Deployment应用场景 部署无状态应用 或者 管理Pod和ReplicaSet 部署、滚动升级 Pod资源限制 健康检查 : 存活检查 :就绪检查 检测方式如下 HTTPGET：通过发送HTTP请求进行检测,范围200-400为正确 EXEC：通过进入容器执行命令进行检测 TCPSocker：通过建立Socker连接来进行检测 生成Yaml文件 对外暴露端口 应用升级(更新镜像) 动态扩容(属于弹性伸缩一部分) Pod的重启策略 Pod的重启策略（RestartPolicy）应用与Pod内所有容器，并且仅在Pod所处的Node上由kubelet进行判断和重启操作。当某个容器异常退出或者健康检查失败时，kubelet将根据RestartPolicy的设置来进行相应的操作。 Pod的重启策略包括：Always、OnFailure和Never，默认值为Always。 ：当容器失效时，由kubelet自动重启该容器。 ：当容器终止运行且退出码不为0时，由kubelet自动重启该容器。 ：不论容器运行状态如何，kubelet都不会重启该容器。 "],["Redis集群搭建","2021年02月02日","/2021/02/19/redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.html/"," Redis Cluster（Redis集群）简介 redis是一个开源的key value存储系统，受到了广大互联网公司的青睐。redis3.0版本之前只支持单例模式，在3.0版本及以后才支持集群，我这里用的是redis3.0.0版本； redis集群采用P2P模式，是完全去中心化的，不存在中心节点或者代理节点； redis集群是没有统一的入口的，客户端（client）连接集群的时候连接集群中的任意节点（node）即可，集群内部的节点是相互通信的（PING-PONG机制），每个节点都是一个redis实例； 为了实现集群的高可用，即判断节点是否健康（能否正常使用），redis-cluster有这么一个投票容错机制：如果集群中超过半数的节点投票认为某个节点挂了，那么这个节点就挂了（fail）。这是判断节点是否挂了的方法； 那么如何判断集群是否挂了呢? -\u0026gt; 如果集群中任意一个节点挂了，而且该节点没有从节点（备份节点），那么这个集群就挂了。这是判断集群是否挂了的方法； 那么为什么任意一个节点挂了（没有从节点）这个集群就挂了呢？ -\u0026gt; 因为集群内置了16384个slot（哈希槽），并且把所有的物理节点映射到了这16384[0-16383]个slot上，或者说把这些slot均等的分配给了各个节点。当需要在Redis集群存放一个数据（key-value）时，redis会先对这个key进行crc16算法，然后得到一个结果。再把这个结果对16384进行求余，这个余数会对应[0-16383]其中一个槽，进而决定key-value存储到哪个节点中。所以一旦某个节点挂了，该节点对应的slot就无法使用，那么就会导致集群无法正常工作。 综上所述，每个Redis集群理论上最多可以有16384个节点。 Redis集群至少需要3个节点，因为投票容错机制要求超过半数节点认为某个节点挂了该节点才是挂了，所以2个节点无法构成集群。 要保证集群的高可用，需要每个节点都有从节点，也就是备份节点，所以Redis集群至少需要6台服务器。因为我没有那么多服务器，也启动不了那么多虚拟机，所在这里搭建的是伪分布式集群，即一台服务器虚拟运行6个redis实例，修改端口号为（7001-7006） 搭建集群 Redis版本 Gcc7x.x.x 1.0 创建目录 1.1 复制配置文件 如果你不想编译安装的话,你可以把redis中的/bin目录的命令移动到每个node节点文件夹中，这样以方便你使用 命令 1.2 编辑配置文件 此文件内容为集群模式最小配置文件内容. Redis运行端口 启用集群模式 集群模式配置文件 节点的超时时限 开启AOF持久化 开启后台运行 Redis最大可用内存 连接Redis客户端密码 Slave连接master需要的认证 1.3 启动集群 自己建一个启动脚本,要不然手动启动太麻烦了 1.4 加入集群 现在我们有许多实例正在运行，我们需要通过向节点写入一些有意义的配置来创建集群。 如果您使用的是 或更高版本，这很容易完成，因为嵌入到中的Redis Cluster命令行实用程序为我们提供了帮助，该实用程序 可用于创建新集群，检查或重新分片现有集群等。 对于Redis版本3或4，有一个称为的旧工具 ，它非常相似。您可以 在Redis源代码分发的目录中找到它。您需要安装 gem才能运行 。 如果你是用的是Redis3.x或者4.x 请前往官网链接 点我进入 此方法为 或者更高版本 给Master只分配一个slave 1.5 连接集群 是你设置的requirepass密码 注意：出现connected_slaves:1 表示连接到了一个从服务器 如果为0 请查看服务器错误日志 1.6 故障切换 连接到7003的从服务器7005 查看数据是否同步 宕机7003服务器 通过 发现7005已经成为主服务器 再次启动7003发现已经更改为从服务器，并且已经被7005连接到 总结 首先 先说结论：redis集群无法保证强一致性 既然无法保证强一致性，也就是说有可能出现写数据丢失的情况，比如一个客户端发一个写请求给master，master再同步到slave之前就给client一个回执。这个时候会存在一个时间窗口，master 和 slave之间的数据是不一致的。但是redis的最终一致性会使master和slave的数据是最终一致。 另外还有一个可能，在客户端收到了master的一个写请求回执之后，此时master准备把数据同步到slave，同步之前突然挂了，那么这个数据真的就是会丢失了。 如果为了保证强一致，比如我们每秒刷盘进行持久化，那么牺牲了这个吞吐量，就特别类似我们常说的同步复制了。但是redis集群是没有实现强一致的。 1、redis保证最终一致性 2、用最终一致性换取了高吞吐量 3、主节点挂了的时候，如果数据没有同步到备节点，是会出现数据丢失的情况 4、发生网络分区的时候也可能会丢数据，这个时候有个node timeout时间概念 "],["Python-方法反射","2021年01月01日","/2021/01/25/python-%E6%96%B9%E6%B3%95%E5%8F%8D%E5%B0%84.html/"," 什么是反射? 反射的概念是由Smith在1982年首次提出的，主要是指程序可以访问、检测和修改它本身状态或行为的一种能力（自省）。这一概念的提出很快引发了计算机科学领域关于应用反射性的研究。它首先被程序语言的设计领域所采用,并在Lisp和面向对象方面取得了成绩。 简而言之 ：反射就是通过字符串的去操作对象中的属性 反射的方法 : 用于返回一个对象属性值。 : 用于判断对象是否包含对应的属性 : 用于删除属性。 : 用于设置属性值，该属性不一定是存在的。 实例化对象 方法 方法 方法 方法 "],["12306抢票小助手","2021年01月01日","/2021/01/11/12306%E6%8A%A2%E7%A5%A8%E5%B0%8F%E5%8A%A9%E6%89%8B.html/","不过，抢票软件并非万能，巧coder难为无票之炊，除了技术，你可能还需要一点点运气。 无论采取哪种交通方式，祝大家都能开开心心过年回家，平平安安回来搬砖~ 原生项目地址 其实作者已经没有在维护了\u0026hellip; 我只是拿剩下的进行了二开 多多少少会有些问题..:pig: 支持的Python版本 2.7.10 - 2.7.15(目前根据作者代码来看已经不支持) 3.6 - 3.7.4(推荐) 2.7.9(不太确定) 3.8.x(今天测试-不支持) 已实现功能 自动打码 自动登录 准点预售和捡漏 智能候补 邮件通知 server酱通知 短信通知提示(2020-1-11日新增) 更新Token参数(优先调用) 预获取Cookie(待增加) 设置支付接口 依赖库 验证码目前可以本地识别，需要下载模型，放于项目根目录 自托管云打码服务器搭建：12306_code_server 项目依赖 Python依赖 部署教程 推荐root用户直接安装 安装Docker与Docker-compose 部署12306_code_server 启动code_server 1.0 服务启动说明 筛选CDN 修改配置文件 测试配置邮箱 启动服务 1.1 修改配置文件 车票日期记得写对例如： 1.2 筛选CDN 至此，准备工作已全部完成，启动前请先筛选cdn，这点很重要！ 1.3 启动服务 成功Log Cookie以及Token获取 别再问我怎么获取Cookie了！！！ 登录网页版12306官网 网址旁边有个锁子🔐 点击锁子\u0026gt;点击Cookie\u0026gt;点击12306.cn 在 下面找到 和 把值复制进去 再有不懂！直接百度🙅‍♀️ Token 打开12306.cn 打开开发者工具(F12) 点击Network选项-\u0026gt;过滤请求类型选择 登录12306,然后返回到开发者工具 找到 -\u0026gt; Headers-\u0026gt;一直往下拉会有tk "],["Ansible执行Shell模块问题","2021年01月01日","/2021/01/06/ansible%E6%89%A7%E8%A1%8Cshell%E6%A8%A1%E5%9D%97%E9%97%AE%E9%A2%98.html/"," 问题 Ansible调用shell远程启动java包，找不到 或者直接输出为空。 解决过程 首先，在/etc/profile中声明java的变量,发现执行 返回为空 其次，在 中添加环境变量，用ansible远程执行脚本，发现依然输出为空和找不到java\u0026hellip;. 最后\u0026hellip;考虑ansible执行的环境变量与登录时使用的环境变量是否有所不同,所以将 写在 里面,发现执行结果正常\u0026hellip; 原因 由于我的猜测可能是由于ansible执行的时候并没有调用 里面的环境变量配置,只加载 和 里面环境变量 善意的提醒 建议以后把一些Devops或者持续交付的环境变量全部配置到 "],["Redis哨兵模式搭建","2021年01月01日","/2021/01/04/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E6%90%AD%E5%BB%BA.html/"," 哨兵模式简介 主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。 哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。 这里的 有两个作用 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。 然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。 用文字描述一下故障切换（failover）的过程。假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行failover操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线。这样对于客户端而言，一切都是透明的。 搭建Redis哨兵 配置3个哨兵和1主2从的Redis服务器 服务类型 是否是主服务器 IP地址 端口 Redis 是 172.16.87.10 6379 Redis 否 172.16.87.11 6379 Redis 否 172.16.87.12 6379 Sentinel - 172.16.87.10 26379 Sentinel - 172.16.87.11 26379 Sentinel - 172.16.87.12 26379 部署Redis(三台全搞) Redis6.x版本以上需要GCC4.9X 更改Redis 主配置文件 修复master认证密码 更改Redis从配置文件172.16.87.11` 更改Redis从配置文件 上述内容主要是配置Redis服务器，从服务器比主服务器多一个slaveof的配置和密码。 配置哨兵文件 在Redis安装目录下有一个 文件 三台Redis都需要更改此配置文件 注意logfile的命名 禁止保护模式 后台运行 配置监听的主服务器 代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作. mymaster为服务名 123.com为密码,与上述一样即可 我相信大家都能看得懂\u0026hellip;我是这样命名的 redis-sentinel10.log(172.16.87.10) redis-sentinel11.log(172.16.87.11)以此类推 上述都修改完成可以启动redis了 启动Redis和哨兵 注意启动的顺序：首先是主的Redis服务进程，然后启动从机的Redis服务进程，最后启动3个哨兵的服务进程。 检查Redis主从是否同步成功 查看Redis日志 出现两个 并且成功同步复制即成功. 检测哨兵的主从切换是否成功 你可以直接kill掉Redis的master 连接到Redis172.16.87.11 "],["Elasticsearch常用的RESTAPI","2020年12月12日","/2020/12/29/elasticsearch%E5%B8%B8%E7%94%A8%E7%9A%84restapi.html/"," GET方式 1.0 查询Elastic节点状态 1.1 初始化索引 1.2 查看索引信息 1.3 查看多个索引信息 1.4 查询所有索引的信息 1.5 查看所有索引列表 1.6 查看索引相关信息 PUT方式 1.0 创建索引 1.1 创建索引及类型和文档 1.2 创建索引及类型,不设置文档ID（因为会自动设置文档ID） 1.3 更新同一id下的信息 1.4 更新指定字段 DELETE 1.0 delete 地址/索引名称 1.1 删除文档 "],["挂载OSS到ECS服务器","2020年12月12日","/2020/12/20/%E6%8C%82%E8%BD%BDoss%E5%88%B0ecs%E6%9C%8D%E5%8A%A1%E5%99%A8.html/","阿里云 OSS 是对象存储服务，价格也比较便宜，算得上是一个免费的 CDN，我们可以利用 OSSFS 这个工具，将 OSS 挂载到阿里云 ECS 服务器上，可以达到存储、备份的目的。当然，最主要的是可以减轻服务器的压力。 注意阿里云 OSS 下行流量没有免费额度，都需要收费。 本次仅针对Centos7.x Centos8目前不支持挂载OSS存储,不知道支不支持,老教程了。 \u0026ndash; 2022-03-21 OSSFS 通过OSSFS，您可以将阿里云OSS存储桶安装到 系统中的本地文件中。在系统中，您可以方便地在OSS中的对象上进行操作，同时使用本地文件系统维护数据共享。 特征 OSSFS基于S3FS构建，并具有S3FS的所有功能。主要特点： 支持大多数POSIX文件系统功能，包括文件读/写，目录，链接操作，权限，uid / gid和扩展属性）。 支持通过OSS多部分功能上传大文件。 支持MD5验证，以确保数据完整性。 下载安装包 到官方仓库 下载最新的rpm 选择 配置OSSFS 首先需要拿到阿里云的 和 。登录阿里云账号，然后打开密钥管理 页面，然后在列表里随便选择一个并记录下来。然后还需要去 oss 控制台创建一个 bucket，我这里 bucket 的名称叫做 为了演示假如我的 AccessKey ID 为 ， Access Key Secret 为 在系统上创建一个系统目录比如为 , 将此目录作为 ossfs 的挂载目录 表示的是 oss 的 EndPoint 地址 表示运行非 root 用户使用此目录 开机启动挂载 这里需要用到 "],["Linux 误删文件恢复命令及方法","2020年12月12日","/2020/12/11/linux-%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%E6%81%A2%E5%A4%8D%E5%91%BD%E4%BB%A4%E5%8F%8A%E6%96%B9%E6%B3%95.html/","为rm -rf 的手残党准备的 注意事项：虽然有软件可以对误删的数据进行恢复，但是完全恢复数据的概率并不是百分百的。 在提醒：适用rm -rf 的时候依旧慎用 extundelete恢复 使用存储在分区日志中的信息，尝试恢复已从ext3或ext4的分区中删除的文件 extundelete官方地址(官网文档 ) extundelete(下载地址 )最新版本的extundelete是0.2.4，于2013年1月发布 在数据删除之后，要卸载被删除数据所在的磁盘或是分区 如果是系统根分区遭到误删除，就要进入单用户模式,将根分区以只读的方式挂载,尽可能避免数据被覆盖 数据被覆盖后无法找回 恢复仍有一定的机率失败，平时应对重要数据作备份，小心使用rm 1.0安装依赖 2.0安装编译 使用 可以查看版本 3.0 进行文件恢复 1、查看要恢复文件的分区的文件系统 2、对要恢复文件的分区解除挂载 3、查看可以恢复的数据 指定误删文件的分区进行查找 最后一列标记为Deleted的文件，即为删除了的文件 4、恢复单个目录 指定要恢复的目录名 如果是空目录，则不会恢复 当执行恢复文件的命令后，会在执行命令的当前的目录下生成RECOVERED_FILES目录，恢复的文件都会放入此目录中。如未生成目录，即为失败。 5、恢复单个文件 指定要恢复的文件名 如果几k大小的小文件，有很大几率恢复失败 6、恢复全部删除的文件 无需指定文件名或目录名，恢复全部删除的数据 "],["Nginx配置WSS","2020年12月12日","/2020/12/07/nginx%E9%85%8D%E7%BD%AEwss.html/"," 简单了解一下 WebSocket 现在，很多网站为了实现推送技术，所用的技术都是轮询。轮询是在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTP请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会浪费很多的带宽等资源。 在这种情况下，HTML5定义了WebSocket协议，能更好的节省服务器资源和带宽，并且能够更实时地进行通讯。 WebSocket一种在单个 TCP 连接上进行全双工通讯的协议。使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。 简单点说，WebSocket 就是减小客户端与服务器端建立连接的次数，减小系统资源开销，只需要一次 HTTP 握手，整个通讯过程是建立在一次连接/状态中，也就避免了HTTP的非状态性，服务端会一直与客户端保持连接，直到你关闭请求，同时由原本的客户端主动询问，转换为服务器有信息的时候推送。当然，它还能做实时通信、更好的二进制支持、支持扩展、更好的压缩效果等这些优点。 ws 和 wss Websocket使用 ws 或 wss 的统一资源标志符，类似于 HTTP 或 HTTPS ，其中 wss 表示在 TLS 之上的 Websocket ，相当于 HTTPS 了。如： 默认情况下，Websocket 的 ws 协议使用 80 端口；运行在TLS之上时，wss 协议默认使用 443 端口。其实说白了，wss 就是 ws 基于 SSL 的安全传输，与 HTTPS 一样样的道理。 如果你的网站是 HTTPS 协议的，那你就不能使用 了，浏览器会 block 掉连接，和 HTTPS 下不允许 HTTP 请求一样 Nginx配置webscoket location部分一般根据开发的接口来 proxy_pass http://websocket ; 表示代理到websocket 重启nginx "],["Python嵌套函数与匿名函数","2020年12月12日","/2020/12/03/python%E5%B5%8C%E5%A5%97%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0.html/"," 函数的嵌套调用是在\u0026quot;函数调用中再调用其他函数\u0026quot;。也就是说:函数嵌套允许在一个函数中调用另外一个函数。如下： 函数的查找顺序优先局部变量\u0026gt;全局变量 匿名函数 正常情况下我们写的函数如下,对函数声明了cacl的名称 那么匿名函数则不需要对其进行定义 lambda生成匿名函数 map(func,seq) 就是将函数作用在序列的每个元素上，然后创建由函数返回值组成的列表。 map(lambda x: x**x)，遍历mylist每个元素，执行lambda函数，并返回一个列表 "],["Linux Shell 文本处理工具集锦-find篇","2020年11月11日","/2020/11/24/linux-shell-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%E9%9B%86%E9%94%A6-find%E7%AF%87.html/"," 1 查找txt和pdf文件 2 正则方式查找.txt和pdf 3 否定参数 查找所有非txt文本 4 指定搜索深度 打印出当前目录的文件（深度为1） 5 定制搜索 按类型搜索： 按时间搜索： 最近7天被访问过的所有文件： 按大小搜索： w字 k M G 寻找大于2k的文件 按权限查找： 按用户查找： 6 找到后的后续动作 删除： 删除当前目录下所有的swp文件： 执行动作（强大的exec） 注：{}是一个特殊的字符串，对于每一个匹配的文件，{}会被替换成相应的文件名； eg：将找到的文件全都copy到另一个目录： 7 结合多个命令 tips: 如果需要后续执行多个命令，可以将多个命令写成一个脚本。然后 -exec 调用时执行脚本即可； -print的定界符 默认使用\u0026rsquo; \u0026lsquo;作为文件的定界符； -print0 使用\u0026rsquo;\u0026lsquo;作为文件的定界符，这样就可以搜索包含空格的文件； "],["Mongo部署副本集","2020年10月10日","/2020/10/26/mongo%E9%83%A8%E7%BD%B2%E5%89%AF%E6%9C%AC%E9%9B%86.html/"," 部署副本集 1.0 更改Mongo配置文件 启动Mongo 1.1 主Mongo配置 1.2 副本集更新 1.4 更新副本集优先级 1.5 查看副本集状态 1.6 查看副本集的配置信息 1.7 查看节点复制信息 1.8 插入测试数据 开启安全验证 先停止从上面的mongo然后在停止主上面的mongo 在master上进行操作 2.0 创建用户 2.1 创建秘钥文件 将生成的keyFile文件拷贝到其他节点服务器上，并修改文件的操作权限为 600 2.2 启动副本集 "],["Nacos集群部署","2020年10月10日","/2020/10/26/nacos%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.html/"," 点我进入官网 服务发现和服务运行状况检查 Nacos支持基于DNS和基于RPC（Dubbo / gRPC）的服务发现。服务提供商向本机 ，OpenAPI 或专用代理 注册服务后，使用者可以使用DNS 或HTTP 查找服务。 Nacos提供实时运行状况检查，以防止服务将请求发送到不正常的主机或服务实例。Nacos支持传输层（PING或TCP）运行状况检查和应用程序层（例如HTTP，Redis，MySQL和用户定义的协议）运行状况检查。对于复杂云和网络拓扑（例如VPC，边缘服务等）的运行状况检查，Nacos提供代理模式和服务器模式运行状况检查。Nacos还提供统一的服务运行状况仪表板，以帮助您管理服务的可用性和流量。 动态配置管理 动态配置服务使您可以在所有环境中以集中，外部化和动态的方式管理所有应用程序和服务的配置。 动态配置消除了在更新配置时重新部署应用程序和服务的需要。 配置的集中管理使您更方便地实现无状态服务和按需弹性扩展服务实例。 Nacos提供了易于使用的UI TODO ，可帮助您管理所有应用程序或服务的配置。它提供了一些现成的功能，包括配置版本跟踪，canary / beta版本，配置回滚和客户端配置更新状态跟踪，以确保安全并控制配置更改的风险。 动态DNS服务 支持加权路由的动态DNS服务使您可以更轻松地在数据中心内的生产环境中实施中间层负载平衡，灵活的路由策略，流量控制和简单的DNS解析服务。动态DNS服务使您更容易实现基于DNS的服务发现。 Nacos提供了一些简单的DNS API TODO， 供您管理DNS域名和IP。 服务治理和元数据管理 Nacos允许您从微服务平台构建器的角度管理所有服务和元数据。这包括管理服务描述，生命周期，服务静态依赖关系分析，服务运行状况，服务流量管理，路由和安全规则，服务SLA和一线指标。 nacos_map 特征大图：从功能特征和非功能特征介绍我们要解决的问题域的特征。 更大的体系结构：清晰的体系结构可快速进入Nacos世界 业务图：当前功能和最佳实践可以支持的业务场景 生态大图：系统地整理Nacos与主流技术生态之间的关系 优势大图：展示Nacos核心竞争力 战略图片：Nacos从战略到战术层面的宏观优势 配置清单 192.168.20.10 Mysql-master nacos 192.168.20.11 mysql-slave nacos 192.168.20.12 mysql-slave nacos 1.0 三台数据库配置 1.0.1 创建数据库同步用户 1.0.2 从库配置 1.0.3 检测主从同步 2.0 单实例版nacos集群 下载地址 这里使用源代码方式部署 集群最少3节点以上(采用端口号方式) nacos1.0.0没有集群功能 JDK8+ maven3.2+ 2.1 安装nacos 2.2 修改nacos端口号 2.3 配置集群文件 2.4 修改启动脚本 2.5 启动nacos集群 3.0 多实例版nacos集群 3.1 nacos连接mysql存储源 3.2 导入mysql数据 3.3 测试nacos持久化 然后访问nacos新建一个测试的数据 进入mysql查询数据 "],["kubernetes-Rbac","2020年04月04日","/2020/04/07/kubernetes-rbac.html/"," Kubernetes中的基于角色的访问控制 Role ClusterRole(角色) 主体如下 User Group ServiceAccount 一般选择角色与主体进行绑定 角色 当角色可以做什么事情的时候,主体就可以做什么操作 Role：特定的命名空间的访问权限 Cluster Role: 所有命名空间的访问权限 角色绑定 roleBinding: 角色绑定到主体 ClusterRoleBinding: 集群角色绑定到主体 主体 user：用户 group：用户组 ServiceAccount：服务账户(一般用于Pod访问) 创建命名空间 在新的空间中创建Pod 创建一个角色 绑定一个用户 "],["kubernetes-部署NACOS","2020年04月04日","/2020/04/07/kubernetes-%E9%83%A8%E7%BD%B2nacos.html/"," 简单安装使用 最新版本应该是1.4.1 简单使用 如果你使用简单方式快速启动,请注意这是没有使用持久化卷的,可能存在数据丢失风险:!!! 演示使用 服务注册 服务发现 发布配置 获取配置 高级用法 在高级使用中,Nacos在K8S拥有自动扩容缩容和数据持久特性,请注意如果需要使用这部分功能请使用PVC持久卷,Nacos的自动扩容缩容需要依赖持久卷,以及数据持久化也是一样,本例中使用的是NFS来使用PVC. 部署NFS nfs-client-provisioner 可动态为kubernetes提供pv卷，是Kubernetes的简易NFS的外部provisioner，本身不提供NFS，需要现有的NFS服务器提供存储。持久卷目录的命名规则为: 创建角色 修改NFS的yaml 部署NFS-client 部署NFS StorageClass 验证nfs-client-provisioner是否成功 部署mysql 部署Nacos 修改 deploy/nacos/nacos-pvc-nfs.yaml 可以自行选择更改 创建Nacos 扩容测试 在扩容前，使用 (https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands/#exec )获取在pod中的Nacos集群配置文件信息 StatefulSet控制器根据其序数索引为每个Pod提供唯一的主机名。 主机名采用 - 的形式。 因为nacos StatefulSet的副本字段设置为3，所以当前集群文件中只有三个Nacos节点地址 使用kubectl scale 对Nacos动态扩容 "],["kubernetes-卷的概念","2020年04月04日","/2020/04/07/kubernetes-%E5%8D%B7%E7%9A%84%E6%A6%82%E5%BF%B5.html/"," PersistentVolume 是由管理员设置的存储,他是集群的一部分。就像节点是集群中的资源一样,PV也是集群中的资源。 PV是Volume之类的卷插件,但具有独立于适用PV的Pod的生命周期。此API对象包含存储实现的细节 即NFS、ISCSI或特定于云供应商存储系统 有关于PV的分类 静态PV: 集群管理员创建一些PV ,他们带有可供集群用户使用的实际存储的细节。,他们存在于KubernetesAPI中 动态PV：当管理员创建的静态PV都不匹配用户的persistenVolumeClaim时候,集群可能会尝试动态的为PVC创建卷。此配置基于 也就是说PVC必须请求 并且管理员必须创建并且配置类才能动态创建 绑定：master中的控制环路监视新的PVC,寻找匹配的PV(如果可能),并将它们绑定在一起。如果为新的PVC动态调配PV,则该环路将始终会把PV绑定到PVC,否则,用户总会得到它们所请求的存储,但是容量可能超出要求的数量。一旦PV和PVC绑定完成之后 不管他们是如何绑定的 PVC和PV是一对一的映射。 PVC 根据容量和读写模式进行匹配 使用户存储的请求。它与Pod相似。Pod消耗节点资源,PVC消耗PV资源,Pod可以请求特定级别的CPU和内存 PVC可以请求特定的大小和访问模式。 持久化卷声明的保护 PVC保护的目的是确保Pod正在使用的PVC不会从系统中移除 当启用PVC保护alpha的功能时候,如果用户删除了一个Pod正在使用的PVC,则该PVC不会被立即删除 ,PVC的删除将会被延迟,直到PVC不再被任何Pod使用 持久化卷类型 GcePersistentDisk FlexVolume Cinder HostPath PV创建 选择NFS作为PV的底层存储 PV访问模式 可以以资源提供者支持的任何方式挂载到主机上。如下图所示 供应商具有不同的功能,每个PV的访问模式都将被设置为该卷支持的特定模式。 注意：并不是所有的插件都支持多个读/写客户端 例如可以指定NFS的PV只能以读的方式导出到服务器上. ReadWriteOnce：该卷可以被单个Pod以读/写模式挂载 ReadOnlyMany：该卷可以被多个Pod以只读模式挂载 ReadWriteMany：该卷可以被多个Pod以读/写模式挂载 回收策略 Retain：保留\u0026ndash;手动回收 Recycle：回收\u0026ndash;基本擦除(差不多类似于rm -rf /*) 新版本已经删除了 Delete(删除)\u0026ndash;关联的存储资产(例如AWS EBS) 当前只有NFS和HostPath支持回收策略 AWS EBS Azure Disk支持删除 状态 卷可以处于以下某种的状态 Available：可用-一块空闲资源还没有被任何声明绑定. Bound：已绑定-卷已经声明绑定 Released：已释放-声明被删除,但是资源还未被集群重新声明 Failed：失败-该卷的自动回收失败 PVC创建 安装NFS的我就不写了 创建服务并且使用Pvc 面介绍的PV和PVC模式是需要运维人员先创建好PV，然后开发人员定义好PVC进行一对一的Bond，但是如果PVC请求成千上万，那么就需要创建成千上万的PV，对于运维人员来说维护成本很高，Kubernetes提供一种自动创建PV的机制，叫StorageClass，它的作用就是创建PV的模板。 具体来说，StorageClass会定义一下两部分： PV的属性 ，比如存储的大小、类型等 创建这种PV需要使用到的存储插件，比如Ceph等 有了这两部分信息，Kubernetes就能够根据用户提交的PVC，找到对应的StorageClass，然后Kubernetes就会调用 StorageClass声明的存储插件，创建出需要的PV。 这里我们以NFS为例，要使用NFS，我们就需要一个nfs-client的自动装载程序，我们称之为Provisioner，这个程序会使用我们已经配置好的NFS服务器自动创建持久卷，也就是自动帮我们创建PV。 说明： 自动创建的PV会以 的目录格式放到NFS服务器上； 如果这个PV被回收，则会以 这样的格式存放到NFS服务器上； "],["","0001年01月01日","/1/01/01/.html/"," Helm的Chart上传至Harbor仓库 配置Harbor支持Chart 添加仓库 "]]